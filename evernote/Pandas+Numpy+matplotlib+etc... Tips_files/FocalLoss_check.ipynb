{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/gpfsx01/home/aaa00162/jupyterhub/notebook/H3-057/work/FocalLoss_check\r\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/home/bioinfo/.conda/envs/tfgpu_py36/bin/python'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!pwd\n",
    "import sys\n",
    "sys.executable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focal Loss test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "gpu_num = 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = str(gpu_num)\n",
    "\n",
    "# 自作モジュールimport\n",
    "sys.path.append('/gpfsx01/home/aaa00162/jupyterhub/notebook/H3-057/Submit/make_hERG_PAMPA_model/make_model/')\n",
    "from modules import *\n",
    "#sys.path.append('/gpfsx01/home/aaa00162/jupyterhub/notebook/H3-057/Submit/make_hERG_PAMPA_model/make_model/modules/Git/mixup-generator/')\n",
    "#from random_eraser import get_random_eraser\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import keras.backend as K\n",
    "K.clear_session()\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multi-class binary, categoricalの時のFocal Loss\n",
    "- https://github.com/umbertogriffo/focal-loss-keras/blob/master/losses.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dill\n",
    "\n",
    "def binary_focal_loss(gamma=2., alpha=.25, mask_value=None):\n",
    "    \"\"\"\n",
    "    Binary form of focal loss.\n",
    "      FL(p_t) = -alpha * (1 - p_t)**gamma * log(p_t)\n",
    "      where p = sigmoid(x), p_t = p or 1 - p depending on if the label is 1 or 0, respectively.\n",
    "    References:\n",
    "        https://arxiv.org/pdf/1708.02002.pdf\n",
    "    Usage:\n",
    "     model.compile(loss=[binary_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "     \n",
    "     # モデルロード時は以下のようにcustom_objectが必要\n",
    "     import dill\n",
    "     custom_object = {'binary_focal_loss_fixed': dill.loads(dill.dumps(binary_focal_loss(gamma=2., alpha=.25)))\n",
    "                      , 'categorical_focal_loss_fixed': dill.loads(dill.dumps(categorical_focal_loss(gamma=2., alpha=.25)))\n",
    "                      , 'categorical_focal_loss': categorical_focal_loss\n",
    "                      , 'binary_focal_loss': binary_focal_loss}\n",
    "      model = keras.models.load_model(input_model_path, custom_objects=custom_object)\n",
    "    \"\"\"\n",
    "    def binary_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred:  A tensor resulting from a sigmoid\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        if mask_value is not None:\n",
    "            mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "            y_true = y_true * mask\n",
    "            y_pred = y_pred * mask\n",
    "        \n",
    "        pt_1 = tf.where(tf.equal(y_true, 1), y_pred, tf.ones_like(y_pred))\n",
    "        pt_0 = tf.where(tf.equal(y_true, 0), y_pred, tf.zeros_like(y_pred))\n",
    "\n",
    "        epsilon = K.epsilon()\n",
    "        # clip to prevent NaN's and Inf's\n",
    "        pt_1 = K.clip(pt_1, epsilon, 1. - epsilon)\n",
    "        pt_0 = K.clip(pt_0, epsilon, 1. - epsilon)\n",
    "\n",
    "        return -K.sum(alpha * K.pow(1. - pt_1, gamma) * K.log(pt_1)) \\\n",
    "               -K.sum((1 - alpha) * K.pow(pt_0, gamma) * K.log(1. - pt_0))\n",
    "\n",
    "    return binary_focal_loss_fixed\n",
    "\n",
    "\n",
    "def categorical_focal_loss(gamma=2., alpha=.25, mask_value=None):\n",
    "    \"\"\"\n",
    "    Softmax version of focal loss.\n",
    "           m\n",
    "      FL = ∑  -alpha * (1 - p_o,c)^gamma * y_o,c * log(p_o,c)\n",
    "          c=1\n",
    "      where m = number of classes, c = class and o = observation\n",
    "    Parameters:\n",
    "      alpha -- the same as weighing factor in balanced cross entropy\n",
    "      gamma -- focusing parameter for modulating factor (1-p)\n",
    "    Default value:\n",
    "      gamma -- 2.0 as mentioned in the paper\n",
    "      alpha -- 0.25 as mentioned in the paper\n",
    "    References:\n",
    "        Official paper: https://arxiv.org/pdf/1708.02002.pdf\n",
    "        https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy\n",
    "    Usage:\n",
    "     model.compile(loss=[categorical_focal_loss(alpha=.25, gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "     \n",
    "     # モデルロード時は以下のようにcustom_objectが必要\n",
    "     import dill\n",
    "     custom_object = {'binary_focal_loss_fixed': dill.loads(dill.dumps(binary_focal_loss(gamma=2., alpha=.25)))\n",
    "                      , 'categorical_focal_loss_fixed': dill.loads(dill.dumps(categorical_focal_loss(gamma=2., alpha=.25)))\n",
    "                      , 'categorical_focal_loss': categorical_focal_loss\n",
    "                      , 'binary_focal_loss': binary_focal_loss}\n",
    "      model = keras.models.load_model(input_model_path, custom_objects=custom_object)\n",
    "    \"\"\"\n",
    "    def categorical_focal_loss_fixed(y_true, y_pred):\n",
    "        \"\"\"\n",
    "        :param y_true: A tensor of the same shape as `y_pred`\n",
    "        :param y_pred: A tensor resulting from a softmax\n",
    "        :return: Output tensor.\n",
    "        \"\"\"\n",
    "        if mask_value is not None:\n",
    "            mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "            y_true = y_true * mask\n",
    "            y_pred = y_pred * mask\n",
    "        \n",
    "        # Scale predictions so that the class probas of each sample sum to 1\n",
    "        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n",
    "\n",
    "        # Clip the prediction value to prevent NaN's and Inf's\n",
    "        epsilon = K.epsilon()\n",
    "        y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "        # Calculate Cross Entropy\n",
    "        cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "        # Calculate Focal Loss\n",
    "        loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "\n",
    "        # Sum the losses in mini_batch\n",
    "        return K.sum(loss, axis=1)\n",
    "\n",
    "    return categorical_focal_loss_fixed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-class classification with focal loss for imbalanced datasets \n",
    "- https://github.com/Tony607/Focal_Loss_Keras\n",
    "\n",
    "\n",
    "- 出力層2nodeの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrg</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9839.64</td>\n",
       "      <td>170136.0</td>\n",
       "      <td>160296.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1864.28</td>\n",
       "      <td>21249.0</td>\n",
       "      <td>19384.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>181.00</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>11668.14</td>\n",
       "      <td>41554.0</td>\n",
       "      <td>29885.86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step    amount  oldbalanceOrg  newbalanceOrig  oldbalanceDest  \\\n",
       "0     1   9839.64       170136.0       160296.36             0.0   \n",
       "1     1   1864.28        21249.0        19384.72             0.0   \n",
       "2     1    181.00          181.0            0.00             0.0   \n",
       "3     1    181.00          181.0            0.00         21182.0   \n",
       "4     1  11668.14        41554.0        29885.86             0.0   \n",
       "\n",
       "   newbalanceDest  isFraud  isFlaggedFraud  \n",
       "0             0.0        0               0  \n",
       "1             0.0        0               0  \n",
       "2             0.0        1               0  \n",
       "3             0.0        1               0  \n",
       "4             0.0        0               0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6354407\n",
      "1       8213\n",
      "Name: isFraud, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create data frame containing your data, each column can be accessed # by df['column   name']\n",
    "dataset = pd.read_csv('./input/PS_20174392719_1491204439457_log.csv')\n",
    "del dataset['nameDest']\n",
    "del dataset['nameOrig']\n",
    "del dataset['type']\n",
    "display(dataset.head())\n",
    "print(dataset['isFraud'].value_counts())\n",
    "\n",
    "def feature_normalize(dataset):\n",
    "    mu = np.mean(dataset, axis=0)\n",
    "    sigma = np.std(dataset, axis=0)\n",
    "    return (dataset - mu) / sigma\n",
    "\n",
    "def init_data():\n",
    "    #Splitting the Training/Test Data\n",
    "    from sklearn.model_selection  import train_test_split\n",
    "    \n",
    "    X, y = dataset.iloc[:,:-2], dataset.iloc[:, -2]\n",
    "    y = keras.utils.to_categorical(y, num_classes=2)\n",
    "    X = feature_normalize(X.as_matrix())\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
    "    #print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)\n",
    "    #print(y_train[:5])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def conf_matrix_jupyter(model, X_test, y_test, LABELS = ['Normal','Fraud']):\n",
    "    from sklearn import metrics\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    sns.set(font_scale=2)\n",
    "    predictions = model.predict(X_test, batch_size=1000)\n",
    "\n",
    "    max_test = np.argmax(y_test, axis=1)\n",
    "    max_predictions = np.argmax(predictions, axis=1)\n",
    "    confusion_matrix = metrics.confusion_matrix(max_test, max_predictions)\n",
    "\n",
    "    plt.figure(figsize=(5, 5))\n",
    "    sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\", annot_kws={\"size\": 20});\n",
    "    plt.title(\"Confusion matrix\", fontsize=20)\n",
    "    plt.ylabel('True label', fontsize=20)\n",
    "    plt.xlabel('Predicted label', fontsize=20)\n",
    "    plt.show()\n",
    "    \n",
    "def binary_classification_train_demo(X_train, X_test, y_train, y_test, activation='sigmoid', loss='binary_crossentropy'):   \n",
    "    import tensorflow as tf\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "\n",
    "    K.clear_session()\n",
    "    model = Sequential()\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    nb_classes = y_train.shape[1]\n",
    "\n",
    "    model.add(Dense(10, input_dim=input_dim, activation='relu', name='input'))\n",
    "    model.add(Dense(20, activation='relu', name='fc1'))\n",
    "    model.add(Dense(10, activation='relu', name='fc2'))\n",
    "    model.add(Dense(nb_classes, activation=activation, name='output'))\n",
    "\n",
    "    model.compile(loss=loss, optimizer='nadam', metrics=['accuracy'])\n",
    "    model.fit(X_train, y_train, epochs=3, batch_size=1000)\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, batch_size=1000)\n",
    "    print(model.metrics_names, score)\n",
    "\n",
    "    conf_matrix_jupyter(model, X_test, y_test, LABELS = ['Normal','Fraud'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid + Focal Lossなし\n",
    "- うまくいってる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5090096/5090096 [==============================] - 24s 5us/step - loss: 0.0098 - acc: 0.9989\n",
      "Epoch 2/3\n",
      "5090096/5090096 [==============================] - 23s 5us/step - loss: 0.0039 - acc: 0.9993\n",
      "Epoch 3/3\n",
      "5090096/5090096 [==============================] - 23s 4us/step - loss: 0.0034 - acc: 0.9993\n",
      "1272524/1272524 [==============================] - 2s 1us/step\n",
      "['loss', 'acc'] [0.0032575988104764524, 0.999337150769447]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = init_data()\n",
    "binary_classification_train_demo(X_train, X_test, y_train, y_test, activation='sigmoid', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid + binary_Focal_Lossあり\n",
    "- うまくいってるが、2nodeだからか全然精度は上がってない（sigmoidだから本来は1nodeでやるべき）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5090096/5090096 [==============================] - 24s 5us/step - loss: 2.6903 - acc: 0.9979\n",
      "Epoch 2/3\n",
      "5090096/5090096 [==============================] - 23s 5us/step - loss: 1.0074 - acc: 0.9993\n",
      "Epoch 3/3\n",
      "5090096/5090096 [==============================] - 23s 5us/step - loss: 0.9085 - acc: 0.9994\n",
      "1272524/1272524 [==============================] - 2s 1us/step\n",
      "['loss', 'acc'] [0.8610878719367148, 0.9993752639069762]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAakAAAFnCAYAAAAczrafAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzs3XdUVNfawOEfXRQIRgERqRrAiooSMZHYY0ONxsSOsReSG2ONUWNJPmNijSV2RQ3kGlEvdkWNmoiCBUTsihVRQFFRkDLn+4M7cxlnBmdGhEH2s9asJefs95w9o87L3mcXI0mSJARBEATBABmXdAUEQRAEQRORpARBEASDJZKUIAiCYLBEkhIEQRAMlkhSgiAIgsESSUoQBEEwWCJJlWHr16+nQ4cO1KtXDy8vL9atW/fG79myZUtatmz5xu9TlvTr1w8vL6+SroYgvBGmJV2BsuDatWuEhoZy4sQJ7t27x4sXL7C1taVWrVq0adOGzp07Y2FhUax12rlzJz/++CO1atUiKCgIc3Nz6tevX6x1EPJ5eXnh5+fHhg0bSroqgmBwRJJ6wxYvXsySJUuQyWTUr1+fTz75hPLly5Oamkp0dDSTJ08mLCyMLVu2FGu9Dh06BMCyZctwcHAotvsWR2utrJk9ezaZmZklXQ1BeCNEknqDli1bxqJFi3B0dGThwoX4+PiolDl06BBr1qwp9ro9ePAAoFgTFICLi0ux3q8sqFq1aklXQRDeGPFM6g25c+cOixcvxszMjBUrVqhNUAAtWrRg9erVKsd37dpFnz598PX1pV69egQGBrJ8+XKys7NVysqf82RmZjJ79myaN29OnTp1aNOmDStWrKDgyleLFi3Cy8uLEydOAPldTfKXvN5eXl5MnDhRbX3VPf+QJImtW7fSs2dPmjRpQt26dfnoo48YNGgQu3btUlvXl2VnZ7NixQoCAwPx8fGhYcOG9O7dWyX+5TreuXOH0aNH8/7771O3bl26deumaCVqy8vLi379+pGamsq3335L06ZNqV+/Pj179uTkyZMAPH/+nNmzZ9OiRQvq1KlDx44d2b17t8q1nj59yqpVq+jfvz8BAQHUqVOHJk2aMHz4cGJjY5XKbtmyRfFZRkdHK/1dLFq0SOW9JiYm8vXXX+Pv74+3t7fi7/Dlv5Ps7Gy6d++Ol5cXBw4cUKnjuHHj8PLyYunSpTp9ToJQEkRL6g3ZsmULOTk5dOzYEU9Pz0LLmpubK/08b948li9fTsWKFenUqRPly5fn6NGjzJs3j7///ps1a9ZgZmamFJOTk8PAgQN58OABAQEBmJiYEBkZydy5c8nOziY4OBgAPz8/goOD2bp1K3fv3lUcfx3z589n+fLlVKtWjfbt22NtbU1KSgrx8fHs2bOHDh06FBqfnZ3NoEGDiI6OxsPDg969e5OVlcXevXsZPXo0Fy9e5JtvvlGJu3v3Lj169MDZ2ZkuXbrw+PFjdu3axciRI1m7di1NmjTR+j08efKEXr16UaFCBTp27Ki41qBBg/j3v//N1KlTefz4Mc2bNyc3N5cdO3YwevRoHB0dlZ7lXbt2jQULFtCoUSOaN2+OjY0N9+7d4+DBgxw9epTffvuNgIAAAGrWrElwcDCLFy/GycmJTz75RHEdPz8/pfrdunWLzz77DDc3NwIDA8nKysLKykrtezE3N2fBggV07dqVSZMmsW3bNhwdHQEIDw8nIiJCkTgFweBJwhvRv39/ydPTU9q0aZNOcadPn5Y8PT2ljz76SHrw4IHieE5OjjRs2DDJ09NT+u2335RiWrRoIXl6ekqDBw+WMjMzFcdTU1MlX19fydfXV8rOzlaK6du3r+Tp6aly/9u3b0uenp7ShAkT1NZPXZyfn5/UrFkz6fnz5yrl09LSVOraokULpWPLli1T1D8nJ0ep/vL3durUKZU6enp6SosWLVK61pEjRxTX0pb8WlOmTJHy8vIUx7du3Sp5enpKjRs3loYNGyZlZWUpzsXExEienp7SyJEjla715MkTlfcsSZJ079496YMPPpDatWun9v59+/ZVW7eC73Xu3Llqy2j6u9y5c6fk6ekp9erVS8rNzZWuXr0q+fj4SP7+/kr/tgTBkInuvjckJSUF0P2ZT3h4OAAjRozAzs5OcdzU1JQJEyZgbGzMn3/+qTZ28uTJlCtXTvFzpUqVaNWqFU+fPiUxMVHXt6ATU1NTTExMVI6/++67r4wNDw/HyMiIiRMnYmr6v8Z9pUqVGDFiBIDa9+zk5KQ4L9esWTOqVq3K2bNndaq/paUl48ePx9j4f/8lAgMDMTU15fHjx3z33XdKIzAbNWqEk5MTFy5cULqOtbW12vdcpUoV2rVrx/Xr10lKStKpbgCVK1fWudXboUMHPv/8c06dOsWcOXP4+uuvycrK4ueff1b6tyUIhkx0970h0n+fAxkZGekUd/78eQC1XVXu7u5UqVKFO3fu8OTJE2xsbBTnrK2tcXV1VYmpUqUKkN+d9aYEBgayYcMGOnbsSLt27WjcuDENGjTA2tr6lbEZGRncvHkTBwcHqlevrnJe/jm8nAwAvL291SbGKlWqqDz/eRU3NzeV7jMTExMqVapEZmYmzs7OKjEODg5qk+GpU6dYv349sbGxpKWlkZOTo3T+/v37Og928Pb2VukW1sZ3333HmTNnFINzhg0bxocffqjzdQShpIgk9YbY29tz/fp1kpOTdYp7+vQpgMbfdO3s7EhKSuLp06dKSargnwuSt0zy8vJ0qocuvv32W5ydnQkPD2fFihWsWLECU1NTAgICmDhxotrkKZeRkQFofr/29vaA+iRb2HuWyWQ6vQdNCdXU1LTQc7m5uUrH9u/fz1dffYWFhQVNmzbFxcUFS0tLjI2NiY6OJjo6Wu3gl1epXLmyzjEAFhYWNG/enMuXL2NqakqfPn30uo4glBSRpN4QX19fjh8/zvHjx+nRo4fWcfIvxNTUVLXDteXdiNq0UvQh7+56+ctXTl2yMDExISgoiKCgINLS0jh16hQ7d+5kz549XL16lZ07d2psBchbL6mpqWrPy4fKv6n3W9QWLlyImZkZ4eHhKi3DqVOnEh0drdd1dW2Ry508eZLVq1dTsWJFHj16xKRJk1i1apXe1xOE4iaeSb0h3bp1w8zMjL1793L16tVCyxb8zbpmzZoAiuHFBd28eZPk5GSqVaumsRXxuuTXVdcCzMjI4MaNG4XGV6pUibZt27Jw4UKaNGnCrVu3uHz5ssbyVlZWuLi4cP/+fbXXln8OtWrV0v5NlKCbN29So0YNlQQlk8k4deqU2hhjY+M30tJNT09nzJgxmJqaEhISQmBgIH///TcrV64s8nsJwpsiktQbUq1aNYKDg8nJyWHo0KHEx8erLXfkyBEGDx6s+Ll79+4A/Pbbbzx8+FBxPC8vj9mzZyOTyfj000/fWL2trKzw8PDg9OnTSsk1Ly+PWbNmkZWVpVQ+OzubqKgopblYkD8k/vHjx0D+oITCdO/eHUmS+Pnnn5W+rB8+fKiYyyP/XAydk5MTN27c4P79+4pjkiSxePFijb+s2Nra6twtrI2JEyeSnJzMt99+i5eXF9OnT8fNzY2FCxdy+vTpIr+fILwJorvvDRo+fDi5ubksWbKETz/9lAYNGlCnTh0qVKhAamoqJ0+e5MaNG9SpU0cR07BhQwYPHsyqVavo1KkTH3/8MZaWlhw9epTLly/j6+vLoEGD3mi9Bw0axHfffUevXr1o164dFhYWnDhxgpycHLy9vbl48aKibFZWFgMGDMDJyQkfHx+qVq3KixcvOHbsGNeuXaNly5ZqB0QUNHDgQI4cOcKBAwfo0qULAQEBZGVlsWfPHtLS0hg8eDCNGjV6o++5qAwYMIDvv/+eTz75hLZt22Jqasrp06e5du0aLVq0UDvR2N/fn507dzJ8+HBq166NiYkJjRs3pnHjxnrXY926dRw6dIi2bdvSq1cvACpUqMC8efP4/PPPGTNmDNu2beOdd97R+x6CUBxEknrDgoODad++vWKB2S1btpCdnY2trS3e3t4MHjyYLl26KMWMGzeOWrVqsXHjRrZt20Zubi4uLi58/fXXDBw4UK9RXrr49NNPkSSJdevWsXXrVt555x1atWrF6NGj+eqrr5TKWlpaMnbsWE6cOMGZM2eIjIykQoUKuLi4MG3aNK1aQObm5qxdu5a1a9eyY8cONm7ciImJCd7e3kyaNIlOnTq9qbda5Hr27Im5uTkhISFs27YNCwsLGjVqxKxZs9i3b5/aJPXdd99hZGREVFQUhw8fRiaTERwcrHeSOnfuHHPmzMHJyYkff/xR6Vzt2rUZP348P/74I99++61YdUIweEbSy/00giAIgmAgxDMpQRAEwWCJJCUIgiAYLPFMShCEMu/69escPXqU+Ph4zp07x40bN5AkiYULF9KuXTuV8jk5OZw8eZLDhw9z+vRpkpKSSE9Pp2LFijRo0IA+ffrw/vvvq73XxIkT2bp1q8a6uLu7s2fPHrXnZDIZYWFhhIeHk5iYiLGxMV5eXvTu3fuVz263b99OWFgYly5dQiaT4e7uTvfu3enVq5fScmAvO3LkCOvWrePcuXO8ePECZ2dnOnbsyKBBgwp9Ph4XF8eKFSs4ffo0GRkZODo60rp1a0aMGKHTvEeRpARBKPPCwsJYv3691uVjYmL44osvgPzVUmrXro2lpSXXrl1j79697N27l5EjR/Kvf/1L4zUaNmyodjUWTauv5OXlERwczMGDB7GysuKDDz5QTAEZM2YMsbGxTJ48WW3s9OnTCQ0NxcLCAn9/f0xNTYmKimLGjBlERUWxcOFCtUuMrVy5kjlz5mBiYoKfnx82NjbExMSwYMEC/vrrL9atW6d2ismOHTsYP348eXl5NGzYEAcHB+Li4li9ejWRkZGEhYVRqVIljZ+NkpJb21YQBMEwbNq0SZo9e7a0c+dO6ebNm4qV5Xfv3q22/LFjx6Qvv/xSiomJUTm3c+dOqWbNmpKnp6cUFRWlcn7ChAmSp6enFB4erlMdV69eLXl6ekodOnSQUlJSFMcTExOlpk2bSp6entL+/ftV4vbs2SN5enpKH3zwgZSYmKg4npKSIrVv317y9PSU1q1bpxJ39uxZycvLS/Lx8ZFiY2MVxzMyMqQ+ffpInp6e0o8//qgSd+/ePalevXqSt7e3Un1ycnKkr7/+Wu3uAYUpcy2pnNTrJV0FQU+WVZuVdBWE15CbfVevOH3+z5pV9tCpvC5Ll0H+3DZ/f3+15zp06MA///zD5s2bFXt3va68vDxWrVoFwLRp05TWcnRzc2Ps2LFMnDiRZcuW0bp1a6XY5cuXAzB27Fjc3NwUxytXrsy0adPo168fK1eupF+/fkrdfitXrkSSJAYPHqy0aWuFChWYNWsWbdu2JTQ0lODgYKUVcEJCQsjKyqJbt25KdTE1NWXmzJkcOXKEyMhIrl69So0aNV753sXACUEQDJssT/dXCZMv41Vw5ZHXcebMGdLS0qhSpYra+XPt2rXDzMyM+Ph4pXsmJyeTkJCAmZmZ2mdrfn5+ODg4kJKSorRzQHZ2NkeOHAGgc+fOKnHOzs7Ur1+fnJwcDh8+rHQuMjJSY5yVlRUtWrRQKvcqIkkJgmDYJJnurxImX4eysH27Tpw4waxZs5gyZQoLFizg6NGjGlfvl29VU7duXbXnLS0tFa2SgtvayLf+ee+995T2mitIfs2CcYmJiWRmZmJra6t2oeuCcfJ7QP76nrdu3Sq0ruriClPmuvsEQShldNx2BfJX69e0vcubWpxZLiUlRTF6r23bthrLbdu2TeVYjRo1mDdvHl5eXkrH79y5A1DoPmSOjo5cuHBBUVaXuIJlC/5Zfk4d+TXv3v1fN648zsbGRmV/tpfjCt6vMCJJCYJg0CQ9WkYhISEsXrxY5XhwcDBffvllUVRLrdzcXMaNG8fTp0/x9/enZcuWKmW8vb2ZPHky/v7+VK1alYyMDM6fP8/8+fO5ePEiX3zxBVu3blXa1fv58+dA4Ys1ly9fHoBnz57pFFehQgW94vS9n7q4wogkJQiCYdOjJRUUFMQnn3yicvxNt6K+//57oqKicHR05JdfflFbZsCAAUo/ly9fHnt7e5o2bUq/fv2IjY1l+fLlTJ06VVFG0nOn79ISVxiRpARBMGx6tKSKo1vvZT/88AObN2/Gzs6OdevWFfo8Sh1zc3OGDh3KyJEjVQYjyFs78paKOvJz8rLaxslbNLrG6Xs/dXGFEUlKEATDZgCj9V7lp59+YsOGDbz77rusW7dOaai3Ljw88ofOvzwq0MnJCYCkpCSNsfI9yeRliyLu3r17GuPk5wrGVatWDch/JpiRkaH2uZQ8Tl72VcToPkEQDJuBj+77+eefWbt2Lba2tqxdu1aruT+apKenA6qtDPmQdk2bp2ZmZnLlyhWlsgX/fOXKFZUNS+Xk15TvCg75ybJcuXKkp6crRuu97OzZsypx8p22C6ururjCiCQlCIKgpzlz5rB69Wreeecd1q5di7e392tdb/fu3QBKG6ECNGjQgEqVKpGcnExMTIxK3J49e8jJyaFu3bpKAy4cHR2pXbs2OTk5atcDjI6OJjk5GTs7Oxo0aKA4bm5uTkBAAAAREREqcbdv3yY2NhYzMzOaN2+udK5Vq1Ya4zIyMhR7qrVp00btZ/AykaQEQTBsMpnur2KwYMECVq5ciY2NDWvWrFFqwWhy4cIFDh06RF6echdmbm4ua9euZcOGDYDq4AoTExPFjtzTpk0jLS1Nce7GjRvMnTsXyN8N/GVDhw4F8hPqzZs3FcfT0tKYPn06AEOGDFFZZHbIkCEYGRmxatUqResH8p9hTZo0CZlMRu/evVWe/QUFBVGuXDm2bdvGgQMHlN7j1KlTycjIoHXr1lq3OMvcpodiWaTSSyyLVLrpuyzSi2vHdY6xqK7bUkQJCQmKL2yAq1ev8uzZM9zc3HjnnXcUxzdt2gTAgQMHGDlyJJDf6nnvvffUXtfDw0ORJCB/lYVRo0Zha2uLm5sbDg4OPHv2jMuXL/PgwQOMjY355ptvGDJkiMq18vLyGDVqFIcOHcLKygp/f39yc3M5duwYL168oF+/fhoXmJ02bRphYWFYWFjQtGlTxQKz8oTx66+/vnKB2SZNmmBtbU1MTAxpaWn4+PgQEhJS6AKzMpkMX19f7O3tiYuL4+7du7i6uuq0wKxIUkKpIZJU6aZ3krpyTOcYi/ea6lT+xIkT9O/f/5XlLl26BMCWLVv49ttvX1nez89P0TqC/G6y9evXEx8fz927d0lPT8fIyIgqVarg6+tLnz59VLr6CpLJZISGhrJlyxauX7+utFVHYGBgoXXZvn07v//+O5cvX0Ymk+Hh4aH1Vh1r165V2qqjU6dOWm3VsXz5cqWtOtq0aaPzVh0iSQmlhkhSpZveSery3zrHWHh+qNe9BMMjhqALgmDYSsEQdOHNEUlKEATDZgALxgolRyQpQRAMWzGN1hMMk0hSgiAYNtGSKtNEkhIEwbCJllSZJpKUIAgGTZLEwImyTCQpQRAMm+juK9NEkhIEwbCJ7r4yTSQpQRAMm2hJlWkiSQmCYNjEZN4yTSQpQRAMm2hJlWkiSQmCYNjEM6kyTewnJQiCIBgs0ZISBMGwie6+Mk0kKUEQDJvo7ivTRJISBMGwiSRVpokkJQiCQRPLIpVtIkkJgmDYREuqTBNJShAEwyYGTpRpIkkJgmDYREuqTBNJShAEwyZaUmWaSFKCIBg20ZIq00SSEgTBsImWVJkmkpQgCIZNtKTKNJGkBEEwbCJJlWkiSQmCYNhEd1+ZJpKUIAiGTbSkyjSRpARBMGyiJVWmiSQlCIJhEy2pMk1seigIgiAYLNGSEgTBsInuvjJNJClBEAyb6O4r00SSEgTBsIkkVaaJJCUIgmGTpJKugVCCRJISBMGwiZZUmSaSlCAIhk0kqTJNJClBEAxbMYzuu379OkePHiU+Pp5z585x48YNJEli4cKFtGvXrtDY7du3ExYWxqVLl5DJZLi7u9O9e3d69eqFsbHmWT5Hjhxh3bp1nDt3jhcvXuDs7EzHjh0ZNGgQ5ubmGuPi4uJYsWIFp0+fJiMjA0dHR1q3bs2IESOwtrYu9D0uXbqU48ePk56ejp2dHQEBAYwaNQp7e3uNcffv32fp0qUcOXKElJQUbG1t8ff3Z+TIkbi7u2uMe/r0Kb/99huRkZHcu3cPKysrGjZsyLBhw6hXr57GuJcZSVLZ6vDNSb1e0lUQ9GRZtVlJV0F4DbnZd/WKy1z/rc4xlv1n6VT+xx9/ZP369SrHX5Wkpk+fTmhoKBYWFvj7+2NqakpUVBTPnj2jTZs2LFy4EBMTE5W4lStXMmfOHExMTPDz88PGxoaYmBgePnxI/fr1WbduHZaWlipxO3bsYPz48eTl5dGwYUMcHByIi4sjKSkJV1dXwsLCqFSpkkpcdHQ0Q4YMISsri9q1a+Pq6srFixe5fv067777LqGhoWoTzrVr1+jduzfp6el4eHjg7e3NzZs3SUhIwNLSktWrV+Pr66sSl5KSQq9evbh9+zZOTk7Uq1eP+/fvc/r0aUxMTJg7dy7t27fX+LkWJJKUUGqIJFW66Z2kQibqHGMZ9JNO5f/8808SExOpU6cOderU4bvvviM6OrrQJLV3716++uor7Ozs2LhxI25ubgCkpqbSv39/rl27xqRJkwgKClKKi4+Pp0ePHpQrV46QkBB8fHwAePbsGcOGDSMmJoagoCAmTZqkFJecnMzHH39MdnY2ixYtonXr1gDk5uYybtw4du3aRevWrVmyZIlS3PPnz2nbti0pKSlMmTKFvn37Ks7Nnj2bNWvWULt2bcLDwzEyMlKck8lkfPLJJ1y8eJGBAwcyYcIExbkNGzbwww8/YG9vz759+1QS6vDhwzl06BAdO3bk559/xtQ0v9MuMjKSL7/8EgsLC/bu3YuDg8Mr/27EihOCIBg2mUz3l4569OjB+PHj6dChAy4uLlrFLF++HICxY8cqEhRA5cqVmTZtGpDfYpK9VJ+VK1ciSRKDBw9WJCiAChUqMGvWLIyNjQkNDeXJkydKcSEhIWRlZdG1a1dFggIwNTVl5syZWFlZERkZydWrV5XitmzZQkpKCn5+fkoJSl53FxcXEhISOHLkiNK5w4cPc/HiRVxdXRk7dqzSuX79+uHn58eDBw/YsmWL0rnLly9z6NAhrKysmDFjhiJBAbRu3ZquXbuSmZlJSEiIymeqjkhSgiAYtmJIUrpKTk4mISEBMzMztS0tPz8/HBwcSElJITY2VnE8OztbkQw6d+6sEufs7Ez9+vXJycnh8OHDSuciIyM1xllZWdGiRQulctrEmZiY0KFDh0LjOnTooLbLUn69AwcOqI1r2bIlVlZWKnGBgYFq4zQRSUoQBMMmyXR/vWHnz58H4L333qNcuXJqy9StWxeACxcuKI4lJiaSmZmJra2txhabPE5+D4CMjAxu3bqldF6buIL3N5Q4+aCJmzdvkpGRobZMQWJ0nyAIBk2S6f7Y/MmTJyrdZQA2NjbY2Ni8dp3u3LkDQNWqVTWWcXR0VCpb8M/yc+rIr3n37v+e4cnjbGxs1LZOCsYVvF9GRgbp6ekAODk5aR1X8GdNcfL38OjRI549e0aFChWU4jR9NlZWVlhZWZGRkUFSUhKenp5qy8mJJCUIgmHTo/suJCSExYsXqxwPDg7myy+/fO0qPX/+HEDtCDw5+Zf2s2fPdIorX758kcUV/LOmWHVx2txTHiePlb9feVzB8+piMzIyVO6pjkhSgiAYNj2674KCgvjkk09UjhdFKwpAPii64Gg4Q4wrCpruqel4UddVJClBEAybHt19RdWtp8nLrQZ15K0EeVlt4+TnijIOIDMzU+1kX3VxkN/aefz4scZ7FmwFqbtnYa0kTfdURyQpLew7dJSTZ+K5eOU6l65e59nzTDq2bcHs78erlL15+y6Rh//hnxOnuXnnLmkP07GxtsKntjf9PuuKn6+PSkzb7kEkJT8otA7Bg/sx/IveSseyXrxg1YZN7Ik8TNL9B1iVL0/jhvUYOagv1d2UH8pGnz7LwC8n8Cr7t6zH0cFO8XOdDzRPuKtXy4vQlQt0us+gvj0YPWLgK+tR2nTr1pGAZk2o71ObevVqYWNjze+h4QQN+EqlbI0a7nzStT1t2zSnRg13HBwq8+jRY05En+bXX1fx1+FjKjFN/RvRufPHfPRRU9xcnbGxsSIp6T4HD/3Nz78s4dq1G8XwLgU5+XOapKQkjWWSk5OVyhb887179zTGyc8VjKtWrRqQ/6wtIyND7XMpeZy8LOQ//7G1tSU9PZ27d+/i7e2t1f3kPz9+/PiVcba2tkrJxsnJifPnz2v8bDIyMhQDJgp7picnkpQWlq/7g0tXr1Pe0hIH+8ok3rytseyilevZc+AI1d1cCPBvjI21NTdu3eGvf45z6O/jTPx6OH17dFGK6fdZV55kqP7WIUkSqzZsIjc3lw+bNFI6l52dzZCvJ3Hm7Hlqe79H3x5dSH6Qyr6DRzlyLJrVv/5Evdr/+4fl5OjAiIF91Nb5yrUbRB7+hxrurkoJSq5qFXu6dGijctzBrrLGz6FRg7o0bqC69EnDerU1xpRmk779F/V9avP0aQZ37t7Dxkbz8jTTp43j88+6kHD+Erv3HOTRo0d4elYnsFNbOgd+zNejp7B4yRqlmE3/XomdXSWiok4SGraVvNxcmjTxZdDA3nz+WRfate/F8ROn3vTbLBkGuHZfrVq1ALhy5QpZWVlqR/jFx8cDULNmTcUxDw8PypUrR3p6Ordu3VI7wu/s2bMqcVZWVri4uHDr1i3i4+Px9/fXKk7+c1RUFPHx8WqTjTxO/p4Kvsfz588THx9Pq1atNL4/dXH79+9XnNd0P1dXV42DQAoSSUoLE74aioN9ZVyqVSXmTHyhLYUP32/EoL49qOlZQ+l4zJmzDPn6O+YuWcXHLZphV/ldxbl+n6v2nQP8c+IUubm51PSsTp2ayiNgQv7Yypmz52nb4kPmzPhWsUZYu1YBfDVxBlP+bz5bN/ymOO7k6MCoQX1V7gEw7vv82fmfdlHfaqpaSKwmjRvU0zlG1d24AAAgAElEQVSmNBs7dhp37t7j6tVEPgrw50DkZo1l9+79i1/mLCE2NkHpeECzJuzZHcbsnyazOXwHyQVa1wt/XcnG38O5d+++UszECV/yw8yJ/PbbbBo0bM1byQCTlKOjI7Vr1yYhIYE9e/bQtWtXpfPR0dEkJydjZ2dHgwYNFMfNzc0JCAhg3759REREEBwcrBR3+/ZtYmNjMTMzo3nz5krnWrVqxdq1a4mIiFBJUhkZGRw6dAiANm3aqMRFRUWxfft2evTooXQuLy+PXbt2aYzbvHkzu3bt4ssvv1SZKxUREQGgNLFYHrdw4UIOHjyottW3fft2tXGaiHlSWvDz9cHV2UmrB4FdO7ZRSVCQ/6XduEFdcnJyiY0/ryZS1Z//2Q1Ajy4dlI5LksSmbfn/sL4ZOUhpEcuWzfzx9anDtRu3OHlG/W8yBaU/fsKBI8coZ2FB4McttaqXoOqvw8e4ejVRq7LrN2xSSVAAR44e5/DhqP+uA6fccv5lzlKVBAXw8y9LeP48k7p1avLuuxX1q7yhkyTdX8Vg6NChAMyZM4ebN28qjqelpTF9+nQAhgwZorLI7JAhQzAyMmLVqlWKVgXkP8OZNGkSMpmM3r17qzxTCwoKoly5cmzbtk1pImxubi5Tp04lIyOD1q1bU6OG8vdPt27dsLOz48SJE/z+++9K5+bMmcOtW7eoVasWAQEBSueaN2+Ol5cXN2/eZO7cuUrnNm7cSHR0NPb29nTr1k3pnJeXF82bNycjI4OpU6eSm5urOBcZGcm2bduwtLRUWS5KE9GSKkby5UFMTFVnb78s9eEj/vrnBOUtLenYprnSudt373Hv/gPcnJ2oVrWKSuyHTRpxKu4cJ07FqX0GVtC2XfvJzs6hc7tWvKOhi+rp02ds2bGX1LRHWFtVoJZXDXzq1FRbVu7WnSRCN0eQ8ew5lStVxNenDq7O6udbCP+Tk5P/H7rgf+zCSJKkKJuXl/fG6lWiiqEllZCQoEgsgGJpofnz57Nmzf+6Xjdt2qT4c7t27ejVqxdhYWEEBgbStGlTxQKz8oTx8jJEkD+ZdcyYMcyZM4eePXvSpEkTrK2tiYmJIS0tDR8fH0aPHq0S5+joyI8//sj48eMZNWoUvr6+2NvbExcXx927d3F1dWXGjBkqcRUqVGDevHkMGTKEGTNmEB4ejpubGxcvXuTatWtUrFiRuXPnqvwSbmxszPz58+nduzerV6/mr7/+wtvbmxs3bpCQkEC5cuWYP3++2iHqP/zwA7169WLnzp3Exsbi4+OjWGDW2NiY//u//9Nq3T4QSarYJCXf58SpWCzLWeDrU+eV5bfu2Edubi5dO7SmQgXl+QaJt/Iny7m6qP/Sd3XOfxh54/arF/QM374XgB5dO2gsc+nqdabOUh4g4VXDg1lTx+JZXf1S/Tv3HWLnvkNKx9o0/4BpE/6lMRmWdS4uTrRs+QHPnj3n6NETWsV8+mkgNjbWHD9+isePVSevvhX0GN2nq4yMDOLi4lSO37hxo9C4adOm4evry++//050dDQymQwPD49XbtUxZMgQvLy8WLt2LfHx8YqtOvr161foVh2dOnXC2dmZ5cuXc/r0aeLi4nB0dGTQoEGFbtXh5+fH1q1bWbJkCcePH+fy5ctUrlyZzz//nODgYI1bdVSvXp2IiAiWLFnCkSNH2LdvH7a2tgQGBjJq1CiNW3XY2dmxZcsWxVYd+/fvx8rKipYtWzJ8+HCdtuoo0ST18gM+XRgZGaksx2GosrOzmTD9Z7Kzc/hm5KBXfklLkkT49j0AfNpZ9TlRxn8HWVhpGL4pP/70FUuOxJw5S+LN29Rwd6VB3VpqywT17Ebr5h/g5uyEhbk512/eZs3vf7Lv0N8M+moim9ctURpA8a7tO4we8QUBTf1wquLAi+xsEi5eYeHydez/6x9SHz4iZMkvhe6zUxaZm5uzIWQx5cqVY8LEmaSnP35ljJubMwvnzyQnJ4dx41V/g35rFMMyR++//z6XLl3SKzYwMFCxHp0uAgICVLrYtOHj48PSpUt1jvPw8FDpttOGg4OD2hbaq9jY2DBhwgSl1dP1UaLfFJIk6f16eWVhQ5WXl8e3M+dw5ux52rUK4Ive3V8ZExVzhjtJydTyqqEyYEIb2k6m26x45qV5mPm4L4fQoG4tKtq+Q/nyltSp6cm8H76jTfMPeJT+hHWh4Urla3i4MqjvZ7zn4Ub58pZUtH2HD5s0Yu3i2VSrWoUzZ8/z1z/atRLKCmNjY0LW/coHH/jx703/Ye68Za+MsbOrxI7tG7G3r8zob74n6vjJYqhpCZFJur+Et0aJtqQuXrxYkrd/4/Ly8pg44xf2HjzKxy0D+GnqeK0GX2yOyE8e6lpRAFZW+S2lDA2T5Z79d6KcppYWwOMnT9l/+J/8ARPtVIeXvspnXTuy/69/OBV3TqvyVhUq0KFNc1aE/MGp2HO0bKY6hLYsMjY2Zn3IInp8GsimPyPoH/TqJXvs7Cqxf98mvL1q8PXoKSxbrt2WB6WVVEp+IRXeDPFM6g3Jzc1jwvTZ7D14lI5tmvN/U8aqXe7+ZWmP0jl49LjaARNy7i75k/Vu3lL/zOnm7fxJdG6FDFT4z65IsrNz6NK+NTbWr56r8LKKtu8AkJmZpXPMcx1i3mYmJiZs3LCEHp8GEhq2hQFf/OuVPQRVqtizb++/8faqQfCXk976BAWIllEZJx4MvAE5OTl8M/lH9h48Sud2rZg1dZxWCQpg2878ARMd2nykMmBCztnJEUcHe27cvsudpGSV83//t+vn/UJG9m3e/t/WWiFdfYU5m5DfClY3uvBVMc5O2se8rczMzNj07xX0+DSQ9Rv+JGjAV69MUE5Ojhw8EI63Vw1GjppYNhIUGORWHULxEUmqiGVnZ/PVtzM5eDSKbp0+5ofvvtF6kED+gIn/jrbronm0nZGREZ/9dzTevKWrlb7cDh6N4lTcOaq7udCogfr9XE7FnuP6jdu85+GmccAEwPlLV9W2ei5dTeTXFflfkJ1emlt1+myC2i/b7XsPsufAEczMTPm4pe4Pi98m5ubmhP+5mi6d27F6TSiDBo9WPEfUxNm5KgcjN1Pdw5UhQ8ewavXvhZZ/q4hnUmWaQXb37d69m71793Ljxg0yMjLU/gc2MjJS2UnyTTlw5BgHj0QB+fOXAOLOXeC7H/JHytja2jAueAgAM35ZzNGoGCra2mBvV4nf1oaqXK9xg3r4NVQdgnniVCy37iRRy6sGtb3fK7ROQT0/4fCxaPYd+pteQ76mSaP63Lufwr6DR7EsZ8HMSaM1Jsc/Fc+8VHcULej3P/9D5OF/eN+3PlXsK2NmbkbizTv8c+IkeXkyPu3cjg4vdUlOnP4zMkmifp2aONhXJvtFDucuXib+/CVMTUz4ftxXODlqNz+iNOnc+WO6/PfzrPLfpaWavO/L6lXzAUhLfcj4iTMBWLrkJzp0aEVKShpJSclMmaw6J+bw4SgO//ffHMDByHDc3V04eSoOV9dqTJ3yjUpMyPpN3Lx5R+V4qSeeSZVpBpWkZDIZX331FQcOHND4m6WRkRGSJBXrkvUXr1znP7uVE+KdpGRFV1vVKvaKJHXnXv6xR+lPWKYmQQEwELVJ6s//aB52/jJzc3NWLfw/Vm3YxK79f7H+31uxqlCelgH+jBrUl+rurmrjHj95yv5Df2s1YKJlgD8Zz55z+VoiJ07F8iI7B9t3rPmwSSM+DWxPi2ZNVGI+/6QjUTGxnIk/T3r6EyQk7CtXomuHNvT9rCve73m88r2VRvV9ahPU/zOlY9Wru1G9uhsAN27cViQpdzdnIH8AxJTJqskGYAZzlZKUu3v+Gm+NfH1opKEb9/DhqLc0SYmWUVlmJL2qn6EY/f7778ycOZOaNWsybtw4/vjjD/bv38/u3bu5efMmERER7Nq1i6FDh/LZZ59p3DGyMDmp199AzYXiYFm1WUlXQXgNudmvnlyuzrMpn7260EsqzNz06kJCqWBQLamIiAgsLCxYuXIllStXVixE6ObmhpubGx999BFNmzZl8uTJ+Pn56ZWkBEEoZURLqkwzqIET165do379+lSurLwFRMHGXvfu3alRowarV68u7uoJglACJJlM55fw9jCoJJWdna2UoCwsLAB4+vSpUjlPT08SElRXkRYEQRDeLgaVpOzs7EhNTVX8LE9Y168rP0dKTU0lJyenWOsmCEIJEUPQyzSDSlLu7u7cunVL8XODBg3yd6ddtUrR5Xfy5EliYmJwc3MroVoKglCsRJIq0wxq4ESzZs34+++/OXv2LPXq1aNJkyZ4eHhw4MABmjVrhr29PZcvX0aSJHr16lXS1RUEoTiIFSTKNINKUoGBgVSsWFGx3bCJiQlLly7lyy+/5MqVK6SmpmJsbEyfPn1UtkEWBOEtJVpGZZpBzZMqzPXr13n8+DGurq68++67el9HzJMqvcQ8qdJN33lST7/Wfa8m6wXb9bqXYHgMqiVVGA+Pt3OlAkEQXkG0pMq0UpOkBEEoo8S8pzLNIJPUvXv3iI6O5sGDB7x48UJtGSMjI0aNGlXMNRMEodiJllSZZlBJKjc3lxkzZrB582bFkPOXH5kVXGBWJClBKANEkirTDCpJLVq0iE2bNmFqakpAQACurq5UKGQLdEEQ3n6lZGyX8IZoTFKBgbqPqIH8lk5ERIResREREVhaWhIWFoa3t7de1xAE4S0jWlJlmsYk9eDBg2LdswkgLS0Nf39/kaAEQfgfkaTKNI1J6sSJE8VZDwAcHR0xNzcv9vsKgmC4JJGkyjSDWruvY8eOREdH8+zZs5KuiiAIhkKs3Vem6Z2kcnJyePz4cVHWheHDh+Pu7s6wYcNITEws0msLglBKyfR4CW8NnUb3vXjxguXLl7N9+3bu3LmDkZER58+fB+Ds2bOsXr2aESNG6P1MydzcnDVr1vD555/TqVMnqlatSpUqVdQ+GzMyMiIkJESv+wiCUHqI7r6yTesk9fz5c/r160dCQgKurq64uLgobatRvXp1Dh8+jLOzs95J6uHDhwwcOJCrV68iSRK3b9/m9u3bassW96AOQRBKiEhSZZrWSWr58uUkJCQwZcoU+vTpw6JFi1i6dKnifIUKFWjcuDHHjh3TuzJz587l4sWLuLu707NnT1xdXSlfvrze1xMEQRBKN62T1J49e2jSpAl9+vQB1LdknJycFN1/+jh8+DB2dnZs2rQJa2trva8jCMJbRDxjKtO0HjiRlJRE7dq1Cy1jZWXFkydP9K7Ms2fPaNCggUhQgiAoSDJJ55fw9tC6JVW+fHkePnxYaJk7d+7wzjvv6F0ZDw8PMfxcEARloiVVpmndkqpduzZHjx4lMzNT7fmHDx9y9OhRGjZsqHdl+vTpQ3R0tBh+LgiCgmhJlW1aJ6k+ffqQmprKqFGjSEpKUjqXlJTEN998w/Pnz+nbt6/elenWrRtBQUH069ePP//8k+TkZL2vJQjCW0LMkyrTdNo+/ueff2bNmjUYGRlhaWlJZmYmjo6O3Lt3D0mSGDlyJF999ZXelalZs6bWZQvO0dKF2D6+9BLbx5du+m4fnxb4kc4xlbYf1uteguHRaTLv+PHjady4MevXryc2NhZJkkhNTaVRo0Z88cUXtGzZ8rUqo8uS/GL5fkEoI0TLqEzTqSX1suzs7FK3IKxoSZVeoiVVuunbkkptr3tLqvJu0ZJ6W7zWpoelLUEJglAKFUNL6sSJE/Tv31+rsocOHaJq1aoATJw4ka1bt2os6+7uzp49e9Sek8lkhIWFER4eTmJiIsbGxnh5edG7d286depUaB22b99OWFgYly5dQiaT4e7uTvfu3enVqxfGxpqHGhw5coR169Zx7tw5Xrx4gbOzMx07dmTQoEGFfp/HxcWxYsUKTp8+TUZGBo6OjrRu3ZoRI0a88SlDOieplJQUdu7cyfnz53n69CnW1tbUqlWLjh07Ymdn91qV8fPz47333uP3339/resIgvD2kIohSVWuXJlPPvlE4/mzZ89y7do1XFxccHR0VDnfsGFDXF1dVY5r+k7My8sjODiYgwcPYmVlxQcffEB2djZRUVGMGTOG2NhYJk+erDZ2+vTphIaGYmFhgb+/P6ampkRFRTFjxgyioqJYuHAhJiYmKnErV65kzpw5mJiY4Ofnh42NDTExMSxYsIC//vqLdevWYWlpqRK3Y8cOxo8fT15eHg0bNsTBwYG4uDhWr15NZGQkYWFhVKpUSeNn97p0SlJ//PEHP/30Ey9evFB6JrR9+3YWLFjAxIkT6dmzp96VycnJoUqVKnrHC4Lw9imOJFW9enV++uknjec7duwIQPfu3dWuttOjRw+6deum9f1CQkI4ePAgNWrUICQkhMqVKwNw48YN+vTpw4YNG2jSpAmtW7dWitu7dy+hoaHY2dmxceNG3NzcAEhNTaV///7s37+fjRs3EhQUpBQXHx/P3LlzsbS0JCQkBB8fHyB/AYVhw4YRExPD/PnzmTRpklJccnIy3333HZIksWTJEkV9cnNzGTduHLt27WLq1KksWbJE6/euK62HoO/fv59p06ZhZGTEgAEDWLZsGZs3b2bZsmUMGDAAIyMjpk+fTmRkpN6VcXFxIT09Xe94QRDePpJM91dROnPmDFevXsXExKTQ1pa28vLyWLVqFQDTpk1TJCgANzc3xo4dC8CyZctUYpcvXw7A2LFjFQkK8luC06ZNA/JbTDKZ8oewcuVKJEli8ODBigQF+Wuuzpo1C2NjY0JDQ1VWDAoJCSErK4uuXbsqJUxTU1NmzpyJlZUVkZGRXL16VY9PQjtaJ6kVK1ZgZWXF1q1bmTBhAs2bN6dOnTo0b96cCRMmEB4eTvny5VmxYoXelencuTMxMTEaVz4XBKEMkox0fxWh8PBwAJo1a4aDg8NrX+/MmTOkpaVRpUoVGjdurHK+Xbt2mJmZER8fz/379xXHk5OTSUhIwMzMjHbt2qnE+fn54eDgQEpKCrGxsYrj2dnZHDlyBMj/jn2Zs7Mz9evXJycnh8OHlQecyBsd6uKsrKxo0aKFUrk3QeskdfnyZdq3b6+UvQvy8PCgffv2XLp0Se/KDBgwgA8//JCgoCB27dpFdna23tcSBOHtUJItqczMTHbt2gXAp59+qrHciRMnmDVrFlOmTGHBggUcPXpUpTUjd+HCBQDq1q2r9rylpSU1atRQKgso5oW+9957lCtXTm2s/JoF4xITE8nMzMTW1hYXF5dC4wrOPc3IyFBsx6SpruriiprWz6QsLS2pWLFioWUqVqz4WltrtG3bFkmSSEpKYsyYMQBUqlQJCwsLlbJGRkZvNHsLgmAYJJnuLaMnT56oXezaxsYGGxsbra+zZ88enj17RqVKlWjevLnGctu2bVM5VqNGDebNm4eXl5fS8Tt37gAoRgiq4+joyIULFxRldYkrWLbgn9UN+JCTX/Pu3f9NE5DH2djYYGVlVWhcwfsVNa2TlL+/P1FRUYWWiYqKomnTpnpXpuAHJB+YkZqaqras2PRQEMoGfVpGISEhLF68WOV4cHAwX375pdbXkXf1denSBTMzM5Xz3t7eTJ48GX9/f6pWrUpGRgbnz59n/vz5XLx4kS+++IKtW7cqdRM+f/4cQO1IOjn5L/sFF9zWJq5ChQp6xel7P3VxRU3rJDVu3Dg+//xzJk+ezOjRo5WGHKalpTFv3jwePHjAokWL9K7MgQMH9I4VBEGQCwoKUjvIQZdW1M2bN4mJiQE0d/UNGDBA6efy5ctjb29P06ZN6devH7GxsSxfvpypU6cqysh/Adf1F+3SElfUNCap4cOHqxyrUqUK4eHhRERE4O7uTuXKlUlNTSUxMZGcnBzq1KnDjBkz+O233/SqjJOTk15xgiC8vSQ9BkLo2q2njrwV1aBBA6pXr65TrLm5OUOHDmXkyJEqgxHkrR15S0Ud+Tl5WW3j5C0aXeP0vZ+6uKKmMUn99ddfGoOys7O5dOmSyiCJ+Pj4Es+6giC8XYpjntTL8vLyFM+Zunfvrtc1PDw8AJRG6MH/fhl/eTeJguQ7QBT8xf114+7du6cxTn6uYFy1atWA/Od7GRkZap9LyePkZd8EjUnq9OnTb+ym2jhz5gzR0dGKv2AHBwf8/Pxo0KBBidZLEITipc/Aidf1999/c//+fcqXL0+HDh30uoZ8zufLrYxatWoB+b/Uq5OZmcmVK1eUyhb885UrV8jKylI7wk9+zYI7Snh4eFCuXDnS09O5deuW2hF+Z8+eVYmzsrLCxcWFW7duER8fj7+/v1ZxRU1jknqdUXqv486dO4wdO5a4uDhAtV+0fv36/PLLL280cwuCYDhKYsODzZs3A9C+fXu9u7J2794NQJ06dZSON2jQgEqVKpGcnExMTIzKXKk9e/aQk5ND3bp1lQZcODo6Urt2bRISEtizZw9du3ZViouOjiY5ORk7OzulX+bNzc0JCAhg3759REREEBwcrBR3+/ZtYmNjMTMzUxnB2KpVK9auXUtERIRKksrIyODQoUMAtGnTRodPRjdaz5MqDo8fP6Z///7ExsZSrlw5OnTowPDhwxk2bBgdOnTA0tKSM2fOEBQUxOPHj0u6uoIgFANJZqTz63U8fPhQ8eVb2NyoCxcucOjQIfLy8pSO5+bmsnbtWjZs2ACoDq4wMTFh0KBBQP6KE2lpaYpzN27cYO7cuYD6cQFDhw4FYM6cOdy8eVNxPC0tjenTpwMwZMgQlUVmhwwZgpGREatWrVK0fiD/GdakSZOQyWT07t1b5TleUFAQ5cqVY9u2bUoD23Jzc5k6dSoZGRm0bt1aMa/rTdBrFfTHjx/z4MEDjZNta9eurVdlVq1aRVJSEm3btmX69Okq87LS09P5/vvv2bt3L6tXr+abb77R6z6CIJQexd3dFxERQU5ODh4eHjRs2FBjubt37zJq1ChsbW1xc3PDwcGBZ8+ecfnyZR48eICxsTFjx46lWTPVLWYGDBhATEwMhw4dom3btvj7+5Obm8uxY8d48eIF/fr1U1m3D/JXo+jVqxdhYWEEBgbStGlTxQKz8oShbnf0evXqMWbMGObMmUPPnj1p0qQJ1tbWxMTEkJaWho+PD6NHj1aJc3R05Mcff2T8+PGMGjUKX19f7O3tiYuL4+7du7i6ujJjxgwdP2Hd6LSf1MmTJ5k9ezbnzp0rtFzB2c666NChA0+fPuXAgQMal43Pzs6mVatWWFtbK2aC60LsJ1V6if2kSjd995NK9NG9K8k9br9e9wIIDAzk8uXLjBs3jsGDB2ssd/v2bdavX098fDx3794lPT0dIyMjqlSpgq+vL3369FHp6itIJpMRGhrKli1buH79utJWHYGBgYXWcfv27fz+++9cvnwZmUyGh4eH1lt1rF27Vmmrjk6dOmm1Vcfy5cuVtupo06ZNsWzVoXWSOn/+PJ9//jkVKlSgZcuWbNmyhfr161OtWjXOnDnD3bt3+eijj/Dw8GDChAl6VcbHx4eWLVsyf/78QsuNHj2agwcPKp5b6UIkqdJLJKnSTd8kdb1uW51jPOL36XUvwfBo3d23bNkyTExM+PPPP3F2dmbLli18+OGHBAcHk5uby9y5c9m8eTPffvut/pUxNSUzM/OV5bKysjA1fa39GgVBKCX0mSclvD20Hjhx6tQpWrZsibOzs8o5U1NTxo8fT9WqVVm4cKHelalevTonTpwgJSVFY5mUlBSOHz+u8+Q6QRBKp5LeqkMoWVonqcePHysN+zY1NVWaiWxkZETjxo05ceKE3pXp3LkzmZmZfPHFF2rXCTx+/DgDBw4kKyuLLl266H0fQRBKD5lkpPNLeHto3WdWsWJFnj59qvi5UqVKKivfSpKkVXedJj179mTv3r3ExMQwcOBA7O3tqVatGkZGRty5c4f79+8jSRLvv//+a+0ALAhC6SG6+8o2rVtSbm5uSpsR1q1bl2PHjilWLn/06BH79u1T2x2oLVNTU1avXs3AgQOxtLTk/v37nDp1ipMnT5KcnIylpSUDBw5k5cqVmJiY6H0fQRBKj+KeJyUYFq1bUs2aNWPx4sU8ffoUa2tr+vbty4EDB+jatSve3t5cvXqV9PR0nZbBV8fc3Jzx48fzr3/9i3Pnzikti1SnTh21e0sJgvD2KokVJwTDofUQ9PT0dC5cuEDt2rUVs5L/85//sHDhQpKSknBwcGDAgAF88cUXb7TCr0sMQS+9xBD00k3fIejnq3fUOabWtZ163UswPDpN5tUkLy9Pr+43+V4t+np5zSttiCRVeokkVbrpm6TOeXTSOabO9R163UswPEUy2Ujf50P9+vXTe2sPIyMjzp8/r1esIAiCUDqU6IzYGjVq6Jyk7ty581ojCAVBKF3E6L6yTWOSetXaUZoYGRkRERGhVdkdO7Rvkl+5coV58+Zx9epVIH+XYEEQ3n5i4ETZpjFJPXjwwCB22b137x6//vorERERyGQybGxsGDp0KP369SvpqgmCUAzE5NyyTWOSep2VI4rCo0ePWLZsGX/88QcvXrzA0tKS/v37M2TIELXbGAuC8HYS3X1lm8Gt0pqZmcmaNWtYu3Ytz549w8TEhJ49ezJq1Cjs7OxKunqCIBQz0d1XthlMksrNzeWPP/5g2bJlip0q27dvz9dff42Li0uR3UcMYxaE0kV095VtBpGkIiIiWLRoEXfu3EGSJD744APGjBlDrVq1SrpqgiCUMNHdV7aVaJI6fPgw8+bN4/Lly0iSpNji+P333y/JagmCYEBES6psK9EkNWzYMIyMjChXrhz9+/enbdv8HTgTEhK0iq9du/abrJ4gCAZAPJIq24pkWSR9eXt7F/uKE6bmTnrdTxCE16PvskjHHLvrHNP0Xrhe9xIMT4m2pKpWrVqStxcEoRQQz6TKthJNUgcPHizJ2wuCUAqI3eDLNp2T1M2bN9m5cyfXrl0jMzOTpUuXApCcnMylS5fw9e1Yz2EAACAASURBVPUVk20FQSgyEqIlVZbplKRWrlzJwoULyc3NBVB6npSVlcXw4cOZMmUKvXv3LtpaCoJQZsnEyIkyTevt4/fv38/cuXNp0KABoaGhKpsburm5UbNmTQ4cOFDklRQEoeySYaTzS3h7aJ2k1q1bh5OTE6tWraJhw4ZUqFBBpcx7771HYmJikVZQEISyTcJI55fw9tA6SV24cIGAgAAsLCw0lrG3t1csaSQIgiAIr0vrZ1IymQwzM7NCyzx69OiVZQRBEHQhRveVbVonKWdnZ+Li4jSelySJM2fOUL169SKpmCAIAojRfWWd1t19H3/8MWfPniUsLEzt+ZCQEK5fv0779u2LrHKCIAgyPV7C20PrltTAgQPZvXs3M2bMYM+ePYph6IsWLeLkyZNER0dTs2ZNMfxcEIQiJZJO2abT2n0PHz5k2rRp7N+/n5fD2rRpw8yZM7G1tS3yShYlsXafIJQMfdfu2+nQS+eYjvfV9/gIpY9Ok3nfffddfv31V+7fv09sbCzp6elYW1vj4+ODk5P48hcEoejJxCOpMk2vtfscHBz4+OOPi7ougiAIKsTk3LLNIHbmFQRB0ESsilS2aZ2kfvjhB60vOnnyZL0qIwiC8DIxcKJs0zpJbdy4sdDzRkZGSJKEkZGRSFKCIBQZmZ4bowpvB62T1Pbt29Uef/LkCfHx8axcuZL333+fESNGFFnlBEEQiqu7b+LEiWzdulXjeXd3d/bs2aNyXCaTERYWRnh4OImJiRgbG+Pl5UXv3r3p1KlToffcvn07YWFhXLp0CZlMhru7O927d6dXr14YG2uexnrkyBHWrVvHuXPnePHiBc7OznTs2JFBgwZhbm6uMS4uLo4VK1Zw+vRpMjIycHR0pHXr1owYMQJra2uNcdevX2fp0qUcP36c9PR07OzsCAgIYNSoUdjb2xf6Hl9XkW0ff/v2bTp37sz06dPp3LlzUVzyjRBD0AWhZOg7BP3fjn10jvn83u86x8iTVMOGDXF1dVU5b2dnx5gxY5SO5eXlERwczMGDB7GyssLf35/s7GyioqLIzs6mX79+GnuWpk+fTmhoKBYWFvj7+2NqakpUVBTPnj2jTZs2LFy4EBMTE5W4lStXMmfOHExMTPDz88PGxoaYmBgePnxI/fr1WbduHZaWlipxO3bsYPz48eTl5dGwYUMcHByIi4sjKSkJV1dXwsLCqFSpkkpcdHQ0Q4YMISsri9q1a+Pq6srFixe5fv067777LqGhobi7u2v7MeusyAZOODs706pVK9auXWvQSUoQhNKluIeg9+jRg27dumlVNiQkhIMHD1KjRg1CQkKoXLkyADdu3KBPnz5s2LCBJk2a0Lp1a6W4vXv3Ehoaip2dHRs3bsTNzQ2A1NRU+vfvz/79+9m4cSNBQUFKcfHx8cydOxdLS0tCQkLw8fEB4NmzZwwbNoyYmBjmz5/PpEmTlOKSk5P57rvvkCSJJUuWKOqTm5vLuHHj2LVrF1OnTmXJkiVKcc+fP+ebb74hKyuLKVOm0LdvX8W52bNns2bNGsaMGUN4eLjS/oJFSetlkbRhZ2fH9evXi/KSgiCUcYa6n1ReXh6rVq0CYNq0aYoEBfn7640dOxaAZcuWqcQuX74cgLFjxyoSFEDlypWZNm0akN9iksmUh42sXLkSSZIYPHiwIkEBVKhQgVmzZmFsbExoaChPnjxRigsJCSErK4uuXbsqJUxTU1NmzpyJlZUVkZGRXL16VSluy5YtpKSk4Ofnp5Sg5HV3cXEhISGBI0eOFPpZvY4iS1KSJHHy5EnKly9fVJcUBEFA0uNVHM6cOUNaWhpVqlShcePGKufbtWuHmZkZ8fHx3L9/X3E8OTmZhIQEzMzMaNeunUqcn58fDg4OpKSkEBsbqzienZ2tSAbqequcnZ2pX78+OTk5HD58WOlcZGSkxjgrKytatGihVE6bOBMTEzp06KA2rihp3d2XkJCg9nheXh737t1j8+bNnDt3jq5duxZZ5QRBEIq7u+/EiRNcunSJ58+fU6lSJXx9ffnggw9UBjJcuHABgLp166q9jqWlJTVq1ODChQtcuHABBwcHAM6fPw/kbxJbrlw5tbF169bl/v37XLhwgYYNGwKQmJhIZmYmtra2uLi4aIw7ffo058+fJzAwEICMjAxu3bpVaF3r1q3L9u3bFXXT9j3Kj78cV5S0TlLdu3cvtM9RkiTq1KnD+PHji6RigiAI+nry5IlKlxeAjY0N/9/encdFWe0PHP+AgBsgLizihqSCy7ghKKaouBttbrnjhnbds7pllqJm3XtzKbVFTRE3MpdMcyuRUtMANVwShVwRBRUEBWSf3x/8ZnKcYRWYkfm+e83rBc8553nOM2N85yzPOdbW1gWW3b17t9axJk2asGzZMlxcXNTHbt26BYCjo2O+56pbty6RkZHqvMUp92TeJ39WpemiOmds7D+TVFTlrK2tsbS0LLDck9dLSUkhKSkJIN9l73SVK21FDlLjxo3TedzU1JQaNWqgUCjo1KlTmQ2eCSGMU0ke5g0MDGTVqlVax6dNm8b06dN1lnF1deXDDz/E09MTR0dHUlJSuHjxIsuXL+fSpUuMGzeOH374Qd0iSktLA9A5k05FNfyRmpqqPlaUctWrVy9RuZJeT1e5J3/Or6yucqWtyEHqvffeK7NKCCFEfkoyxuTr68vrr7+udbygVtTYsWM1fq9WrRp2dnZ07tyZ0aNHExERwerVq5k3b15evf7/6Z3ifjF/XsoZiiJPnPj444/ZunVrWdZFCCG05JoU/2VtbU39+vW1XoV19eliYWHBpEmTADQmJKhaO6qWii6qNFXeopZTtUyKW66k1yuoHMDjx4+LXK60FTlIfffdd9y+fbvMKiKEELoYws68zs7OABqz9FTjNAX9XYyLi9PIWxrl7ty5k285VdqT5erXrw/kjdOlpKQUWE6VF/Jm/an2B3xyjKuw65W2IgcpR0dH9SCaEEKUF0MIUqq/fU+2GFq0aAHkPWCry+PHj4mOjtbI++TP0dHRpKen6yyrOmfz5s3Vx5ydnalSpQpJSUnq2XpPO3funFY5S0tL9WzA/Oqqq9yTvxdW7sn7K21FDlL9+/fn+PHj+UZiIYQoC0qT4r9K24EDBwBo1aqV+li7du2oXbs2cXFxhIeHa5U5ePAgWVlZKBQK9WQLyJud17JlS7KysnSuBRgWFkZcXBy2tra0a9dOfdzCwgIvLy8A9uzZo1UuJiaGiIgIzM3N6d69u0Zaz5498y2XkpJCSEgIkLfDuq5yutZuzcnJYf/+/TrLlaYiB6kpU6bg5OTE+PHjCQ0NLbB/UwghSkt5tKQiIyMJCQkhJydH43h2djYBAQFs2rQJ0JxcUalSJSZMmADkrTiRkJCgTrt+/TpLly4F4M0339S6nmqMa8mSJdy4cUN9PCEhgQULFgDg5+en9WyWn58fJiYmfPvtt+pWDOSNYX3wwQfk5uYyYsQIrbE3X19fqlSpwu7duwkODta4v3nz5pGSkkKvXr1o0qSJRrmBAwdia2tLaGgoW7Zoroe4ZMkSbt68SYsWLdTBsywUeYHZ9u3bo1Qqefz4sXqWSJUqVbRmjJiYmHD69OnSr2kpkQVmhdCPki4wu6rBqMIzPWVaTMFbCz3t8OHDTJ06FRsbG5ycnLC3tyc1NZWoqCju3r2Lqakps2fPxs/PT6NcTk4OU6dOJSQkRL3AbHZ2NidOnCAjI6PABWb9/f0JCgqicuXKdO7cWb3ArCpgrFixotAFZjt16oSVlRXh4eEkJCTQpk0bAgMDC1xgNjc3Fzc3N+zs7Dh79iyxsbHFWmDWycmJS5cuceXKFWrWrMnWrVvVY3ZlochBauDAgUWewrhz585nqlRZkiAlhH6UNEitLEGQml7MIBUTE8PGjRs5f/48sbGxJCUlYWJigoODA25ubowcOVKjq+9Jubm5bN26lV27dnH16lWNrTpUqz7kZ+/evWzZsoWoqChyc3NxdnYu8lYdAQEBGlt1+Pj4FGmrjtWrV2ts1dG7d+8ibdXx5Zdf8scff5CcnEydOnXw8vJi2rRpz89WHc8LCVJC6EdJg9QXDYsfpGbeLF6QEoarwDGp3bt3c+nSpfKqixBCaDGE2X1CfwoMUu+//36Zrm4rhBCFkSBl3Ept00MhhCgLRjUeIbRIkBJCGLTy3qpDGBYJUkIIgybdd8at0CD16NGjYq/ZV9A+KUIIURzS3WfcCg1SGzduZOPGjUU+oYmJSZnu0iiEMC65EqaMWqFBytLSssCHvIQQQoiyUmiQ8vX1Zdq0aeVRFyGE0CJjUsZNJk4IIQyadPYZNwlSQgiDJi0p4yZBSghh0OQ5KeMmQUoIYdBkdp9xKzBIyeKyQgh9kxBl3KQlJYQwaDImZdwkSAkhDJp09xk3CVJCCIMmIcq4SZASQhg06e4zbhKkhBAGTbr7jJsEKSGEQZMQZdwkSAkhDJp09xk3CVJCCIOmlLaUUTPVdwWEti4vevD9tjXE3DhD6qOrxNw4w4F9W+nfz1udZ923y8nOjC3w9fPBbRrn7dqlIxsCVhDxZzDxdy6Q8vAK0ZdP8sOuALx7dCnv26xwxvq+we/H9vIg4TIPk/4mPOwQ06aOx9RU83+zknx2T7OwsCDiz2CyM2O5fvVUWd6W3uWW4CUqDmlJGZgP5sxk4YJ/c+9eAvv2HyYu7i61a9ekbdtWdOvmyYGDRwD4cc9BbtyI0XmOkSMG8cILThw8dETjeI8eL9Kje2fCwv8kJOR30tLSaNCgHi/79OFlnz4s/uRz5vt/Vub3WBEFrP+C0aMGEx9/j++37yE1NY2ePbvy+fJFdO3aiTeGTVLnLcln97TFi96nUcP6pXoPhkomThg3E6VSaVT/Asws6um7CvkaNMiHbUGrOXz4KIOHTiQlJVUj3czMjOzs7ALPUaOGNTE3zlCpkikNndxISHigTqtcuTIZGRlaZRwdHQgPPUidOrVo1LgDcXF3S+eGjMQrr/Rl1471XL16A88XX1K/52ZmZnwX9A2vvdqf8RPeYuOm7ws8T0Gf3ZO6eXnyy8/fM236B3z15X+4desOTs4dSv2+Slt2ZmyJyk1xGlrsMl9dL/i9Fs8P6e4zECYmJny6+ANSU9MYNWaqVoACCg1QAKNGDqJatar8sPuA1h85XQEK4PbtOE7+cYpKlSrh3LhhyW7AiL3+2gAAln++WuM9z87OVrdMp04dV+h5CvrsVKysLFn37XKOHDnOmrWbSqH2hk9ZgpeoOKS7z0B09uyAs3Mjduz8iQcPkhnQvyctW7qQnp5BeHgEf4SeLtJ5JkwYAcC3324p8rVtbWvj4d6O9PR0LkddKVH9jZmDvS0A167d1Eq7evUGAG7tW1OjhjXJyQ/zPU9RPrvPly+iZs0a+E1++1mq/FyR7j7jptcgdebMmWcq3759+1Kqif516NAWgPj4e4SHHaS1ooVG+tGjJxk6bBL37yfme45OHd1orWjB5agr/PrbiXzzubVvzUsv9cLMzIx69erysk9vrK2tmDnro3y/wYv83U/I+0ycnLRboc7OjdQ/u7o0ITRM97/5onx2r77aD98xQ/Gb9DYxMbdLoebPB5kIYdz0GqRGjBiBiUnJdjQzMTHh4sWLpVwj/bGzqw3A5EmjuXYthj593yA07AyNGtXns//Oo2/fHmwLWk3P3kPyPcfEiSMBWLeu4FaUm1sb5n30zzfxhw8fMcFvNlu27CyFOzE++/YfZviw15k1049t3//IgwdJAFSqVIn58/55n2vWrJHvOQr77Ozs6vD1l//lwIFgAjZ8V4q1N3wyBd246TVItWvXTitIZWdnc+7cOQCqVatGvXp5Ex1iY2NJS0vDxMQEhUKBmVnF6qmsVKkSkBd83xg+iXPn8gLwxYtRDBoykci/jtGtW2c6dXTT2fVnbW3FkMEvk5GRQeDGggeN16zdxJq1m6hcuTKNGzdgkt9oAgNW0NnTnanT3i/9m6vgtm37kZHDB9K/f0/Onw1h708/k5aWTs+eXXjBuRFR0Vdp1tSZnJwcneWL8tmt/uYzzM3NmPyvf5flrRgkaUkZN73+pQ8KCtL4PSMjg3HjxtGoUSPeffddevXqpZF++PBhlixZgpmZGQEBAeVZ1TL34EEyAFev3lQHKJX09HR+/uVXJowfgbt7W51BauSIgVSvXo3vtu0ucpddRkYGly79zey351O5cmUmTxpN8JFj7Nq179lvyIgolUpeGziOGdMnMnLkIEaNHERWVjYnT55i/PhZrPhiMTSFu/cSdJYv7LMbNWowL/v0Yez4mdy+HVfWt2NwpCVl3Axqdt9XX31FZGQkGzdu1ApQAL169WLDhg1ERkby1Vdf6aGGZUc1YSEpOVlnetL/B7GqVavoTJ8wIa+7aO3azSW6vuq5nG5eniUqb+xycnJY/vlqOrj3wapGE2rVceWll0dxMTKaNm1akJb2mL/+uqyzbGGfXbu2CgA2rP9C66FfgPr166p/r1HDugzuTr/kYV7jZlB9ZgcOHKBTp07Y29vnm8fBwYFOnTqxf/9+3nrrrXKsXdk6duwPsrKyaNqkMebm5mRlZWmkt2zpAsB1HQ+Beri3o22bllyOusJvR0+W6Pr1HOsCkJ2tu0tKlMyokYOoWrUqgRu/1/kIQVE+uz9CT2O5vprOtAnjR5CamsZ323YDkJGRWXqVNxC5xvUop3iKQQWpuLg4WrRoUWi+ypUrEx8fXw41Kj8JCQ/4fvseRo4YxEcfvsW8+f9Tp/Xq2ZU+fbqTlJTMoUO/apVVDboXNu3cq2snjh0P5ennt52dGzHn/ekAHDhw+BnvxDhZWVny6FGKxrEObm34ZPEcHj1K4ePFy3WWK8pnt337HrZv36MzbcL4ETx4kMzkN98tYc0Nn4Qo42ZQQapmzZqcOnWK9PR0qlTR3a2Vnp5OeHg4NjY25Vy7svfOuwvwcG/PB3Nm0rVLR8LDI2jYqD6vvdqPnJwcJv/r31rP2VhZWTJ0yCtkZGQUuqLBrp3rSUp6SFj4n9yKuU0lMzNeeKERfft0x9zcnJWr1nE4+FhZ3mKFdehAEI8fp3Phr8ukpKTQooUL/ft5k5GRyZChE3U+Q1Wcz86YyXNSxs2gxqR69OjB/fv3mTFjBrdvaz8HcufOHWbOnEliYiI9e/bUQw3L1r17CXTu4sPnn6+hfn1Hpk0bT4/uL7L/QDDdewxk586ftMqMGD4QS8vqBa5SoLJg4VIuXoyio0d73nzTlzcnj6a1ogU/7jnEgJdG8NbseWV1axXezl37sLSyZOSIgcyaOYlWLV1Ztz6I1m178PMvv+ksU5zPzpgpS/CfqDgMau2+xMREBg8ezO3btzEzM6N9+/bUr5+3iGZsbCynT58mOzsbR0dHduzYQa1atYp9DUNeu0+Iiqyka/e90ei1YpfZdmN3ia4lDI9BBSmAu3fvMn/+fH799VetsROA7t27s2DBggInVxREgpQQ+lHSIDWk0avFLrP9xo/Fyp+VlcWpU6f47bffOHPmDLdv3yYpKYmaNWvSrl07Ro4cSceOHbXKvf/++/zwww/5nrdx48YcPHhQZ1pubi5BQUHs3LmTa9euYWpqiouLCyNGjMDHx6fA+u7du5egoCAuX75Mbm4ujRs3ZtCgQQwfPlxra5gnHT16lA0bNnDhwgUyMjJo0KABL730EhMmTMDCwiLfcmfPnmXNmjWcOXOGlJQU6tatS69evfjXv/6FlZVVgXV9VgYXpFRiYmI4deoUcXF5z4XY29vj7u5OgwYNnum8EqSE0I+SBqnBjV4pdpkdN3RPNMnPiRMnGDcubxFgW1tbWrZsSdWqVbly5QpRUVEATJkyhZkzZ2qUUwWp9u3b06hRI63z2tra8vbb2uss5uTkMG3aNI4cOYKlpSWenp5kZmZy8uRJMjMzGT16NB9++KHOui5YsICtW7dSuXJlPD09MTMz4+TJk6SmptK7d2+++OIL9eIAT1q7di1LliyhUqVKeHh4YG1tTXh4OImJibRt25YNGzZQtWpVrXI//fQT//73v8nJyaF9+/bY29tz9uxZbt++TaNGjQgKCqJ27dqFv8klZFATJ57UoEGDZw5IQojnX3k892RiYkLfvn0ZM2YMHTpobnuyf/9+3nnnHb766is6duxIp06dtMoPGTKEgQMHFvl6gYGBHDlyhCZNmhAYGEidOnUAuH79OiNHjmTTpk106tRJ63nRQ4cOsXXrVmxtbdm8eTNOTk4A3L9/nzFjxvDLL7+wefNmfH19NcqdP3+epUuX5j0OERhImzZtAEhNTWXy5MmEh4ezfPlyPvjgA41ycXFxzJ07F6VSyZdffqmuT3Z2Nu+++y779+9n3rx5fPnll0W+9+IyqIkTQgjxNKVSWexXcXl6erJixQqtAAUwYMAAXn/9dQD27CleC02XnJwcvv32WwD8/f3VAQrAycmJd955B4BvvvlGq+zq1asBeOedd9QBCqBOnTr4+/sDeS2m3FzN0L527VqUSiUTJ05UByiA6tWr8+mnn2JqasrWrVt5+FBz9nBgYCDp6em89tprGgHTzMyMRYsWYWlpyeHDh/n7779L8E4UjUG1pIq7KnpFWgVdCGG4VM9vlsbzmX/++ScJCQk4ODjg7u6uld6vXz8++ugjzp8/T3x8vHr8PS4ujr/++gtzc3P69eunVc7DwwN7e3vi4+OJiIhQ/33MzMzk6NGjALzyinbXaYMGDWjbti1nzpzht99+4+WXX1anHT58ON9ylpaW9OjRg71793L48GGaNGlSgnejcAYVpIqzKnpFWwVdCKGbITwndf36dSBvjEmX0NBQLl++TFpaGrVr18bNzY0XX3xR5ySGyMhIABQKhc5zVa1alSZNmhAZGUlkZKQ6SKn+3jVt2jTf50gVCgXx8fFERkaqg9S1a9d4/PgxNjY2NGyoe1NThULBmTNnuHjxojpIpaSkcPPmzQLrqlAo2Lt3b5n+LTaoIKVrVXTImwVz+/Zt7t69i4mJCa1bt9Y5MCiEqHhKMib18OFDra4rAGtra6yti7e+4b1799Qz+Pr06aMzz+7d2lPemzRpwrJly3BxcdE4fuvWLQAcHR3zvWbdunWJjIxU5y1OuSfzPvmzKk0X1TljY/+Z3KIqZ21tjaWlZYHlnrxeaTOoIPX0quhPu3TpEnPmzMHS0pI1a9aUU62EEPpUkodzAwMDWbVqldbxadOmMX369CKfRzVB4NGjR3h6euLt7a2R7urqyocffoinpyeOjo6kpKRw8eJFli9fzqVLlxg3bhw//PCDxiMzaWlpADpn0qlUq5a3VmNqamqxylWvXr1E5Up6PV3lSptBBanCuLq6smrVKnx8fFi7di1vvvmmvqskhChjJenu8/X1VU92eFJxW1Hz58/n5MmT1K1bl88++0wrfezYsRq/V6tWDTs7Ozp37szo0aOJiIhg9erVzJv3z2ouqokdxd3w9XkpV9qeu9l99erVQ6FQ8OOPxXtYTwjxfCrJ7D5ra2vq16+v9SpOkPr444/ZsWMHtra2bNiwId/xKF0sLCyYNGkSAL/9prkslqq1o2qp6KJKU+UtajlVi6a45Up6PV3lSttzF6QAatSoodF3KoSouPSxn9R//vMfNm3aRK1atdiwYYPGdO+icnZ2BrRnBKp2G9e1PqmKahEDVd7SKHfnzp18y6nSniynWpLu4cOHpKSkFFhOlbcsPHdBKjU1lYiIiHwH8oQQFUt5LzD7v//9j4CAAGxsbAgICCjx1OqkpCRAu5Whms5+/vx5neUeP35MdHS0Rt4nf46OjiY9PV1nWdU5mzdvrj7m7OxMlSpVSEpKUs/We9q5c+e0yllaWqpnA+ZXV13lSptBBan4+Ph8X9euXSM4OJgJEyZw//59OnfurO/qCiHKQS7KYr9KasmSJaxbt44aNWoQEBCAq6tric914MABAFq1aqVxvF27dtSuXZu4uDjCw8O1yh08eJCsrCwUCoXGhIu6devSsmVLsrKydK4HGBYWRlxcHLa2trRr10593MLCAi8vL0D3w8gxMTFERERgbm5O9+7dNdJUu03oKpeSkkJISAgAvXv31vkelAaDClLdunWje/fuOl8DBgxg2rRpREREYGdnp3M9LCFExVMeK04AfP7556xduxZra2vWr19f6AaskZGRhISEkJOjuZt1dnY2AQEBbNq0CdCeXFGpUiUmTJgA5K04kZCQoE67fv06S5cuBdA5MUw1zrVkyRJu3LihPp6QkMCCBQsA8PPz03o+y8/PDxMTE7799lt16wfyeqY++OADcnNzGTFihNaYna+vL1WqVGH37t0EBwdr3OO8efNISUmhV69eZfYgLxjYArNeXl75ziQxNzfH3t4eT09PRo0aVeJND2WBWSH0o6QLzPaoX/xv6SG3filW/uDgYKZMmQLktXyaNm2qM5+zs7M6UBw+fJipU6diY2ODk5MT9vb2pKamEhUVxd27dzE1NWX27Nn4+flpnScnJ4epU6cSEhKiXmA2OzubEydOkJGRUeACs/7+/gQFBVG5cmU6d+6sXmBWFTBWrFhR6AKznTp1wsrKivDwcBISEmjTpg2BgYEFLjCbm5uLm5sbdnZ2nD17ltjY2HJZYNagglR5kCAlhH6UNEh1r9+r8ExP+fXW4WLl37VrF3PmzCk0n4eHh7qFFBMTw8aNGzl//jyxsbEkJSVhYmKCg4MDbm5ujBw5Uqur70m5ubls3bqVXbt2cfXqVY2tOp5cmkiXvXv3smXLFqKiosjNzcXZ2bnIW3UEBARobNXh4+NTpK06Vq9erbFVR+/evY17q46yIkFKCP0oaZDyqlf8XbiPxgYXnkk8F56rh3mFEMbHqL5FCy0GG6TS09OJiYkhJSUl34FQWQVdiIrPEBaYFfpjcEEqJiaGTz75hGPHjmnNmnmSrIIuhHGQ//RylgAAGgtJREFUIGXcDCpIxcfH88Ybb5CYmEidOnXIzc0lMTERhULBzZs3SU5OllXQhTAyRjZsLp5iUM9JrVmzhsTERCZPnszx48fp1q0bJiYmbN++ndDQUFavXo2joyPVqlVj48aN+q6uEEKIMmZQQer48eM4ODgwc+ZMnendunVj3bp1nDp1inXr1pVz7YQQ+lCeK04Iw2NQQerOnTu4urqq5/mrHuzNyspS53FycsLd3Z2ffvpJL3UUQpSv8l67TxgWgwpSlStX1tgWWbWhVmJiokY+GxubMt0JUghhOMprWSRhmAwqSNnZ2WksJ9+oUSMAIiIiNPJFRkaW6f4lQgjDId19xs2gZve1bt2an3/+mczMTCwsLOjSpQtKpZJPP/0US0tLHBwcCAoK4vr163Tr1k3f1RVClANpGRk3g2pJeXl5kZqaql5tt3HjxgwaNIi4uDgmTpyIj48PmzdvxszMLN/JFUKIikVaUsbN4Nfuy87OZv369Rw6dIjk5GScnZ2ZPHkybm5uJTqfrN0nhH6UdO2+1g6exS5zLu5kia4lDI/BB6nSJkFKCP0oaZBqZd+p2GUuxP9RomsJw2NQ3X0zZ85k0aJF+q6GEMKAyBR042ZQQSo4OFhjl0ohhMhVKov9EhWHQc3us7e3L3BRWSGE8ZGWkXEzqJZUt27dOHXqFOnp6fquihDCQEhLyrgZVJCaPn06VatWZdasWcTHx+u7OkIIAyBjUsbNoLr7li1bhouLCyEhIfTu3RuFQoGjo6PGUkkqJiYmLFy4UA+1FEKUJ2kZGTeDmoLu6uqKiYlJkZ4wNzExITIystjXkCnoQuhHSaegO9dpV+wyV+//WaJrCcNjUC0pmX4uhHiaUpmr7yoIPTKoIDVkyBB9V0EIIYQB0evEieDg4BJ12QkhjIes3Wfc9Bqkpk6dmu828HPmzGHHjh3lXCMhhKGR/aSMm0FNQX/SDz/8wOnTp/VdDSGEnklLyrgZ1JiUEEI8TVpGxk2ClBDCoMlzUsZNgpQQwqDJChLGTYKUEMKgSXefcdN7kLp//z7h4eHFTgNwd3cvq2oJIQyETIQwbnpdFkm1DFJJmJiYcPHixWKXk2WRhNCPki6LVMe6WbHL3H8YVaJrCcOj15aUo6OjPi8vhHgOyMQJ46bXIHXkyBF9Xl4I8RyQMSnjpvcxKSGEKIiMSRk3CVJCCIMmLSnjJkFKCGHQZEzKuEmQEkIYtPJ8mHfv3r0EBQVx+fJlcnNzady4MYMGDWL48OGYmhrsUqcVmkHtzFseZAq6EPpR0inoVas2KnaZx49vFLvMggUL2Lp1K5UrV8bT0xMzMzNOnjxJamoqvXv35osvvqBSpUrFPq94NtKSEkIYtPL4Hn3o0CG2bt2Kra0tmzdvxsnJCchbUGDMmDH88ssvbN68GV9f3zKvi9Ak7VchhNFbvXo1AO+88446QAHUqVMHf39/ANauXUturmxlX94kSAkhDJqyBP8VR1xcHH/99Rfm5ub069dPK93DwwN7e3vu3btHREREad2WKCIJUkIIg1bWO/Oqlldr2rQpVapU0ZlHoVAAEBkZ+Ww3I4pNxqSEEAatJGNSDx8+5OHDh1rHra2tsba21jh269YtoOBl2urWrauRV5QfowtSJZ1hJITQj6wS/D+7cuVKVq1apXV82rRpTJ8+XeNYWloaAFWrVs33fNWrVwcgNTW12HURz8bogpQQouLz9fXl9ddf1zr+dCsK/mmplXRHBlG2JEgJISocXd16+VG1klQtKl1ULShVXlF+ZOKEEMKo1auX94D/7du3880TFxenkVeUHwlSQgij1qJFCwCio6NJT0/Xmef8+fMANG/evNzqJfJIkBJCGLW6devSsmVLsrKyOHjwoFZ6WFgYcXFx2Nra0q5dOz3U0LhJkBJCGL1JkyYBsGTJEm7c+Gfdv4SEBBYsWACAn5+fLDKrB0a3wKwQQuji7+9PUFAQlStXpnPnzuoFZlNSUujVqxcrVqyQBWb1QIKUEEL8v71797JlyxaioqLIzc3F2dlZturQMwlSQgghDJZ8NSghb29vXFxccHFx4ddff803n4+PDy4uLoSGhpZf5QyE6v15Hj35+eb3Onz4sL6rWWLDhw/HxcWFU6dO6bsqQhRIHuYtBUuXLsXLy0u6AyqgLl26YGtrqzNNtZ6bEKLsSJB6RlWrViUqKoo9e/bw2muv6bs6opRNmjSJjh076rsaQhgt+er/jEaPHg3kLWiZmZmp59oIIUTFIkHqGfXp04fWrVtz69YtvvvuuyKXy8rKYvPmzQwZMoT27dvTunVr+vfvz5IlS0hKStLKf+vWLVxcXPD29iY7O5t169bxyiuv0LZtWzp06KDO9+Q40K5duxg4cCBt27blxRdf5IMPPiAxMRGAjIwMVqxYQd++fVEoFHTv3p3ly5eTlZWlde3ExEQCAwOZMGEC3t7eKBQK3NzcGDp0KFu2bCEnJ6e4b1uFsn37dlxcXJg7dy6JiYksXLgQb29vWrVqxYwZM9T5Dhw4wJw5cxgwYAAdOnRAoVDQp08fFi5cSHx8vM5ze3l54eLiol6W52kFjS0lJibi7++Pl5cXCoWC3r17s3z58nxXVRDCEEl3Xyl4++238fX15ZtvvmHQoEGFLkKZkZHBxIkTCQsLo2rVqnTs2JEqVapw+vRp1q5dy/79+wkMDKRBgwZaZZVKJdOnT+fYsWO4u7vTpEkTnWuOffbZZwQGBuLh4UHXrl35888/2blzJxcuXCAoKIgJEyZw9epV3N3dadiwIeHh4XzzzTckJiayaNEijXMdO3aMTz75BAcHBxo2bEibNm24f/8+ERERnD17lt9//50vv/zS6FeRTkhIYNCgQaSlpdGhQwdatWpF7dq11emzZs2iWrVqNGnShM6dO5ORkUFkZCRbtmzhwIEDbNu2jYYNG5ZKXeLj4xk+fDixsbHUrl2bHj16kJmZSWBgIGFhYWRnZ5fKdYQoaxKkSkGnTp3o0qULx48fJyAggGnTphWY/4svviAsLAxnZ2c2bNiAvb09AOnp6bz77rv8/PPPvPPOO2zbtk2rrCog7du3j0aNGuV7jd27d/Pjjz/ywgsvAJCcnMwbb7zB5cuXGTZsGFZWVgQHB2NlZQXk7Tg6ePBgtm/fzptvvqmxkGarVq34/vvvadOmjcY17t69y6RJkwgODubAgQMMGDCgCO9WxRUSEoKXlxeff/65zi8qy5cvx9vbW2P31+zsbL744gvWrFnDJ598wjfffFMqdfH39yc2NpYuXbqwcuVKqlWrBsCdO3fw9fXVWFVBCEMm3X2lZPbs2ZiYmLB+/Xp1l5ou6enpBAUFAfDhhx+qAxRAlSpVWLBgAdWqVSMiIoLTp0/ne62CAhTAjBkz1AEKoEaNGgwbNgyAv//+m0WLFqkDFOQtnOnl5YVSqSQ8PFzjXC+88IJWgAKws7Pj3XffBdC55llFMGbMGJ3Tz99//32tvObm5ixcuDDflvSAAQO0tic3MzNj9uzZ1KlTh6NHjxa4XURRxcTEEBISgpmZGf7+/uoABXkzElWfmRDPA2lJlZKWLVvSv39/9u/fz9dff83cuXN15rtw4QJpaWnY2dnx4osvaqXXqlWLHj16sG/fPsLCwnBzc9PK07t370Lr07VrV61jqsDm6OioEcBUnJycgLwW0tOys7P5448/iIiI4N69e2RmZqJUKtX77Fy/fr3QOj2P8puCrutzUSgUhU5Lv3r1KsePH+fmzZukpqaqN9zLzc0lJyeHmJiYZ362LDw8HKVSSfv27XV2Gffq1Ytq1aqVSkAUoqxJkCpFs2bN4ueff+a7775j7NixOveeUQWA+vXr53se1R8WXYPptWvX1vo2rouDg4PWMdU3al1pT6ZnZGRoHL927RpTp07lypUr+V4vJSWl0Do9j4ozBd3R0THftKysLPz9/dmxY0eB5yiN91E1ySK/f2MmJibUq1eP6OjoZ76WEGVNuvtKUaNGjRg8eDCZmZmsWLFCZ55n3aq6KAEKKPDB4uI+dDxjxgyuXLmCt7c3W7duJTQ0lIsXL3L58uUK281XEgV9NgEBAezYsQN7e3uWL1/Or7/+yvnz57l8+TKXL19GoVAA//z7KCpZ1UxUdBKkStnUqVOpWrUqe/bsISoqSitdNQZ169atfM+hSntyvEpfrly5QlRUFLVr12bVqlW4ublhY2OjXg365s2beq7h80EVzD/++GMGDBhA3bp1sbCwUKfn9z6am5sD/2xf/rTY2FitY4X9G1MqlTrLCWGIJEiVMjs7O8aMGUNubi7Lli3TSm/VqhXVqlUjPj6ekydPaqU/ePCAI0eOAODh4VHm9S1McnIykHdfurYp2LNnT3lX6bmkeh91jVn99ttv6vSnqQLOtWvXtNIuXbqkc/zQ3d0dgDNnzugMRsHBwTIeJZ4bEqTKgJ+fHzY2NoSEhGh9m61SpYp6lt3ixYs1/shkZGTg7+9PWloabdu21Tk4X96cnJwwNTUlOjpaa9bfzp072bdvn55q9nxxdnYGICgoSKOL7vr16+pN9XTx9PQEYO3atRrjVbGxsTpnGAI0bNiQ7t27k52djb+/P48fP1anxcXF8dlnnz3TvQhRnmTiRBmwsrLCz8+Pzz77TOMPhMqsWbO4cOECYWFh9O3bV/0w76lTp7h37x6Ojo4sWbJEDzXXVqtWLUaMGMHmzZsZM2YM7u7u2NraEhUVRVRUFJMnT2b16tX6rqbBmzx5MidPnmTLli2cOHGC5s2bk5SURHh4OG5ubtSpU4ezZ89qlRs1ahTbt28nIiKCfv360bZtW5KTkzl//jzt2rWjTZs2OsstWLCA4cOHc/ToUXr27Im7uzsZGRmEhobi4uKCtbU1586dK49bF+KZSEuqjIwePTrfWXSVK1dm/fr1fPjhh7zwwguEhoYSHByMpaUlEydOZNeuXTqnDuvL3LlzWbRoEa6urpw/f56jR49Su3Zt1q5dy9ChQ/VdvedChw4d2LZtG926dePRo0ccOXKEu3fvMmXKFNauXZvvjq81a9YkKCgIHx8fsrOz+fXXX7l79y5+fn6sWbMm33IODg5s376dYcOGYWpqSnBwMNHR0YwcOZKAgADMzOT7qXg+yKaHQgghDJa0pIQQQhgsCVJCCCEMlgQpIYQQBkuClBBCCIMlQUoIIYTBkiAlhBDCYEmQEkIIYbAkSIlC3bp1S+dGf++//z4uLi4FLpZrSIpb39GjRz/z3k4A3t7eeHt7P/N5ClJadRXC0Mhj5wbi6T8wpqamWFtb4+LiwuDBg3nllVf0VLOyc+vWLXr27Mnrr7/Of/7zH31XRwhhgCRIGZhp06YBeTvhXrt2jcOHDxMaGspff/3FnDlz9Fw7TbNnz8bPz88gthQRQlRMEqQMzPTp0zV+P3nyJOPGjSMwMJDRo0cXuKNvebOzs8POzk7f1RBCVGAyJmXgPD09cXZ2RqlUcv78eUBzjOjatWvMmjULT09PXF1dCQ0NVZdNSkpi6dKl9O/fn9atW+Pm5oavry/Hjx/Xea2UlBQ+/fRTvLy8UCgU9OvXj4CAgHx3fy1ojOfcuXPMmjWLrl270qpVK7p06cL48ePZv38/ACtXrqRnz54A/PDDD7i4uKhfu3bt0jjXsWPH8PPzo2PHjrRq1YpevXrx3//+l4cPH+qs14kTJxgxYgRt27bFw8ODKVOmcOXKlULe6aLJzMxk8+bN+Pn50aNHD1q1aoWHhwdjx47lt99+K7Dso0ePWLhwIV27dkWhUDBgwAA2btyY7/t79uxZZsyYwYsvvkirVq3o1q0b8+bNIz4+vlTuRYjngbSkngP5bTl/8+ZNhg4dipOTEy+//DLp6elYWloCefsNjR49mtjYWDp06EDXrl15/PgxISEhTJw4kYULF2qsYJ6ZmcnYsWM5f/48rq6uvPzyyzx69IivvvqKsLCwYtX3+++/x9/fH1NTU7y9vXFyciIhIYELFy4QFBTEgAED8PDwYMyYMWzcuBFXV1d69eqlLt+8eXP1z6tWrWLlypXY2NjQvXt3atWqRVRUFOvXr+fo0aNs27ZNfc+QtwPuW2+9hbm5OQMGDMDW1pbTp08zbNiwUplYkJyczOLFi2nXrh2dO3emVq1a3Lt3j5CQECZNmsTHH3/MkCFDtMqp3t9Hjx7x0ksvkZWVxaFDh1i8eDHXrl1j/vz5Gvl37tzJRx99hIWFBd7e3jg4OHDjxg22b9/OkSNH+P7773F0dHzm+xHC4CmFQWjWrJmyWbNmWsd///13pYuLi9LFxUV569YtpVKpVMbExKjzL126VOf5Ro0apXRxcVH+9NNPGseTk5OVr7zyilKhUCjv3bunPv71118rmzVrppw2bZoyJydHffzmzZtKd3d3ZbNmzZTvvfeexrnee+89ZbNmzZQxMTHqY9HR0coWLVoo3d3dlVFRUVr1unPnjvpn1X08fV6VkydPKps1a6Z84403lMnJyRppO3fuVDZr1ky5ePFi9bGUlBSlh4eHskWLFspz585p5F+8eLH6PXuyvgUZNWqU1meSkZGhcQ8qDx8+VL700ktKd3d35ePHjzXSevTooWzWrJly2LBhyoyMDPXxBw8eKHv27Kls1qyZMiwsTH386tWrypYtWyp79eqljIuL0zjXiRMnlK6ursopU6YUWlchKgLp7jMwK1euZOXKlSxfvpwZM2YwceJElEolvr6+1KtXTyNvnTp11BMtnnTp0iXCwsLo06cPL730kkaatbU106dPJyMjg0OHDqmP79q1C1NTU959911MTf/5Z9GgQQNGjx5d5PoHBQWRnZ3NlClTaNq0qVZ6fnts6bJp0yYAFi1ahLW1tUbawIEDad68OXv37lUfCw4OJikpCR8fHxQKhUb+6dOnY2VlVeRr58fCwkLnPVhZWTFo0CD1hoS6vP3221hYWKh/t7GxYcqUKQAaXZxBQUFkZWUxd+5crUkpnp6eeHt7ExISorFTrxAVlXT3GZhVq1YBeV171tbWuLm5MXjwYF599VWtvK6urhp/9FT+/PNPIG+MaeXKlVrpiYmJAFy9elWd78aNG9StW5eGDRtq5ffw8Chy/SMiIgDo2rVrkcsUdC5zc3MOHjzIwYMHtdKzsrJITEzkwYMH1KxZk4sXLwLg7u6uldfKyormzZsXu+tSl+joaNatW0d4eDj37t0jIyNDI13XmJGZmRnt2rXTOq56b1V1h3/ew7CwMJ0BLyEhgZycHK5fv06rVq2e6V6EMHQSpAzM5cuXi5y3Tp06Oo8nJSUB8Pvvv/P777/nWz4tLQ1A/Y28du3axbqOLo8ePQIolWnpSUlJZGdnqwN3ftLS0qhZs6b62vnVtzj3kZ+IiAh8fX3JycmhU6dOeHt7Y2lpiampKZGRkQQHB5OZmalVrmbNmjp30bW1tQX+ed/gn89v3bp1BdZF9fkJUZFJkHqOPT2RQkXVrTV37lzGjBlT6HlUEw8SEhJ0pt+/f7/IdVJdOz4+XmNCQ0lYWlqiVCqL3PpRXTu/+hbnPvLz9ddfk56ezsaNG+nYsaNG2urVqwkODtZZ7sGDB+Tk5GgFqnv37gFodEWq3rfTp08/83soxPNOxqQqoDZt2gBw6tSpIuW3tLSkUaNGxMfHc/PmTa304nSRtW3bFsibNl4Y1R/snJycfM+VnJxMdHR0ka7dokULAMLDw7XSHj16RGRkZJHOU5AbN25gY2OjFaCg4PcpOztb3Q2rq4yq7vDPe1jUz0+IikyCVAWkUCjo0KEDv/zyCzt27NCZ5/Llyxotp4EDB5Kbm8uSJUvIzc1VH4+JiVFPYCiK4cOHY2ZmxldffcXff/+tlR4XF6f+2draGhMTE+7cuaPzXGPHjgXgo48+0jnOk5aWph6/AejZsyc1atTgp59+0hrLWblypUaXWknVq1ePpKQkLl26pHF8+/bt+T5/prJ06VKNrsCkpCS+/vprIO/9Vxk5ciTm5uZ8+umnXLt2Tes8mZmZEsCE0ZDuvgpq6dKl+Pr6MnfuXDZt2kSbNm2wsrIiLi6OqKgooqKi2LZtm3ocavz48Rw+fJhDhw7x+uuv06VLFx49esSBAwfo0KEDR44cKdJ1mzRpwvz585k/fz6vvfYaPXv2xMnJiQcPHnDhwgWqV6+uDnrVq1enTZs2nDp1irfffpvGjRurn61ydXXF09OTt99+m2XLltG3b1+8vLyoX78+aWlp3L59m/DwcNq3b68eu6levToLFy7krbfeYuTIkRrPSUVHR+Pu7q6zlVUcqoehR4wYQf/+/bGysuLChQucPn2avn37asyYfJKtrS2ZmZn4+Pjg7e1NdnY2Bw8e5N69e4wYMUJjsscLL7zA4sWLmTt3Lj4+PnTt2hUnJyeys7O5ffs2p0+fpmbNmjonkwhR0UiQqqAcHBzYuXMnmzdv5ueff2bv3r3k5ORQp04dmjRpwqhRo2jWrJk6v4WFBRs2bGDlypXs37+fjRs3Uq9ePf71r3/Ru3fvIgcpgKFDh9K0aVPWr19PWFgYwcHB2NjY4OLiovWg6//+9z8+/fRTjh8/zr59+1AqlTg4OODq6grApEmTaN++PZs2beL06dMcOXIES0tL7O3tGTp0KD4+Phrn69evH1ZWVqxatYoDBw5gYWFBhw4d+O6771i7du0zBykvLy+++eYbvv76a/bv30+lSpVo3bo1GzduJCYmJt8gpXp/ly1bxr59+3jw4AENGjRg0qRJOqf4v/rqq7i6uhIQEEBoaCjHjx+nWrVq2NnZ0bdvX/r37/9M9yHE88JEqcxnTRYhhBBCz2RMSgghhMGSICWEEMJgSZASQghhsCRICSGEMFgSpIQQQhgsCVJCCCEMlgQpIYQQBkuClBBCCIMlQUoIIYTBkiAlhBDCYP0faTS7mHM2MBYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = init_data()\n",
    "binary_classification_train_demo(X_train, X_test, y_train, y_test, activation='sigmoid', loss=binary_focal_loss(gamma=2., alpha=.25, mask_value=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid + 欠損ラベル作成して、maskありでbinary_Focal_Loss使用\n",
    "- うまくいってる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0    4916815\n",
      "-1.0     166715\n",
      " 0.0       6566\n",
      "Name: 0, dtype: int64\n",
      " 0.0    5083530\n",
      " 1.0       6351\n",
      "-1.0        215\n",
      "Name: 1, dtype: int64\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "Epoch 1/3\n",
      "5090096/5090096 [==============================] - 24s 5us/step - loss: 2.7719 - acc: 0.9645\n",
      "Epoch 2/3\n",
      "5090096/5090096 [==============================] - 23s 5us/step - loss: 1.0466 - acc: 0.9665\n",
      "Epoch 3/3\n",
      "5090096/5090096 [==============================] - 24s 5us/step - loss: 0.9097 - acc: 0.9666\n",
      "1272524/1272524 [==============================] - 2s 1us/step\n",
      "['loss', 'acc'] [1.0406536880686525, 0.9993540462714668]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = init_data()\n",
    "\n",
    "mask_value = -1.0\n",
    "\n",
    "_df = pd.DataFrame(y_train)\n",
    "#print(_df.shape)\n",
    "#display(_df.head())\n",
    "\n",
    "_df0 = _df[_df[0] == 1.0]\n",
    "#print(_df0.shape)\n",
    "_ids = np.random.choice(_df0.index, _df0.shape[0]//30)\n",
    "#print(_ids[:5])\n",
    "_df.loc[_ids,0] = mask_value\n",
    "\n",
    "_df1 = _df[_df[1] == 1.0]\n",
    "#print(_df1.shape)\n",
    "_ids = np.random.choice(_df1.index, _df1.shape[0]//30)\n",
    "#print(_ids[:5])\n",
    "_df.loc[_ids,1] = mask_value\n",
    "\n",
    "print(_df[0].value_counts())\n",
    "print(_df[1].value_counts())\n",
    "\n",
    "y_train_mask = np.array(_df)\n",
    "print(y_train_mask)\n",
    "\n",
    "binary_classification_train_demo(X_train, X_test\n",
    "                                 , y_train_mask\n",
    "                                 , y_test\n",
    "                                 , activation='sigmoid', loss=binary_focal_loss(gamma=2., alpha=.25, mask_value=mask_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### softmax + Focal Lossなし\n",
    "- うまくいってる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5090096/5090096 [==============================] - 23s 4us/step - loss: 0.0099 - acc: 0.9982\n",
      "Epoch 2/3\n",
      "5090096/5090096 [==============================] - 23s 4us/step - loss: 0.0037 - acc: 0.9993\n",
      "Epoch 3/3\n",
      "5090096/5090096 [==============================] - 23s 4us/step - loss: 0.0033 - acc: 0.9994\n",
      "1272524/1272524 [==============================] - 2s 1us/step\n",
      "['loss', 'acc'] [0.003227625273607976, 0.9993438307666886]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = init_data()\n",
    "binary_classification_train_demo(X_train, X_test, y_train, y_test, activation='softmax', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### softmax + categorical_Focal_Lossあり\n",
    "- うまくいってて、精度上がってる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "5090096/5090096 [==============================] - 24s 5us/step - loss: 0.0011 - acc: 0.9956\n",
      "Epoch 2/3\n",
      "5090096/5090096 [==============================] - 24s 5us/step - loss: 2.9174e-04 - acc: 0.9993\n",
      "Epoch 3/3\n",
      "5090096/5090096 [==============================] - 24s 5us/step - loss: 2.5708e-04 - acc: 0.9993\n",
      "1272524/1272524 [==============================] - 2s 1us/step\n",
      "['loss', 'acc'] [0.00023637541426469033, 0.9993642623851611]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = init_data()\n",
    "binary_classification_train_demo(X_train, X_test, y_train, y_test, activation='softmax', loss=categorical_focal_loss(gamma=2., alpha=.25, mask_value=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### softmax + 欠損ラベル作成して、maskありでcategorical_Focal_Loss使用\n",
    "- なんかおかしい。おそらく作った欠損ラベルがおかしい。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1.0    4916864\n",
      "-1.0     166666\n",
      " 0.0       6566\n",
      "Name: 0, dtype: int64\n",
      " 0.0    4916864\n",
      "-1.0     166666\n",
      " 1.0       6566\n",
      "Name: 1, dtype: int64\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n",
      "Epoch 1/3\n",
      "5090096/5090096 [==============================] - 24s 5us/step - loss: 7.4302e-06 - acc: 0.9987\n",
      "Epoch 2/3\n",
      "5090096/5090096 [==============================] - 23s 4us/step - loss: 4.0965e-22 - acc: 0.9987\n",
      "Epoch 3/3\n",
      "5090096/5090096 [==============================] - 23s 4us/step - loss: 4.0965e-22 - acc: 0.9987\n",
      "1272524/1272524 [==============================] - 2s 1us/step\n",
      "['loss', 'acc'] [4.235164736271502e-22, 0.9987057298387667]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = init_data()\n",
    "\n",
    "mask_value = -1.0\n",
    "\n",
    "_df = pd.DataFrame(y_train)\n",
    "#print(_df.shape)\n",
    "#display(_df.head())\n",
    "\n",
    "_df0 = _df[_df[0] == 1.0]\n",
    "#print(_df0.shape)\n",
    "_ids = np.random.choice(_df0.index, _df0.shape[0]//30)\n",
    "#print(_ids[:5])\n",
    "_df.loc[_ids] = mask_value\n",
    "#_df.loc[_ids,1] = mask_value\n",
    "\n",
    "print(_df[0].value_counts())\n",
    "print(_df[1].value_counts())\n",
    "\n",
    "y_train_mask = np.array(_df)\n",
    "print(y_train_mask)\n",
    "\n",
    "binary_classification_train_demo(X_train, X_test\n",
    "                                 , y_train_mask\n",
    "                                 , y_test\n",
    "                                 , activation='softmax'\n",
    "                                 , loss=categorical_focal_loss(gamma=2., alpha=.25, mask_value=mask_value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3node learning Demo\n",
    "- https://www.dlology.com/blog/how-to-multi-task-learning-with-missing-labels-in-keras/\n",
    "\n",
    "\n",
    "- 出力層3nodeの場合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_learning_demo(activation='sigmoid', loss='binary_crossentropy', mask_value=None):\n",
    "    \"\"\"\n",
    "    https://www.dlology.com/blog/how-to-multi-task-learning-with-missing-labels-in-keras/\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.model_selection  import train_test_split\n",
    "    import tensorflow as tf\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    import numpy as np\n",
    "    seed = 42\n",
    "    np.random.seed(seed) # 乱数シード固定\n",
    "    \n",
    "    # 2D空間で100,000個のデータポイントをランダムに生成します。各軸の範囲は0〜1\n",
    "    N =100000\n",
    "    X = np.random.rand(N,2)\n",
    "    \n",
    "    threshold = 0.5\n",
    "    if isinstance(loss, str) == False:\n",
    "        # focal loss用に不均衡にする\n",
    "        threshold = 0.05\n",
    "    \n",
    "    # place holder for Y\n",
    "    Y = np.ones((N,3))\n",
    "    if activation == 'sigmoid':\n",
    "        print('sigmoid')\n",
    "        Y[:,0] = X[:, 1] <= threshold\n",
    "        Y[:,1] = X[:, 0] >= threshold\n",
    "        Y[:,2] = X[:, 0] + X[:, 1] > 1\n",
    "    else:\n",
    "        print('not sigmoid')\n",
    "        Y[:,0] = X[:, 1] <= threshold\n",
    "        Y[:,1] = X[:, 1] > threshold\n",
    "        Y[:,2] = 0\n",
    "\n",
    "    # Mask for missing label.\n",
    "    if mask_value is not None:\n",
    "        # Drop 2% y0.\n",
    "        Y[: int(N*0.020), 0] = mask_value\n",
    "        # Drop 0.7% y1.\n",
    "        Y[int(N*0.018): int(N*0.025), 1] = mask_value\n",
    "        # Drop 1.1% y2.\n",
    "        Y[int(N*0.024): int(N*0.035), 2] = mask_value\n",
    "\n",
    "    print(Y.shape, Y)\n",
    "    for i in range(3): \n",
    "        print(pd.Series(Y[:,i]).value_counts())\n",
    "        \n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(X[:-3000], Y[:-3000], test_size=0.9, random_state=seed)\n",
    "\n",
    "    K.clear_session()\n",
    "    model = Sequential()\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    nb_classes = y_train.shape[1]\n",
    "    print('input_dim, nb_classes:', input_dim, nb_classes)\n",
    "\n",
    "    model.add(Dense(10, input_dim=input_dim, activation='relu', name='input'))\n",
    "    model.add(Dense(20, activation='relu', name='fc1'))\n",
    "    model.add(Dense(10, activation='relu', name='fc2'))\n",
    "    model.add(Dense(nb_classes, activation=activation, name='output'))\n",
    "\n",
    "    model.compile(loss=loss, optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_dev,y_dev), epochs=300, batch_size=500000)\n",
    "\n",
    "    print(model.metrics_names, model.evaluate(X[-3000:],Y[-3000:]))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid + Focal Lossなし\n",
    "- うまくいってる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid\n",
      "(100000, 3) [[0. 0. 1.]\n",
      " [0. 1. 1.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0.]\n",
      " [1. 1. 0.]\n",
      " [1. 1. 0.]]\n",
      "0.0    50159\n",
      "1.0    49841\n",
      "dtype: int64\n",
      "1.0    50073\n",
      "0.0    49927\n",
      "dtype: int64\n",
      "1.0    50034\n",
      "0.0    49966\n",
      "dtype: int64\n",
      "input_dim, nb_classes: 2 3\n",
      "Train on 9700 samples, validate on 87300 samples\n",
      "Epoch 1/300\n",
      "9700/9700 [==============================] - 0s 16us/step - loss: 0.6875 - acc: 0.4843 - val_loss: 0.6845 - val_acc: 0.5732\n",
      "Epoch 2/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6847 - acc: 0.5727 - val_loss: 0.6826 - val_acc: 0.6072\n",
      "Epoch 3/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6828 - acc: 0.6048 - val_loss: 0.6810 - val_acc: 0.6315\n",
      "Epoch 4/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6812 - acc: 0.6300 - val_loss: 0.6794 - val_acc: 0.6553\n",
      "Epoch 5/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6796 - acc: 0.6553 - val_loss: 0.6778 - val_acc: 0.6817\n",
      "Epoch 6/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6780 - acc: 0.6796 - val_loss: 0.6762 - val_acc: 0.6957\n",
      "Epoch 7/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6765 - acc: 0.6940 - val_loss: 0.6746 - val_acc: 0.7064\n",
      "Epoch 8/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6749 - acc: 0.7060 - val_loss: 0.6730 - val_acc: 0.7147\n",
      "Epoch 9/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6733 - acc: 0.7147 - val_loss: 0.6713 - val_acc: 0.7207\n",
      "Epoch 10/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6716 - acc: 0.7203 - val_loss: 0.6696 - val_acc: 0.7263\n",
      "Epoch 11/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6699 - acc: 0.7262 - val_loss: 0.6679 - val_acc: 0.7315\n",
      "Epoch 12/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6682 - acc: 0.7319 - val_loss: 0.6661 - val_acc: 0.7359\n",
      "Epoch 13/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6664 - acc: 0.7363 - val_loss: 0.6642 - val_acc: 0.7402\n",
      "Epoch 14/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6646 - acc: 0.7409 - val_loss: 0.6624 - val_acc: 0.7461\n",
      "Epoch 15/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6627 - acc: 0.7471 - val_loss: 0.6605 - val_acc: 0.7508\n",
      "Epoch 16/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6608 - acc: 0.7518 - val_loss: 0.6585 - val_acc: 0.7550\n",
      "Epoch 17/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6589 - acc: 0.7562 - val_loss: 0.6565 - val_acc: 0.7581\n",
      "Epoch 18/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6569 - acc: 0.7591 - val_loss: 0.6545 - val_acc: 0.7608\n",
      "Epoch 19/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6548 - acc: 0.7614 - val_loss: 0.6524 - val_acc: 0.7629\n",
      "Epoch 20/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6527 - acc: 0.7637 - val_loss: 0.6502 - val_acc: 0.7648\n",
      "Epoch 21/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6506 - acc: 0.7655 - val_loss: 0.6480 - val_acc: 0.7662\n",
      "Epoch 22/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6484 - acc: 0.7670 - val_loss: 0.6457 - val_acc: 0.7677\n",
      "Epoch 23/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6461 - acc: 0.7679 - val_loss: 0.6433 - val_acc: 0.7691\n",
      "Epoch 24/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6438 - acc: 0.7691 - val_loss: 0.6409 - val_acc: 0.7704\n",
      "Epoch 25/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6414 - acc: 0.7698 - val_loss: 0.6384 - val_acc: 0.7715\n",
      "Epoch 26/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6389 - acc: 0.7707 - val_loss: 0.6357 - val_acc: 0.7730\n",
      "Epoch 27/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6362 - acc: 0.7713 - val_loss: 0.6330 - val_acc: 0.7742\n",
      "Epoch 28/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6335 - acc: 0.7726 - val_loss: 0.6302 - val_acc: 0.7751\n",
      "Epoch 29/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6307 - acc: 0.7738 - val_loss: 0.6273 - val_acc: 0.7762\n",
      "Epoch 30/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6279 - acc: 0.7746 - val_loss: 0.6243 - val_acc: 0.7771\n",
      "Epoch 31/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6249 - acc: 0.7752 - val_loss: 0.6213 - val_acc: 0.7779\n",
      "Epoch 32/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6219 - acc: 0.7760 - val_loss: 0.6182 - val_acc: 0.7786\n",
      "Epoch 33/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6188 - acc: 0.7765 - val_loss: 0.6150 - val_acc: 0.7795\n",
      "Epoch 34/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6157 - acc: 0.7774 - val_loss: 0.6118 - val_acc: 0.7804\n",
      "Epoch 35/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6125 - acc: 0.7781 - val_loss: 0.6085 - val_acc: 0.7815\n",
      "Epoch 36/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6092 - acc: 0.7788 - val_loss: 0.6051 - val_acc: 0.7827\n",
      "Epoch 37/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6059 - acc: 0.7805 - val_loss: 0.6017 - val_acc: 0.7842\n",
      "Epoch 38/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6025 - acc: 0.7822 - val_loss: 0.5982 - val_acc: 0.7857\n",
      "Epoch 39/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5990 - acc: 0.7838 - val_loss: 0.5947 - val_acc: 0.7872\n",
      "Epoch 40/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5955 - acc: 0.7854 - val_loss: 0.5910 - val_acc: 0.7889\n",
      "Epoch 41/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5919 - acc: 0.7867 - val_loss: 0.5874 - val_acc: 0.7905\n",
      "Epoch 42/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5883 - acc: 0.7885 - val_loss: 0.5836 - val_acc: 0.7920\n",
      "Epoch 43/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5845 - acc: 0.7903 - val_loss: 0.5798 - val_acc: 0.7937\n",
      "Epoch 44/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5808 - acc: 0.7919 - val_loss: 0.5759 - val_acc: 0.7954\n",
      "Epoch 45/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5769 - acc: 0.7943 - val_loss: 0.5720 - val_acc: 0.7972\n",
      "Epoch 46/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5730 - acc: 0.7959 - val_loss: 0.5680 - val_acc: 0.7989\n",
      "Epoch 47/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5690 - acc: 0.7976 - val_loss: 0.5640 - val_acc: 0.8007\n",
      "Epoch 48/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5650 - acc: 0.7993 - val_loss: 0.5599 - val_acc: 0.8024\n",
      "Epoch 49/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5610 - acc: 0.8015 - val_loss: 0.5557 - val_acc: 0.8041\n",
      "Epoch 50/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5568 - acc: 0.8032 - val_loss: 0.5515 - val_acc: 0.8060\n",
      "Epoch 51/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5527 - acc: 0.8050 - val_loss: 0.5473 - val_acc: 0.8079\n",
      "Epoch 52/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5484 - acc: 0.8071 - val_loss: 0.5430 - val_acc: 0.8098\n",
      "Epoch 53/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5441 - acc: 0.8093 - val_loss: 0.5386 - val_acc: 0.8119\n",
      "Epoch 54/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5398 - acc: 0.8116 - val_loss: 0.5342 - val_acc: 0.8140\n",
      "Epoch 55/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5354 - acc: 0.8138 - val_loss: 0.5298 - val_acc: 0.8162\n",
      "Epoch 56/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5310 - acc: 0.8162 - val_loss: 0.5253 - val_acc: 0.8181\n",
      "Epoch 57/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5265 - acc: 0.8184 - val_loss: 0.5207 - val_acc: 0.8203\n",
      "Epoch 58/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5219 - acc: 0.8202 - val_loss: 0.5161 - val_acc: 0.8224\n",
      "Epoch 59/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5173 - acc: 0.8228 - val_loss: 0.5115 - val_acc: 0.8247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5127 - acc: 0.8246 - val_loss: 0.5068 - val_acc: 0.8269\n",
      "Epoch 61/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5080 - acc: 0.8265 - val_loss: 0.5021 - val_acc: 0.8291\n",
      "Epoch 62/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5033 - acc: 0.8285 - val_loss: 0.4973 - val_acc: 0.8312\n",
      "Epoch 63/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4986 - acc: 0.8303 - val_loss: 0.4926 - val_acc: 0.8332\n",
      "Epoch 64/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4938 - acc: 0.8319 - val_loss: 0.4878 - val_acc: 0.8354\n",
      "Epoch 65/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4890 - acc: 0.8339 - val_loss: 0.4830 - val_acc: 0.8376\n",
      "Epoch 66/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4842 - acc: 0.8363 - val_loss: 0.4781 - val_acc: 0.8399\n",
      "Epoch 67/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4793 - acc: 0.8382 - val_loss: 0.4732 - val_acc: 0.8422\n",
      "Epoch 68/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4744 - acc: 0.8405 - val_loss: 0.4683 - val_acc: 0.8444\n",
      "Epoch 69/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4695 - acc: 0.8429 - val_loss: 0.4634 - val_acc: 0.8468\n",
      "Epoch 70/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4646 - acc: 0.8457 - val_loss: 0.4585 - val_acc: 0.8491\n",
      "Epoch 71/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4596 - acc: 0.8487 - val_loss: 0.4535 - val_acc: 0.8514\n",
      "Epoch 72/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4547 - acc: 0.8509 - val_loss: 0.4486 - val_acc: 0.8538\n",
      "Epoch 73/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4497 - acc: 0.8531 - val_loss: 0.4436 - val_acc: 0.8561\n",
      "Epoch 74/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4448 - acc: 0.8556 - val_loss: 0.4387 - val_acc: 0.8584\n",
      "Epoch 75/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4398 - acc: 0.8579 - val_loss: 0.4337 - val_acc: 0.8606\n",
      "Epoch 76/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4348 - acc: 0.8607 - val_loss: 0.4287 - val_acc: 0.8631\n",
      "Epoch 77/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4298 - acc: 0.8633 - val_loss: 0.4238 - val_acc: 0.8655\n",
      "Epoch 78/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4249 - acc: 0.8661 - val_loss: 0.4188 - val_acc: 0.8680\n",
      "Epoch 79/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4199 - acc: 0.8678 - val_loss: 0.4139 - val_acc: 0.8705\n",
      "Epoch 80/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4149 - acc: 0.8703 - val_loss: 0.4089 - val_acc: 0.8732\n",
      "Epoch 81/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4100 - acc: 0.8724 - val_loss: 0.4040 - val_acc: 0.8757\n",
      "Epoch 82/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4050 - acc: 0.8744 - val_loss: 0.3991 - val_acc: 0.8782\n",
      "Epoch 83/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4001 - acc: 0.8769 - val_loss: 0.3942 - val_acc: 0.8807\n",
      "Epoch 84/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3952 - acc: 0.8793 - val_loss: 0.3894 - val_acc: 0.8833\n",
      "Epoch 85/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3903 - acc: 0.8820 - val_loss: 0.3845 - val_acc: 0.8858\n",
      "Epoch 86/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3854 - acc: 0.8843 - val_loss: 0.3797 - val_acc: 0.8882\n",
      "Epoch 87/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3806 - acc: 0.8865 - val_loss: 0.3749 - val_acc: 0.8908\n",
      "Epoch 88/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3758 - acc: 0.8885 - val_loss: 0.3701 - val_acc: 0.8932\n",
      "Epoch 89/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3710 - acc: 0.8917 - val_loss: 0.3653 - val_acc: 0.8956\n",
      "Epoch 90/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3662 - acc: 0.8944 - val_loss: 0.3606 - val_acc: 0.8980\n",
      "Epoch 91/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3614 - acc: 0.8970 - val_loss: 0.3559 - val_acc: 0.9002\n",
      "Epoch 92/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3567 - acc: 0.8995 - val_loss: 0.3513 - val_acc: 0.9026\n",
      "Epoch 93/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3521 - acc: 0.9028 - val_loss: 0.3467 - val_acc: 0.9051\n",
      "Epoch 94/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3474 - acc: 0.9046 - val_loss: 0.3421 - val_acc: 0.9071\n",
      "Epoch 95/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3428 - acc: 0.9065 - val_loss: 0.3376 - val_acc: 0.9092\n",
      "Epoch 96/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3383 - acc: 0.9084 - val_loss: 0.3330 - val_acc: 0.9112\n",
      "Epoch 97/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3337 - acc: 0.9100 - val_loss: 0.3286 - val_acc: 0.9131\n",
      "Epoch 98/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3293 - acc: 0.9120 - val_loss: 0.3242 - val_acc: 0.9150\n",
      "Epoch 99/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3248 - acc: 0.9142 - val_loss: 0.3198 - val_acc: 0.9167\n",
      "Epoch 100/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3204 - acc: 0.9157 - val_loss: 0.3154 - val_acc: 0.9185\n",
      "Epoch 101/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3160 - acc: 0.9175 - val_loss: 0.3111 - val_acc: 0.9200\n",
      "Epoch 102/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3117 - acc: 0.9196 - val_loss: 0.3069 - val_acc: 0.9218\n",
      "Epoch 103/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3074 - acc: 0.9212 - val_loss: 0.3027 - val_acc: 0.9234\n",
      "Epoch 104/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3032 - acc: 0.9227 - val_loss: 0.2985 - val_acc: 0.9253\n",
      "Epoch 105/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2990 - acc: 0.9245 - val_loss: 0.2944 - val_acc: 0.9270\n",
      "Epoch 106/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2949 - acc: 0.9263 - val_loss: 0.2903 - val_acc: 0.9285\n",
      "Epoch 107/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2907 - acc: 0.9280 - val_loss: 0.2862 - val_acc: 0.9301\n",
      "Epoch 108/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2867 - acc: 0.9297 - val_loss: 0.2822 - val_acc: 0.9317\n",
      "Epoch 109/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2826 - acc: 0.9316 - val_loss: 0.2783 - val_acc: 0.9334\n",
      "Epoch 110/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2787 - acc: 0.9332 - val_loss: 0.2744 - val_acc: 0.9350\n",
      "Epoch 111/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2747 - acc: 0.9347 - val_loss: 0.2705 - val_acc: 0.9366\n",
      "Epoch 112/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2708 - acc: 0.9362 - val_loss: 0.2667 - val_acc: 0.9384\n",
      "Epoch 113/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2670 - acc: 0.9375 - val_loss: 0.2629 - val_acc: 0.9399\n",
      "Epoch 114/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2632 - acc: 0.9398 - val_loss: 0.2591 - val_acc: 0.9414\n",
      "Epoch 115/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2594 - acc: 0.9412 - val_loss: 0.2555 - val_acc: 0.9430\n",
      "Epoch 116/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2557 - acc: 0.9431 - val_loss: 0.2518 - val_acc: 0.9447\n",
      "Epoch 117/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2520 - acc: 0.9446 - val_loss: 0.2482 - val_acc: 0.9461\n",
      "Epoch 118/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2484 - acc: 0.9457 - val_loss: 0.2447 - val_acc: 0.9475\n",
      "Epoch 119/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2449 - acc: 0.9475 - val_loss: 0.2412 - val_acc: 0.9491\n",
      "Epoch 120/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2413 - acc: 0.9492 - val_loss: 0.2377 - val_acc: 0.9505\n",
      "Epoch 121/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2379 - acc: 0.9508 - val_loss: 0.2343 - val_acc: 0.9520\n",
      "Epoch 122/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2344 - acc: 0.9522 - val_loss: 0.2310 - val_acc: 0.9533\n",
      "Epoch 123/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2311 - acc: 0.9534 - val_loss: 0.2277 - val_acc: 0.9547\n",
      "Epoch 124/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2277 - acc: 0.9548 - val_loss: 0.2244 - val_acc: 0.9559\n",
      "Epoch 125/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2245 - acc: 0.9561 - val_loss: 0.2212 - val_acc: 0.9573\n",
      "Epoch 126/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2213 - acc: 0.9574 - val_loss: 0.2181 - val_acc: 0.9586\n",
      "Epoch 127/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2181 - acc: 0.9587 - val_loss: 0.2150 - val_acc: 0.9598\n",
      "Epoch 128/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2150 - acc: 0.9602 - val_loss: 0.2120 - val_acc: 0.9608\n",
      "Epoch 129/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2120 - acc: 0.9615 - val_loss: 0.2090 - val_acc: 0.9620\n",
      "Epoch 130/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2090 - acc: 0.9624 - val_loss: 0.2061 - val_acc: 0.9630\n",
      "Epoch 131/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2061 - acc: 0.9634 - val_loss: 0.2033 - val_acc: 0.9641\n",
      "Epoch 132/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2032 - acc: 0.9643 - val_loss: 0.2005 - val_acc: 0.9650\n",
      "Epoch 133/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2004 - acc: 0.9654 - val_loss: 0.1977 - val_acc: 0.9658\n",
      "Epoch 134/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1977 - acc: 0.9667 - val_loss: 0.1950 - val_acc: 0.9668\n",
      "Epoch 135/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1949 - acc: 0.9674 - val_loss: 0.1924 - val_acc: 0.9676\n",
      "Epoch 136/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1923 - acc: 0.9682 - val_loss: 0.1898 - val_acc: 0.9684\n",
      "Epoch 137/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1897 - acc: 0.9691 - val_loss: 0.1872 - val_acc: 0.9692\n",
      "Epoch 138/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1871 - acc: 0.9698 - val_loss: 0.1847 - val_acc: 0.9700\n",
      "Epoch 139/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1846 - acc: 0.9705 - val_loss: 0.1823 - val_acc: 0.9706\n",
      "Epoch 140/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1822 - acc: 0.9713 - val_loss: 0.1799 - val_acc: 0.9713\n",
      "Epoch 141/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1798 - acc: 0.9715 - val_loss: 0.1776 - val_acc: 0.9719\n",
      "Epoch 142/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1774 - acc: 0.9725 - val_loss: 0.1753 - val_acc: 0.9726\n",
      "Epoch 143/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1751 - acc: 0.9730 - val_loss: 0.1730 - val_acc: 0.9732\n",
      "Epoch 144/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1729 - acc: 0.9735 - val_loss: 0.1708 - val_acc: 0.9738\n",
      "Epoch 145/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1707 - acc: 0.9740 - val_loss: 0.1687 - val_acc: 0.9744\n",
      "Epoch 146/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1685 - acc: 0.9744 - val_loss: 0.1666 - val_acc: 0.9750\n",
      "Epoch 147/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1664 - acc: 0.9751 - val_loss: 0.1645 - val_acc: 0.9754\n",
      "Epoch 148/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1643 - acc: 0.9755 - val_loss: 0.1625 - val_acc: 0.9760\n",
      "Epoch 149/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1623 - acc: 0.9759 - val_loss: 0.1605 - val_acc: 0.9764\n",
      "Epoch 150/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1603 - acc: 0.9764 - val_loss: 0.1585 - val_acc: 0.9770\n",
      "Epoch 151/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1584 - acc: 0.9770 - val_loss: 0.1566 - val_acc: 0.9773\n",
      "Epoch 152/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1565 - acc: 0.9774 - val_loss: 0.1548 - val_acc: 0.9779\n",
      "Epoch 153/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1546 - acc: 0.9782 - val_loss: 0.1530 - val_acc: 0.9781\n",
      "Epoch 154/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1528 - acc: 0.9781 - val_loss: 0.1512 - val_acc: 0.9790\n",
      "Epoch 155/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1510 - acc: 0.9792 - val_loss: 0.1494 - val_acc: 0.9786\n",
      "Epoch 156/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1493 - acc: 0.9789 - val_loss: 0.1478 - val_acc: 0.9802\n",
      "Epoch 157/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1476 - acc: 0.9804 - val_loss: 0.1460 - val_acc: 0.9787\n",
      "Epoch 158/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1459 - acc: 0.9788 - val_loss: 0.1445 - val_acc: 0.9816\n",
      "Epoch 159/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1443 - acc: 0.9817 - val_loss: 0.1429 - val_acc: 0.9780\n",
      "Epoch 160/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1428 - acc: 0.9780 - val_loss: 0.1417 - val_acc: 0.9831\n",
      "Epoch 161/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1414 - acc: 0.9833 - val_loss: 0.1401 - val_acc: 0.9762\n",
      "Epoch 162/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1401 - acc: 0.9758 - val_loss: 0.1392 - val_acc: 0.9839\n",
      "Epoch 163/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1388 - acc: 0.9837 - val_loss: 0.1375 - val_acc: 0.9752\n",
      "Epoch 164/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1375 - acc: 0.9745 - val_loss: 0.1364 - val_acc: 0.9841\n",
      "Epoch 165/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1361 - acc: 0.9840 - val_loss: 0.1346 - val_acc: 0.9767\n",
      "Epoch 166/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1346 - acc: 0.9763 - val_loss: 0.1333 - val_acc: 0.9840\n",
      "Epoch 167/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1330 - acc: 0.9842 - val_loss: 0.1316 - val_acc: 0.9790\n",
      "Epoch 168/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1316 - acc: 0.9788 - val_loss: 0.1304 - val_acc: 0.9838\n",
      "Epoch 169/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1302 - acc: 0.9840 - val_loss: 0.1289 - val_acc: 0.9806\n",
      "Epoch 170/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1288 - acc: 0.9807 - val_loss: 0.1277 - val_acc: 0.9836\n",
      "Epoch 171/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1275 - acc: 0.9835 - val_loss: 0.1264 - val_acc: 0.9816\n",
      "Epoch 172/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1263 - acc: 0.9816 - val_loss: 0.1252 - val_acc: 0.9835\n",
      "Epoch 173/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1251 - acc: 0.9833 - val_loss: 0.1240 - val_acc: 0.9822\n",
      "Epoch 174/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1239 - acc: 0.9825 - val_loss: 0.1229 - val_acc: 0.9836\n",
      "Epoch 175/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1228 - acc: 0.9835 - val_loss: 0.1217 - val_acc: 0.9826\n",
      "Epoch 176/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1216 - acc: 0.9829 - val_loss: 0.1206 - val_acc: 0.9837\n",
      "Epoch 177/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1205 - acc: 0.9836 - val_loss: 0.1195 - val_acc: 0.9830\n",
      "Epoch 178/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1194 - acc: 0.9834 - val_loss: 0.1185 - val_acc: 0.9838\n",
      "Epoch 179/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1184 - acc: 0.9840 - val_loss: 0.1174 - val_acc: 0.9833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1173 - acc: 0.9834 - val_loss: 0.1164 - val_acc: 0.9841\n",
      "Epoch 181/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1163 - acc: 0.9839 - val_loss: 0.1154 - val_acc: 0.9836\n",
      "Epoch 182/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1153 - acc: 0.9836 - val_loss: 0.1144 - val_acc: 0.9843\n",
      "Epoch 183/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1143 - acc: 0.9838 - val_loss: 0.1134 - val_acc: 0.9839\n",
      "Epoch 184/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1133 - acc: 0.9839 - val_loss: 0.1125 - val_acc: 0.9844\n",
      "Epoch 185/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1124 - acc: 0.9840 - val_loss: 0.1115 - val_acc: 0.9841\n",
      "Epoch 186/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1115 - acc: 0.9837 - val_loss: 0.1106 - val_acc: 0.9847\n",
      "Epoch 187/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1105 - acc: 0.9843 - val_loss: 0.1097 - val_acc: 0.9842\n",
      "Epoch 188/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1096 - acc: 0.9838 - val_loss: 0.1088 - val_acc: 0.9850\n",
      "Epoch 189/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1087 - acc: 0.9843 - val_loss: 0.1079 - val_acc: 0.9844\n",
      "Epoch 190/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1079 - acc: 0.9838 - val_loss: 0.1070 - val_acc: 0.9853\n",
      "Epoch 191/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1070 - acc: 0.9849 - val_loss: 0.1062 - val_acc: 0.9845\n",
      "Epoch 192/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1062 - acc: 0.9839 - val_loss: 0.1054 - val_acc: 0.9855\n",
      "Epoch 193/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1053 - acc: 0.9853 - val_loss: 0.1045 - val_acc: 0.9846\n",
      "Epoch 194/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1045 - acc: 0.9841 - val_loss: 0.1038 - val_acc: 0.9859\n",
      "Epoch 195/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1037 - acc: 0.9856 - val_loss: 0.1029 - val_acc: 0.9845\n",
      "Epoch 196/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1030 - acc: 0.9843 - val_loss: 0.1022 - val_acc: 0.9861\n",
      "Epoch 197/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1022 - acc: 0.9857 - val_loss: 0.1014 - val_acc: 0.9846\n",
      "Epoch 198/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1015 - acc: 0.9844 - val_loss: 0.1008 - val_acc: 0.9864\n",
      "Epoch 199/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1008 - acc: 0.9864 - val_loss: 0.1000 - val_acc: 0.9843\n",
      "Epoch 200/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1001 - acc: 0.9840 - val_loss: 0.0995 - val_acc: 0.9865\n",
      "Epoch 201/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0995 - acc: 0.9863 - val_loss: 0.0988 - val_acc: 0.9838\n",
      "Epoch 202/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0989 - acc: 0.9836 - val_loss: 0.0983 - val_acc: 0.9860\n",
      "Epoch 203/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0983 - acc: 0.9861 - val_loss: 0.0976 - val_acc: 0.9833\n",
      "Epoch 204/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0977 - acc: 0.9830 - val_loss: 0.0971 - val_acc: 0.9858\n",
      "Epoch 205/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0971 - acc: 0.9859 - val_loss: 0.0963 - val_acc: 0.9832\n",
      "Epoch 206/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0964 - acc: 0.9829 - val_loss: 0.0957 - val_acc: 0.9861\n",
      "Epoch 207/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0957 - acc: 0.9862 - val_loss: 0.0948 - val_acc: 0.9838\n",
      "Epoch 208/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0949 - acc: 0.9840 - val_loss: 0.0941 - val_acc: 0.9867\n",
      "Epoch 209/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0942 - acc: 0.9866 - val_loss: 0.0933 - val_acc: 0.9847\n",
      "Epoch 210/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0934 - acc: 0.9846 - val_loss: 0.0926 - val_acc: 0.9873\n",
      "Epoch 211/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0927 - acc: 0.9870 - val_loss: 0.0919 - val_acc: 0.9855\n",
      "Epoch 212/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0920 - acc: 0.9853 - val_loss: 0.0912 - val_acc: 0.9878\n",
      "Epoch 213/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0913 - acc: 0.9874 - val_loss: 0.0905 - val_acc: 0.9862\n",
      "Epoch 214/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0907 - acc: 0.9856 - val_loss: 0.0899 - val_acc: 0.9880\n",
      "Epoch 215/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0900 - acc: 0.9875 - val_loss: 0.0893 - val_acc: 0.9866\n",
      "Epoch 216/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0894 - acc: 0.9859 - val_loss: 0.0887 - val_acc: 0.9881\n",
      "Epoch 217/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0888 - acc: 0.9873 - val_loss: 0.0881 - val_acc: 0.9868\n",
      "Epoch 218/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0883 - acc: 0.9863 - val_loss: 0.0876 - val_acc: 0.9881\n",
      "Epoch 219/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0877 - acc: 0.9875 - val_loss: 0.0870 - val_acc: 0.9870\n",
      "Epoch 220/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0872 - acc: 0.9864 - val_loss: 0.0865 - val_acc: 0.9883\n",
      "Epoch 221/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0866 - acc: 0.9878 - val_loss: 0.0859 - val_acc: 0.9873\n",
      "Epoch 222/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0861 - acc: 0.9865 - val_loss: 0.0854 - val_acc: 0.9883\n",
      "Epoch 223/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0856 - acc: 0.9879 - val_loss: 0.0849 - val_acc: 0.9874\n",
      "Epoch 224/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0851 - acc: 0.9867 - val_loss: 0.0844 - val_acc: 0.9885\n",
      "Epoch 225/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0846 - acc: 0.9879 - val_loss: 0.0839 - val_acc: 0.9876\n",
      "Epoch 226/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0841 - acc: 0.9867 - val_loss: 0.0834 - val_acc: 0.9885\n",
      "Epoch 227/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0836 - acc: 0.9880 - val_loss: 0.0829 - val_acc: 0.9876\n",
      "Epoch 228/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0831 - acc: 0.9869 - val_loss: 0.0825 - val_acc: 0.9887\n",
      "Epoch 229/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0827 - acc: 0.9881 - val_loss: 0.0820 - val_acc: 0.9878\n",
      "Epoch 230/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0822 - acc: 0.9871 - val_loss: 0.0815 - val_acc: 0.9888\n",
      "Epoch 231/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0817 - acc: 0.9880 - val_loss: 0.0811 - val_acc: 0.9878\n",
      "Epoch 232/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0813 - acc: 0.9872 - val_loss: 0.0806 - val_acc: 0.9889\n",
      "Epoch 233/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0809 - acc: 0.9881 - val_loss: 0.0802 - val_acc: 0.9878\n",
      "Epoch 234/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0804 - acc: 0.9872 - val_loss: 0.0798 - val_acc: 0.9889\n",
      "Epoch 235/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0800 - acc: 0.9879 - val_loss: 0.0794 - val_acc: 0.9878\n",
      "Epoch 236/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0796 - acc: 0.9871 - val_loss: 0.0790 - val_acc: 0.9890\n",
      "Epoch 237/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0792 - acc: 0.9881 - val_loss: 0.0786 - val_acc: 0.9877\n",
      "Epoch 238/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0788 - acc: 0.9870 - val_loss: 0.0782 - val_acc: 0.9888\n",
      "Epoch 239/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0784 - acc: 0.9883 - val_loss: 0.0778 - val_acc: 0.9875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0781 - acc: 0.9871 - val_loss: 0.0775 - val_acc: 0.9887\n",
      "Epoch 241/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0778 - acc: 0.9886 - val_loss: 0.0772 - val_acc: 0.9872\n",
      "Epoch 242/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0774 - acc: 0.9869 - val_loss: 0.0769 - val_acc: 0.9886\n",
      "Epoch 243/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0771 - acc: 0.9882 - val_loss: 0.0766 - val_acc: 0.9868\n",
      "Epoch 244/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0768 - acc: 0.9866 - val_loss: 0.0762 - val_acc: 0.9884\n",
      "Epoch 245/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0765 - acc: 0.9880 - val_loss: 0.0759 - val_acc: 0.9864\n",
      "Epoch 246/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0762 - acc: 0.9866 - val_loss: 0.0756 - val_acc: 0.9882\n",
      "Epoch 247/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0759 - acc: 0.9880 - val_loss: 0.0752 - val_acc: 0.9864\n",
      "Epoch 248/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0755 - acc: 0.9865 - val_loss: 0.0749 - val_acc: 0.9883\n",
      "Epoch 249/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0751 - acc: 0.9881 - val_loss: 0.0745 - val_acc: 0.9866\n",
      "Epoch 250/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0748 - acc: 0.9867 - val_loss: 0.0741 - val_acc: 0.9886\n",
      "Epoch 251/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0744 - acc: 0.9882 - val_loss: 0.0737 - val_acc: 0.9870\n",
      "Epoch 252/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0739 - acc: 0.9870 - val_loss: 0.0732 - val_acc: 0.9889\n",
      "Epoch 253/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0735 - acc: 0.9884 - val_loss: 0.0728 - val_acc: 0.9876\n",
      "Epoch 254/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0731 - acc: 0.9875 - val_loss: 0.0724 - val_acc: 0.9893\n",
      "Epoch 255/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0727 - acc: 0.9885 - val_loss: 0.0720 - val_acc: 0.9881\n",
      "Epoch 256/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0723 - acc: 0.9881 - val_loss: 0.0716 - val_acc: 0.9896\n",
      "Epoch 257/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0720 - acc: 0.9889 - val_loss: 0.0713 - val_acc: 0.9884\n",
      "Epoch 258/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0716 - acc: 0.9882 - val_loss: 0.0709 - val_acc: 0.9897\n",
      "Epoch 259/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0712 - acc: 0.9891 - val_loss: 0.0706 - val_acc: 0.9887\n",
      "Epoch 260/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0709 - acc: 0.9886 - val_loss: 0.0702 - val_acc: 0.9899\n",
      "Epoch 261/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0705 - acc: 0.9893 - val_loss: 0.0699 - val_acc: 0.9890\n",
      "Epoch 262/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0702 - acc: 0.9887 - val_loss: 0.0695 - val_acc: 0.9901\n",
      "Epoch 263/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0699 - acc: 0.9892 - val_loss: 0.0692 - val_acc: 0.9892\n",
      "Epoch 264/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0696 - acc: 0.9888 - val_loss: 0.0689 - val_acc: 0.9902\n",
      "Epoch 265/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0692 - acc: 0.9891 - val_loss: 0.0686 - val_acc: 0.9894\n",
      "Epoch 266/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0689 - acc: 0.9889 - val_loss: 0.0683 - val_acc: 0.9903\n",
      "Epoch 267/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0686 - acc: 0.9893 - val_loss: 0.0680 - val_acc: 0.9896\n",
      "Epoch 268/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0683 - acc: 0.9889 - val_loss: 0.0677 - val_acc: 0.9904\n",
      "Epoch 269/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0680 - acc: 0.9894 - val_loss: 0.0674 - val_acc: 0.9897\n",
      "Epoch 270/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0677 - acc: 0.9891 - val_loss: 0.0671 - val_acc: 0.9905\n",
      "Epoch 271/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0675 - acc: 0.9895 - val_loss: 0.0668 - val_acc: 0.9898\n",
      "Epoch 272/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0672 - acc: 0.9892 - val_loss: 0.0665 - val_acc: 0.9906\n",
      "Epoch 273/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0669 - acc: 0.9896 - val_loss: 0.0663 - val_acc: 0.9898\n",
      "Epoch 274/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0666 - acc: 0.9893 - val_loss: 0.0660 - val_acc: 0.9906\n",
      "Epoch 275/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0663 - acc: 0.9898 - val_loss: 0.0657 - val_acc: 0.9898\n",
      "Epoch 276/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0661 - acc: 0.9893 - val_loss: 0.0654 - val_acc: 0.9907\n",
      "Epoch 277/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0658 - acc: 0.9897 - val_loss: 0.0652 - val_acc: 0.9898\n",
      "Epoch 278/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0656 - acc: 0.9894 - val_loss: 0.0649 - val_acc: 0.9907\n",
      "Epoch 279/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0653 - acc: 0.9899 - val_loss: 0.0647 - val_acc: 0.9897\n",
      "Epoch 280/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0651 - acc: 0.9897 - val_loss: 0.0644 - val_acc: 0.9907\n",
      "Epoch 281/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0648 - acc: 0.9900 - val_loss: 0.0642 - val_acc: 0.9897\n",
      "Epoch 282/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0646 - acc: 0.9896 - val_loss: 0.0639 - val_acc: 0.9908\n",
      "Epoch 283/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0643 - acc: 0.9901 - val_loss: 0.0638 - val_acc: 0.9896\n",
      "Epoch 284/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0641 - acc: 0.9896 - val_loss: 0.0635 - val_acc: 0.9907\n",
      "Epoch 285/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0639 - acc: 0.9902 - val_loss: 0.0633 - val_acc: 0.9894\n",
      "Epoch 286/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0637 - acc: 0.9896 - val_loss: 0.0631 - val_acc: 0.9906\n",
      "Epoch 287/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0635 - acc: 0.9899 - val_loss: 0.0630 - val_acc: 0.9891\n",
      "Epoch 288/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0633 - acc: 0.9891 - val_loss: 0.0627 - val_acc: 0.9905\n",
      "Epoch 289/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0631 - acc: 0.9897 - val_loss: 0.0626 - val_acc: 0.9889\n",
      "Epoch 290/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0629 - acc: 0.9891 - val_loss: 0.0623 - val_acc: 0.9903\n",
      "Epoch 291/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0628 - acc: 0.9896 - val_loss: 0.0622 - val_acc: 0.9886\n",
      "Epoch 292/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0626 - acc: 0.9889 - val_loss: 0.0620 - val_acc: 0.9902\n",
      "Epoch 293/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0624 - acc: 0.9895 - val_loss: 0.0619 - val_acc: 0.9883\n",
      "Epoch 294/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0622 - acc: 0.9887 - val_loss: 0.0616 - val_acc: 0.9901\n",
      "Epoch 295/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0620 - acc: 0.9896 - val_loss: 0.0615 - val_acc: 0.9883\n",
      "Epoch 296/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0618 - acc: 0.9887 - val_loss: 0.0611 - val_acc: 0.9902\n",
      "Epoch 297/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0616 - acc: 0.9897 - val_loss: 0.0610 - val_acc: 0.9884\n",
      "Epoch 298/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0613 - acc: 0.9889 - val_loss: 0.0606 - val_acc: 0.9904\n",
      "Epoch 299/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0611 - acc: 0.9897 - val_loss: 0.0605 - val_acc: 0.9887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0608 - acc: 0.9891 - val_loss: 0.0601 - val_acc: 0.9906\n",
      "3000/3000 [==============================] - 0s 28us/step\n",
      "['loss', 'acc'] [0.061653155783812204, 0.9900000190734863]\n",
      "[[0.66108923 0.95594316]] [[9.2377581e-07 9.9689376e-01 9.9999928e-01]]\n"
     ]
    }
   ],
   "source": [
    "model = multi_learning_demo(activation='sigmoid', loss='binary_crossentropy')\n",
    "x = np.random.rand(1,2)\n",
    "print(x, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid + binary_Focal_Lossあり\n",
    "- なんかおかしい。3nodeだからか精度は下がってる（sigmoidだから本来は1nodeでやるべき）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid\n",
      "(100000, 3) [[0. 1. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 1. 0.]]\n",
      "0.0    95031\n",
      "1.0     4969\n",
      "dtype: int64\n",
      "1.0    95109\n",
      "0.0     4891\n",
      "dtype: int64\n",
      "1.0    50034\n",
      "0.0    49966\n",
      "dtype: int64\n",
      "input_dim, nb_classes: 2 3\n",
      "Train on 9700 samples, validate on 87300 samples\n",
      "Epoch 1/300\n",
      "9700/9700 [==============================] - 0s 18us/step - loss: 2312.6033 - acc: 0.2948 - val_loss: 20330.6250 - val_acc: 0.2901\n",
      "Epoch 2/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2264.5198 - acc: 0.2943 - val_loss: 20054.1250 - val_acc: 0.3277\n",
      "Epoch 3/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2233.6787 - acc: 0.3330 - val_loss: 19805.5352 - val_acc: 0.3853\n",
      "Epoch 4/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2205.9724 - acc: 0.3901 - val_loss: 19561.7988 - val_acc: 0.4740\n",
      "Epoch 5/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2178.8105 - acc: 0.4822 - val_loss: 19317.1230 - val_acc: 0.6114\n",
      "Epoch 6/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2151.5107 - acc: 0.6137 - val_loss: 19067.7324 - val_acc: 0.7736\n",
      "Epoch 7/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2123.6560 - acc: 0.7784 - val_loss: 18812.3145 - val_acc: 0.8868\n",
      "Epoch 8/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2095.1292 - acc: 0.8898 - val_loss: 18549.6367 - val_acc: 0.9033\n",
      "Epoch 9/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2065.7832 - acc: 0.9061 - val_loss: 18278.9102 - val_acc: 0.9033\n",
      "Epoch 10/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2035.5176 - acc: 0.9061 - val_loss: 18002.0938 - val_acc: 0.9033\n",
      "Epoch 11/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2004.5699 - acc: 0.9061 - val_loss: 17720.3418 - val_acc: 0.9033\n",
      "Epoch 12/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1973.0614 - acc: 0.9061 - val_loss: 17431.5332 - val_acc: 0.9033\n",
      "Epoch 13/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1940.7484 - acc: 0.9061 - val_loss: 17138.8516 - val_acc: 0.9033\n",
      "Epoch 14/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1907.9895 - acc: 0.9061 - val_loss: 16844.7246 - val_acc: 0.9033\n",
      "Epoch 15/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1875.0314 - acc: 0.9061 - val_loss: 16547.5938 - val_acc: 0.9033\n",
      "Epoch 16/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1841.7158 - acc: 0.9061 - val_loss: 16247.6240 - val_acc: 0.9033\n",
      "Epoch 17/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1808.0739 - acc: 0.9061 - val_loss: 15948.6006 - val_acc: 0.9033\n",
      "Epoch 18/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1774.5177 - acc: 0.9061 - val_loss: 15652.4004 - val_acc: 0.9033\n",
      "Epoch 19/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1741.2618 - acc: 0.9061 - val_loss: 15360.2168 - val_acc: 0.9033\n",
      "Epoch 20/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1708.4592 - acc: 0.9061 - val_loss: 15080.6582 - val_acc: 0.9033\n",
      "Epoch 21/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1677.0686 - acc: 0.9061 - val_loss: 14802.0049 - val_acc: 0.9033\n",
      "Epoch 22/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1645.7627 - acc: 0.9061 - val_loss: 14530.9150 - val_acc: 0.9033\n",
      "Epoch 23/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1615.3035 - acc: 0.9061 - val_loss: 14266.8301 - val_acc: 0.9033\n",
      "Epoch 24/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1585.6370 - acc: 0.9061 - val_loss: 14009.6484 - val_acc: 0.9033\n",
      "Epoch 25/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1556.7430 - acc: 0.9061 - val_loss: 13759.5850 - val_acc: 0.9033\n",
      "Epoch 26/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1528.6621 - acc: 0.9061 - val_loss: 13516.7705 - val_acc: 0.9033\n",
      "Epoch 27/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1501.4001 - acc: 0.9061 - val_loss: 13281.1309 - val_acc: 0.9033\n",
      "Epoch 28/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1474.9425 - acc: 0.9061 - val_loss: 13052.9854 - val_acc: 0.9033\n",
      "Epoch 29/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1449.3154 - acc: 0.9061 - val_loss: 12832.1260 - val_acc: 0.9033\n",
      "Epoch 30/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1424.4952 - acc: 0.9061 - val_loss: 12618.1260 - val_acc: 0.9033\n",
      "Epoch 31/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1400.4513 - acc: 0.9061 - val_loss: 12411.0752 - val_acc: 0.9033\n",
      "Epoch 32/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1377.1782 - acc: 0.9061 - val_loss: 12209.7734 - val_acc: 0.9033\n",
      "Epoch 33/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1354.5231 - acc: 0.9061 - val_loss: 12014.2324 - val_acc: 0.9033\n",
      "Epoch 34/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1332.5317 - acc: 0.9061 - val_loss: 11824.0781 - val_acc: 0.9033\n",
      "Epoch 35/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1311.1251 - acc: 0.9061 - val_loss: 11636.5947 - val_acc: 0.9033\n",
      "Epoch 36/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1289.9976 - acc: 0.9061 - val_loss: 11452.1729 - val_acc: 0.9033\n",
      "Epoch 37/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1269.2456 - acc: 0.9061 - val_loss: 11272.7490 - val_acc: 0.9033\n",
      "Epoch 38/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1249.0497 - acc: 0.9061 - val_loss: 11102.2314 - val_acc: 0.9033\n",
      "Epoch 39/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1229.8330 - acc: 0.9061 - val_loss: 10939.3350 - val_acc: 0.9033\n",
      "Epoch 40/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1211.4946 - acc: 0.9061 - val_loss: 10790.2520 - val_acc: 0.9033\n",
      "Epoch 41/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1194.6866 - acc: 0.9061 - val_loss: 10655.6875 - val_acc: 0.9033\n",
      "Epoch 42/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1179.4817 - acc: 0.9061 - val_loss: 10532.6885 - val_acc: 0.9033\n",
      "Epoch 43/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1165.5626 - acc: 0.9061 - val_loss: 10419.6875 - val_acc: 0.9033\n",
      "Epoch 44/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1152.7617 - acc: 0.9061 - val_loss: 10315.5469 - val_acc: 0.9033\n",
      "Epoch 45/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1140.9521 - acc: 0.9061 - val_loss: 10219.2334 - val_acc: 0.9033\n",
      "Epoch 46/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1130.0215 - acc: 0.9061 - val_loss: 10129.7998 - val_acc: 0.9033\n",
      "Epoch 47/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1119.8630 - acc: 0.9061 - val_loss: 10046.3389 - val_acc: 0.9033\n",
      "Epoch 48/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1110.3794 - acc: 0.9061 - val_loss: 9968.0791 - val_acc: 0.9033\n",
      "Epoch 49/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1101.4834 - acc: 0.9061 - val_loss: 9894.3516 - val_acc: 0.9033\n",
      "Epoch 50/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1093.1027 - acc: 0.9061 - val_loss: 9824.5234 - val_acc: 0.9033\n",
      "Epoch 51/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1085.1680 - acc: 0.9061 - val_loss: 9757.9932 - val_acc: 0.9033\n",
      "Epoch 52/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1077.6122 - acc: 0.9061 - val_loss: 9694.2041 - val_acc: 0.9033\n",
      "Epoch 53/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1070.3719 - acc: 0.9061 - val_loss: 9632.6553 - val_acc: 0.9033\n",
      "Epoch 54/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1063.3936 - acc: 0.9061 - val_loss: 9572.9160 - val_acc: 0.9033\n",
      "Epoch 55/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1056.6290 - acc: 0.9061 - val_loss: 9514.5332 - val_acc: 0.9033\n",
      "Epoch 56/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1050.0283 - acc: 0.9061 - val_loss: 9457.1416 - val_acc: 0.9033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1043.5527 - acc: 0.9061 - val_loss: 9400.4121 - val_acc: 0.9033\n",
      "Epoch 58/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1037.1633 - acc: 0.9061 - val_loss: 9344.0596 - val_acc: 0.9033\n",
      "Epoch 59/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1030.8279 - acc: 0.9061 - val_loss: 9287.9150 - val_acc: 0.9033\n",
      "Epoch 60/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1024.5272 - acc: 0.9061 - val_loss: 9231.7969 - val_acc: 0.9033\n",
      "Epoch 61/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1018.2402 - acc: 0.9061 - val_loss: 9173.0303 - val_acc: 0.9033\n",
      "Epoch 62/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1011.6816 - acc: 0.9061 - val_loss: 9105.9453 - val_acc: 0.9033\n",
      "Epoch 63/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1004.2822 - acc: 0.9061 - val_loss: 9038.7344 - val_acc: 0.9033\n",
      "Epoch 64/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 996.8679 - acc: 0.9061 - val_loss: 8971.4521 - val_acc: 0.9033\n",
      "Epoch 65/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 989.4501 - acc: 0.9061 - val_loss: 8903.5117 - val_acc: 0.9033\n",
      "Epoch 66/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 981.9631 - acc: 0.9061 - val_loss: 8834.7158 - val_acc: 0.9033\n",
      "Epoch 67/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 974.3838 - acc: 0.9061 - val_loss: 8764.9873 - val_acc: 0.9033\n",
      "Epoch 68/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 966.7066 - acc: 0.9061 - val_loss: 8694.3682 - val_acc: 0.9033\n",
      "Epoch 69/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 958.9360 - acc: 0.9061 - val_loss: 8622.8818 - val_acc: 0.9033\n",
      "Epoch 70/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 951.0728 - acc: 0.9061 - val_loss: 8550.5693 - val_acc: 0.9033\n",
      "Epoch 71/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 943.1192 - acc: 0.9061 - val_loss: 8477.4775 - val_acc: 0.9033\n",
      "Epoch 72/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 935.0814 - acc: 0.9061 - val_loss: 8403.6748 - val_acc: 0.9033\n",
      "Epoch 73/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 926.9651 - acc: 0.9061 - val_loss: 8329.2734 - val_acc: 0.9033\n",
      "Epoch 74/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 918.7870 - acc: 0.9061 - val_loss: 8254.3574 - val_acc: 0.9033\n",
      "Epoch 75/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 910.5528 - acc: 0.9061 - val_loss: 8178.9141 - val_acc: 0.9033\n",
      "Epoch 76/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 902.2528 - acc: 0.9061 - val_loss: 8102.9761 - val_acc: 0.9033\n",
      "Epoch 77/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 893.8981 - acc: 0.9061 - val_loss: 8026.6265 - val_acc: 0.9033\n",
      "Epoch 78/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 885.4985 - acc: 0.9061 - val_loss: 7949.8071 - val_acc: 0.9033\n",
      "Epoch 79/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 877.0402 - acc: 0.9061 - val_loss: 7872.3608 - val_acc: 0.9033\n",
      "Epoch 80/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 868.5098 - acc: 0.9061 - val_loss: 7793.6592 - val_acc: 0.9033\n",
      "Epoch 81/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 859.8287 - acc: 0.9061 - val_loss: 7711.2437 - val_acc: 0.9033\n",
      "Epoch 82/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 850.7622 - acc: 0.9061 - val_loss: 7625.6182 - val_acc: 0.9033\n",
      "Epoch 83/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 841.3751 - acc: 0.9061 - val_loss: 7540.2969 - val_acc: 0.9033\n",
      "Epoch 84/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 832.0092 - acc: 0.9061 - val_loss: 7454.6475 - val_acc: 0.9033\n",
      "Epoch 85/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 822.5907 - acc: 0.9061 - val_loss: 7368.9775 - val_acc: 0.9033\n",
      "Epoch 86/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 813.1665 - acc: 0.9061 - val_loss: 7282.0415 - val_acc: 0.9033\n",
      "Epoch 87/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 803.5874 - acc: 0.9061 - val_loss: 7193.8857 - val_acc: 0.9033\n",
      "Epoch 88/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 793.8519 - acc: 0.9061 - val_loss: 7104.8042 - val_acc: 0.9033\n",
      "Epoch 89/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 784.0092 - acc: 0.9061 - val_loss: 7016.0581 - val_acc: 0.9033\n",
      "Epoch 90/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 774.2001 - acc: 0.9061 - val_loss: 6929.2104 - val_acc: 0.9033\n",
      "Epoch 91/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 764.6016 - acc: 0.9061 - val_loss: 6844.3037 - val_acc: 0.9033\n",
      "Epoch 92/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 755.2029 - acc: 0.9061 - val_loss: 6760.5229 - val_acc: 0.9033\n",
      "Epoch 93/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 745.9037 - acc: 0.9061 - val_loss: 6677.4536 - val_acc: 0.9033\n",
      "Epoch 94/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 736.6821 - acc: 0.9061 - val_loss: 6595.1479 - val_acc: 0.9033\n",
      "Epoch 95/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 727.5377 - acc: 0.9061 - val_loss: 6514.1753 - val_acc: 0.9033\n",
      "Epoch 96/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 718.5419 - acc: 0.9061 - val_loss: 6435.0586 - val_acc: 0.9033\n",
      "Epoch 97/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 709.7525 - acc: 0.9061 - val_loss: 6357.5781 - val_acc: 0.9033\n",
      "Epoch 98/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 701.1340 - acc: 0.9061 - val_loss: 6281.5620 - val_acc: 0.9033\n",
      "Epoch 99/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 692.6714 - acc: 0.9061 - val_loss: 6206.9062 - val_acc: 0.9033\n",
      "Epoch 100/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 684.3618 - acc: 0.9061 - val_loss: 6133.6284 - val_acc: 0.9033\n",
      "Epoch 101/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 676.2034 - acc: 0.9061 - val_loss: 6061.6797 - val_acc: 0.9033\n",
      "Epoch 102/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 668.1929 - acc: 0.9061 - val_loss: 5991.0786 - val_acc: 0.9033\n",
      "Epoch 103/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 660.3354 - acc: 0.9061 - val_loss: 5921.8350 - val_acc: 0.9033\n",
      "Epoch 104/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 652.6318 - acc: 0.9061 - val_loss: 5853.9688 - val_acc: 0.9033\n",
      "Epoch 105/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 645.0825 - acc: 0.9061 - val_loss: 5787.4658 - val_acc: 0.9033\n",
      "Epoch 106/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 637.6872 - acc: 0.9061 - val_loss: 5722.3672 - val_acc: 0.9033\n",
      "Epoch 107/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 630.4468 - acc: 0.9061 - val_loss: 5658.6592 - val_acc: 0.9033\n",
      "Epoch 108/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 623.3649 - acc: 0.9061 - val_loss: 5596.3721 - val_acc: 0.9033\n",
      "Epoch 109/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 616.4418 - acc: 0.9061 - val_loss: 5535.5000 - val_acc: 0.9033\n",
      "Epoch 110/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 609.6790 - acc: 0.9061 - val_loss: 5476.0474 - val_acc: 0.9033\n",
      "Epoch 111/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 603.0767 - acc: 0.9061 - val_loss: 5418.0005 - val_acc: 0.9033\n",
      "Epoch 112/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 596.6299 - acc: 0.9061 - val_loss: 5361.3438 - val_acc: 0.9033\n",
      "Epoch 113/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 590.3380 - acc: 0.9061 - val_loss: 5306.2930 - val_acc: 0.9033\n",
      "Epoch 114/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 584.2244 - acc: 0.9061 - val_loss: 5252.3662 - val_acc: 0.9033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 578.2338 - acc: 0.9061 - val_loss: 5199.7646 - val_acc: 0.9033\n",
      "Epoch 116/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 572.3882 - acc: 0.9061 - val_loss: 5148.4883 - val_acc: 0.9033\n",
      "Epoch 117/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 566.6877 - acc: 0.9061 - val_loss: 5098.4883 - val_acc: 0.9033\n",
      "Epoch 118/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 561.1313 - acc: 0.9061 - val_loss: 5049.7725 - val_acc: 0.9033\n",
      "Epoch 119/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 555.7156 - acc: 0.9061 - val_loss: 5002.2695 - val_acc: 0.9033\n",
      "Epoch 120/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 550.4346 - acc: 0.9061 - val_loss: 4955.9604 - val_acc: 0.9033\n",
      "Epoch 121/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 545.2877 - acc: 0.9061 - val_loss: 4910.8320 - val_acc: 0.9033\n",
      "Epoch 122/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 540.2712 - acc: 0.9061 - val_loss: 4866.8579 - val_acc: 0.9033\n",
      "Epoch 123/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 535.3789 - acc: 0.9061 - val_loss: 4823.9546 - val_acc: 0.9033\n",
      "Epoch 124/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 530.6059 - acc: 0.9061 - val_loss: 4782.1216 - val_acc: 0.9033\n",
      "Epoch 125/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 525.9470 - acc: 0.9061 - val_loss: 4741.3140 - val_acc: 0.9033\n",
      "Epoch 126/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 521.4023 - acc: 0.9061 - val_loss: 4701.5234 - val_acc: 0.9033\n",
      "Epoch 127/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 516.9656 - acc: 0.9061 - val_loss: 4662.6919 - val_acc: 0.9033\n",
      "Epoch 128/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 512.6311 - acc: 0.9061 - val_loss: 4624.7783 - val_acc: 0.9033\n",
      "Epoch 129/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 508.3970 - acc: 0.9061 - val_loss: 4587.7847 - val_acc: 0.9033\n",
      "Epoch 130/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 504.2644 - acc: 0.9061 - val_loss: 4551.6958 - val_acc: 0.9033\n",
      "Epoch 131/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 500.2341 - acc: 0.9061 - val_loss: 4516.5063 - val_acc: 0.9033\n",
      "Epoch 132/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 496.3035 - acc: 0.9061 - val_loss: 4482.1890 - val_acc: 0.9033\n",
      "Epoch 133/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 492.4676 - acc: 0.9061 - val_loss: 4448.6870 - val_acc: 0.9033\n",
      "Epoch 134/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 488.7207 - acc: 0.9061 - val_loss: 4415.9771 - val_acc: 0.9033\n",
      "Epoch 135/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 485.0593 - acc: 0.9061 - val_loss: 4384.0347 - val_acc: 0.9033\n",
      "Epoch 136/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 481.4819 - acc: 0.9061 - val_loss: 4352.8125 - val_acc: 0.9033\n",
      "Epoch 137/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 477.9866 - acc: 0.9061 - val_loss: 4322.3071 - val_acc: 0.9033\n",
      "Epoch 138/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 474.5754 - acc: 0.9061 - val_loss: 4292.4453 - val_acc: 0.9033\n",
      "Epoch 139/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 471.2385 - acc: 0.9061 - val_loss: 4263.2378 - val_acc: 0.9033\n",
      "Epoch 140/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 467.9751 - acc: 0.9061 - val_loss: 4234.6133 - val_acc: 0.9033\n",
      "Epoch 141/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 464.7801 - acc: 0.9061 - val_loss: 4206.5586 - val_acc: 0.9033\n",
      "Epoch 142/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 461.6497 - acc: 0.9061 - val_loss: 4179.0342 - val_acc: 0.9033\n",
      "Epoch 143/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 458.5821 - acc: 0.9061 - val_loss: 4152.0122 - val_acc: 0.9033\n",
      "Epoch 144/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 455.5728 - acc: 0.9061 - val_loss: 4125.4517 - val_acc: 0.9033\n",
      "Epoch 145/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 452.6184 - acc: 0.9061 - val_loss: 4099.3350 - val_acc: 0.9033\n",
      "Epoch 146/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 449.7134 - acc: 0.9061 - val_loss: 4073.6228 - val_acc: 0.9033\n",
      "Epoch 147/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 446.8566 - acc: 0.9061 - val_loss: 4048.3042 - val_acc: 0.9033\n",
      "Epoch 148/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 444.0455 - acc: 0.9061 - val_loss: 4023.3394 - val_acc: 0.9033\n",
      "Epoch 149/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 441.2769 - acc: 0.9061 - val_loss: 3998.6995 - val_acc: 0.9033\n",
      "Epoch 150/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 438.5466 - acc: 0.9061 - val_loss: 3974.3464 - val_acc: 0.9033\n",
      "Epoch 151/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 435.8484 - acc: 0.9061 - val_loss: 3950.2581 - val_acc: 0.9033\n",
      "Epoch 152/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 433.1812 - acc: 0.9061 - val_loss: 3926.4375 - val_acc: 0.9033\n",
      "Epoch 153/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 430.5457 - acc: 0.9061 - val_loss: 3902.8638 - val_acc: 0.9033\n",
      "Epoch 154/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 427.9392 - acc: 0.9061 - val_loss: 3879.5012 - val_acc: 0.9033\n",
      "Epoch 155/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 425.3596 - acc: 0.9061 - val_loss: 3856.2727 - val_acc: 0.9033\n",
      "Epoch 156/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 422.7908 - acc: 0.9061 - val_loss: 3833.3088 - val_acc: 0.9033\n",
      "Epoch 157/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 420.2519 - acc: 0.9061 - val_loss: 3810.5527 - val_acc: 0.9033\n",
      "Epoch 158/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 417.7388 - acc: 0.9061 - val_loss: 3787.9717 - val_acc: 0.9033\n",
      "Epoch 159/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 415.2464 - acc: 0.9061 - val_loss: 3765.5781 - val_acc: 0.9033\n",
      "Epoch 160/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 412.7784 - acc: 0.9061 - val_loss: 3743.3718 - val_acc: 0.9033\n",
      "Epoch 161/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 410.3359 - acc: 0.9061 - val_loss: 3721.3120 - val_acc: 0.9033\n",
      "Epoch 162/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 407.9133 - acc: 0.9061 - val_loss: 3699.3833 - val_acc: 0.9033\n",
      "Epoch 163/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 405.5034 - acc: 0.9061 - val_loss: 3677.5588 - val_acc: 0.9033\n",
      "Epoch 164/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 403.1045 - acc: 0.9061 - val_loss: 3655.9233 - val_acc: 0.9033\n",
      "Epoch 165/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 400.7317 - acc: 0.9061 - val_loss: 3634.3669 - val_acc: 0.9033\n",
      "Epoch 166/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 398.3644 - acc: 0.9061 - val_loss: 3612.8850 - val_acc: 0.9033\n",
      "Epoch 167/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 396.0115 - acc: 0.9061 - val_loss: 3591.4829 - val_acc: 0.9033\n",
      "Epoch 168/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 393.6648 - acc: 0.9061 - val_loss: 3570.1340 - val_acc: 0.9033\n",
      "Epoch 169/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 391.3318 - acc: 0.9061 - val_loss: 3548.9216 - val_acc: 0.9033\n",
      "Epoch 170/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 389.0092 - acc: 0.9061 - val_loss: 3527.6711 - val_acc: 0.9033\n",
      "Epoch 171/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 386.6905 - acc: 0.9061 - val_loss: 3506.4978 - val_acc: 0.9033\n",
      "Epoch 172/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 384.3745 - acc: 0.9061 - val_loss: 3485.1489 - val_acc: 0.9033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 173/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 382.0285 - acc: 0.9061 - val_loss: 3463.3267 - val_acc: 0.9033\n",
      "Epoch 174/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 379.6328 - acc: 0.9061 - val_loss: 3441.0337 - val_acc: 0.9033\n",
      "Epoch 175/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 377.1864 - acc: 0.9061 - val_loss: 3415.5034 - val_acc: 0.9033\n",
      "Epoch 176/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 374.4609 - acc: 0.9061 - val_loss: 3388.1990 - val_acc: 0.9033\n",
      "Epoch 177/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 371.6582 - acc: 0.9061 - val_loss: 3364.6055 - val_acc: 0.9033\n",
      "Epoch 178/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 369.0001 - acc: 0.9061 - val_loss: 3340.6445 - val_acc: 0.9033\n",
      "Epoch 179/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 366.3766 - acc: 0.9061 - val_loss: 3316.8296 - val_acc: 0.9033\n",
      "Epoch 180/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 363.7694 - acc: 0.9061 - val_loss: 3293.1965 - val_acc: 0.9033\n",
      "Epoch 181/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 361.1799 - acc: 0.9061 - val_loss: 3269.7244 - val_acc: 0.9033\n",
      "Epoch 182/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 358.6206 - acc: 0.9061 - val_loss: 3246.4575 - val_acc: 0.9033\n",
      "Epoch 183/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 356.0896 - acc: 0.9061 - val_loss: 3223.4395 - val_acc: 0.9033\n",
      "Epoch 184/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 353.5861 - acc: 0.9061 - val_loss: 3200.6545 - val_acc: 0.9033\n",
      "Epoch 185/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 351.1042 - acc: 0.9061 - val_loss: 3178.1165 - val_acc: 0.9033\n",
      "Epoch 186/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 348.6491 - acc: 0.9061 - val_loss: 3155.8264 - val_acc: 0.9033\n",
      "Epoch 187/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 346.2192 - acc: 0.9061 - val_loss: 3133.8440 - val_acc: 0.9033\n",
      "Epoch 188/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 343.8181 - acc: 0.9061 - val_loss: 3112.0774 - val_acc: 0.9033\n",
      "Epoch 189/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 341.4430 - acc: 0.9061 - val_loss: 3090.6099 - val_acc: 0.9033\n",
      "Epoch 190/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 339.0977 - acc: 0.9061 - val_loss: 3069.3638 - val_acc: 0.9033\n",
      "Epoch 191/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 336.7856 - acc: 0.9061 - val_loss: 3048.4875 - val_acc: 0.9033\n",
      "Epoch 192/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 334.5057 - acc: 0.9061 - val_loss: 3027.7871 - val_acc: 0.9033\n",
      "Epoch 193/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 332.2555 - acc: 0.9061 - val_loss: 3007.3806 - val_acc: 0.9033\n",
      "Epoch 194/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 330.0354 - acc: 0.9061 - val_loss: 2987.2659 - val_acc: 0.9033\n",
      "Epoch 195/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 327.8441 - acc: 0.9061 - val_loss: 2967.4211 - val_acc: 0.9033\n",
      "Epoch 196/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 325.6807 - acc: 0.9061 - val_loss: 2947.8242 - val_acc: 0.9033\n",
      "Epoch 197/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 323.5452 - acc: 0.9061 - val_loss: 2928.5706 - val_acc: 0.9033\n",
      "Epoch 198/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 321.4452 - acc: 0.9061 - val_loss: 2909.5156 - val_acc: 0.9033\n",
      "Epoch 199/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 319.3717 - acc: 0.9061 - val_loss: 2890.7517 - val_acc: 0.9033\n",
      "Epoch 200/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 317.3259 - acc: 0.9061 - val_loss: 2872.2246 - val_acc: 0.9033\n",
      "Epoch 201/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 315.3081 - acc: 0.9061 - val_loss: 2853.9048 - val_acc: 0.9033\n",
      "Epoch 202/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 313.3157 - acc: 0.9061 - val_loss: 2835.8552 - val_acc: 0.9033\n",
      "Epoch 203/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 311.3489 - acc: 0.9061 - val_loss: 2818.0552 - val_acc: 0.9033\n",
      "Epoch 204/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 309.4057 - acc: 0.9061 - val_loss: 2800.4600 - val_acc: 0.9033\n",
      "Epoch 205/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 307.4870 - acc: 0.9061 - val_loss: 2783.1287 - val_acc: 0.9032\n",
      "Epoch 206/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 305.5952 - acc: 0.9059 - val_loss: 2766.0801 - val_acc: 0.9033\n",
      "Epoch 207/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 303.7358 - acc: 0.9061 - val_loss: 2749.3279 - val_acc: 0.9031\n",
      "Epoch 208/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 301.9137 - acc: 0.9059 - val_loss: 2733.2913 - val_acc: 0.9033\n",
      "Epoch 209/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 300.1513 - acc: 0.9061 - val_loss: 2717.6523 - val_acc: 0.9027\n",
      "Epoch 210/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 298.4641 - acc: 0.9055 - val_loss: 2703.6604 - val_acc: 0.9033\n",
      "Epoch 211/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 296.9156 - acc: 0.9061 - val_loss: 2690.6482 - val_acc: 0.9019\n",
      "Epoch 212/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 295.5243 - acc: 0.9046 - val_loss: 2680.8716 - val_acc: 0.9033\n",
      "Epoch 213/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 294.4084 - acc: 0.9061 - val_loss: 2671.6323 - val_acc: 0.9002\n",
      "Epoch 214/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 293.4532 - acc: 0.9029 - val_loss: 2666.0315 - val_acc: 0.9033\n",
      "Epoch 215/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 292.7687 - acc: 0.9061 - val_loss: 2655.1580 - val_acc: 0.8987\n",
      "Epoch 216/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 291.6438 - acc: 0.9012 - val_loss: 2644.4492 - val_acc: 0.9033\n",
      "Epoch 217/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 290.4166 - acc: 0.9061 - val_loss: 2624.4512 - val_acc: 0.8984\n",
      "Epoch 218/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 288.2812 - acc: 0.9008 - val_loss: 2605.8896 - val_acc: 0.9033\n",
      "Epoch 219/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 286.2199 - acc: 0.9061 - val_loss: 2583.0564 - val_acc: 0.8993\n",
      "Epoch 220/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 283.7755 - acc: 0.9016 - val_loss: 2564.0156 - val_acc: 0.9033\n",
      "Epoch 221/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 281.6749 - acc: 0.9061 - val_loss: 2544.8706 - val_acc: 0.9000\n",
      "Epoch 222/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 279.6145 - acc: 0.9027 - val_loss: 2528.2205 - val_acc: 0.9031\n",
      "Epoch 223/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 277.7847 - acc: 0.9059 - val_loss: 2511.9827 - val_acc: 0.9006\n",
      "Epoch 224/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 276.0321 - acc: 0.9037 - val_loss: 2497.1501 - val_acc: 0.9028\n",
      "Epoch 225/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 274.4048 - acc: 0.9055 - val_loss: 2482.6521 - val_acc: 0.9009\n",
      "Epoch 226/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 272.8303 - acc: 0.9039 - val_loss: 2468.8689 - val_acc: 0.9026\n",
      "Epoch 227/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 271.3169 - acc: 0.9054 - val_loss: 2455.2419 - val_acc: 0.9011\n",
      "Epoch 228/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 269.8354 - acc: 0.9040 - val_loss: 2442.0527 - val_acc: 0.9024\n",
      "Epoch 229/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 268.3849 - acc: 0.9054 - val_loss: 2428.9187 - val_acc: 0.9013\n",
      "Epoch 230/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 266.9555 - acc: 0.9040 - val_loss: 2416.1389 - val_acc: 0.9023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 231/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 265.5480 - acc: 0.9053 - val_loss: 2403.4084 - val_acc: 0.9013\n",
      "Epoch 232/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 264.1581 - acc: 0.9040 - val_loss: 2390.9238 - val_acc: 0.9021\n",
      "Epoch 233/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 262.7814 - acc: 0.9052 - val_loss: 2378.4800 - val_acc: 0.9014\n",
      "Epoch 234/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 261.4214 - acc: 0.9041 - val_loss: 2366.2517 - val_acc: 0.9021\n",
      "Epoch 235/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 260.0749 - acc: 0.9052 - val_loss: 2354.0623 - val_acc: 0.9014\n",
      "Epoch 236/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 258.7404 - acc: 0.9042 - val_loss: 2342.0723 - val_acc: 0.9020\n",
      "Epoch 237/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 257.4189 - acc: 0.9052 - val_loss: 2330.1133 - val_acc: 0.9014\n",
      "Epoch 238/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 256.1099 - acc: 0.9043 - val_loss: 2318.3374 - val_acc: 0.9020\n",
      "Epoch 239/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 254.8136 - acc: 0.9049 - val_loss: 2306.6130 - val_acc: 0.9014\n",
      "Epoch 240/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 253.5287 - acc: 0.9043 - val_loss: 2295.0618 - val_acc: 0.9020\n",
      "Epoch 241/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 252.2569 - acc: 0.9049 - val_loss: 2283.5515 - val_acc: 0.9015\n",
      "Epoch 242/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 250.9971 - acc: 0.9043 - val_loss: 2272.2261 - val_acc: 0.9020\n",
      "Epoch 243/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 249.7493 - acc: 0.9049 - val_loss: 2260.9434 - val_acc: 0.9016\n",
      "Epoch 244/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 248.5145 - acc: 0.9044 - val_loss: 2249.8508 - val_acc: 0.9020\n",
      "Epoch 245/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 247.2912 - acc: 0.9049 - val_loss: 2238.7429 - val_acc: 0.9016\n",
      "Epoch 246/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 246.0777 - acc: 0.9044 - val_loss: 2227.8594 - val_acc: 0.9020\n",
      "Epoch 247/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 244.8769 - acc: 0.9049 - val_loss: 2217.0117 - val_acc: 0.9016\n",
      "Epoch 248/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 243.6914 - acc: 0.9044 - val_loss: 2206.3337 - val_acc: 0.9020\n",
      "Epoch 249/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 242.5172 - acc: 0.9051 - val_loss: 2195.6846 - val_acc: 0.9015\n",
      "Epoch 250/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 241.3569 - acc: 0.9044 - val_loss: 2185.2720 - val_acc: 0.9020\n",
      "Epoch 251/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 240.2089 - acc: 0.9051 - val_loss: 2174.8440 - val_acc: 0.9014\n",
      "Epoch 252/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 239.0706 - acc: 0.9043 - val_loss: 2164.6875 - val_acc: 0.9021\n",
      "Epoch 253/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 237.9514 - acc: 0.9052 - val_loss: 2154.5820 - val_acc: 0.9013\n",
      "Epoch 254/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 236.8452 - acc: 0.9040 - val_loss: 2144.7102 - val_acc: 0.9021\n",
      "Epoch 255/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 235.7596 - acc: 0.9052 - val_loss: 2134.9475 - val_acc: 0.9011\n",
      "Epoch 256/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 234.6869 - acc: 0.9037 - val_loss: 2125.5466 - val_acc: 0.9023\n",
      "Epoch 257/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 233.6518 - acc: 0.9053 - val_loss: 2116.2585 - val_acc: 0.9009\n",
      "Epoch 258/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 232.6343 - acc: 0.9036 - val_loss: 2107.6101 - val_acc: 0.9025\n",
      "Epoch 259/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 231.6788 - acc: 0.9053 - val_loss: 2099.1777 - val_acc: 0.9005\n",
      "Epoch 260/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 230.7564 - acc: 0.9034 - val_loss: 2091.8672 - val_acc: 0.9026\n",
      "Epoch 261/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 229.9472 - acc: 0.9054 - val_loss: 2084.7661 - val_acc: 0.8999\n",
      "Epoch 262/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 229.1684 - acc: 0.9025 - val_loss: 2079.6272 - val_acc: 0.9029\n",
      "Epoch 263/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 228.5929 - acc: 0.9056 - val_loss: 2073.8789 - val_acc: 0.8995\n",
      "Epoch 264/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 227.9632 - acc: 0.9021 - val_loss: 2071.1570 - val_acc: 0.9031\n",
      "Epoch 265/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 227.6474 - acc: 0.9059 - val_loss: 2065.9094 - val_acc: 0.8988\n",
      "Epoch 266/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 227.0689 - acc: 0.9014 - val_loss: 2064.2473 - val_acc: 0.9032\n",
      "Epoch 267/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 226.8809 - acc: 0.9059 - val_loss: 2056.5818 - val_acc: 0.8982\n",
      "Epoch 268/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 226.0248 - acc: 0.9007 - val_loss: 2052.0242 - val_acc: 0.9033\n",
      "Epoch 269/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 225.5405 - acc: 0.9061 - val_loss: 2039.3164 - val_acc: 0.8982\n",
      "Epoch 270/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 224.1198 - acc: 0.9007 - val_loss: 2030.1339 - val_acc: 0.9032\n",
      "Epoch 271/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 223.1535 - acc: 0.9059 - val_loss: 2014.9214 - val_acc: 0.8987\n",
      "Epoch 272/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 221.4539 - acc: 0.9015 - val_loss: 2003.2167 - val_acc: 0.9031\n",
      "Epoch 273/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 220.2250 - acc: 0.9059 - val_loss: 1988.9464 - val_acc: 0.8994\n",
      "Epoch 274/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 218.6199 - acc: 0.9020 - val_loss: 1977.2268 - val_acc: 0.9029\n",
      "Epoch 275/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 217.3926 - acc: 0.9057 - val_loss: 1965.3451 - val_acc: 0.9000\n",
      "Epoch 276/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 216.0460 - acc: 0.9026 - val_loss: 1954.6749 - val_acc: 0.9026\n",
      "Epoch 277/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 214.9272 - acc: 0.9054 - val_loss: 1944.6173 - val_acc: 0.9006\n",
      "Epoch 278/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 213.7853 - acc: 0.9033 - val_loss: 1935.0029 - val_acc: 0.9025\n",
      "Epoch 279/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 212.7686 - acc: 0.9053 - val_loss: 1926.0255 - val_acc: 0.9010\n",
      "Epoch 280/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 211.7527 - acc: 0.9034 - val_loss: 1917.1735 - val_acc: 0.9024\n",
      "Epoch 281/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 210.8120 - acc: 0.9053 - val_loss: 1908.9132 - val_acc: 0.9013\n",
      "Epoch 282/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 209.8779 - acc: 0.9036 - val_loss: 1900.5746 - val_acc: 0.9022\n",
      "Epoch 283/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 208.9858 - acc: 0.9053 - val_loss: 1892.7117 - val_acc: 0.9015\n",
      "Epoch 284/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 208.1000 - acc: 0.9038 - val_loss: 1884.6926 - val_acc: 0.9022\n",
      "Epoch 285/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 207.2396 - acc: 0.9053 - val_loss: 1877.1123 - val_acc: 0.9016\n",
      "Epoch 286/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 206.3861 - acc: 0.9040 - val_loss: 1869.3359 - val_acc: 0.9023\n",
      "Epoch 287/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 205.5488 - acc: 0.9053 - val_loss: 1861.9432 - val_acc: 0.9017\n",
      "Epoch 288/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 204.7179 - acc: 0.9041 - val_loss: 1854.3347 - val_acc: 0.9023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 289/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 203.8992 - acc: 0.9053 - val_loss: 1847.0797 - val_acc: 0.9017\n",
      "Epoch 290/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 203.0859 - acc: 0.9042 - val_loss: 1839.6608 - val_acc: 0.9023\n",
      "Epoch 291/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 202.2807 - acc: 0.9051 - val_loss: 1832.4744 - val_acc: 0.9018\n",
      "Epoch 292/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 201.4812 - acc: 0.9042 - val_loss: 1825.2067 - val_acc: 0.9024\n",
      "Epoch 293/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 200.6924 - acc: 0.9051 - val_loss: 1818.1593 - val_acc: 0.9018\n",
      "Epoch 294/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 199.9077 - acc: 0.9043 - val_loss: 1811.0186 - val_acc: 0.9024\n",
      "Epoch 295/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 199.1306 - acc: 0.9049 - val_loss: 1804.0830 - val_acc: 0.9018\n",
      "Epoch 296/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 198.3595 - acc: 0.9044 - val_loss: 1797.0452 - val_acc: 0.9024\n",
      "Epoch 297/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 197.5956 - acc: 0.9052 - val_loss: 1790.2501 - val_acc: 0.9018\n",
      "Epoch 298/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 196.8368 - acc: 0.9045 - val_loss: 1783.3087 - val_acc: 0.9024\n",
      "Epoch 299/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 196.0859 - acc: 0.9053 - val_loss: 1776.6437 - val_acc: 0.9018\n",
      "Epoch 300/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 195.3397 - acc: 0.9045 - val_loss: 1769.8368 - val_acc: 0.9025\n",
      "3000/3000 [==============================] - 0s 31us/step\n",
      "['loss', 'acc'] [0.6480891485214233, 0.9089999998410543]\n",
      "[[0.66108923 0.95594316]] [[0.00272178 0.9956963  0.98837864]]\n"
     ]
    }
   ],
   "source": [
    "model = multi_learning_demo(activation='sigmoid', loss=[binary_focal_loss(alpha=.25, gamma=2)])\n",
    "x = np.random.rand(1,2)\n",
    "print(x, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid +  欠損ラベル作成して、maskありでbinary_Focal_Loss使用\n",
    "- なんかおかしい。3nodeだからか精度は下がってる（sigmoidだから本来は1nodeでやるべき）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid\n",
      "(100000, 3) [[-1.  1.  1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1.  0.]\n",
      " ...\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  1.  0.]]\n",
      " 0.0    93132\n",
      " 1.0     4868\n",
      "-1.0     2000\n",
      "dtype: int64\n",
      " 1.0    94440\n",
      " 0.0     4859\n",
      "-1.0      701\n",
      "dtype: int64\n",
      " 1.0    49495\n",
      " 0.0    49405\n",
      "-1.0     1100\n",
      "dtype: int64\n",
      "input_dim, nb_classes: 2 3\n",
      "Train on 9700 samples, validate on 87300 samples\n",
      "Epoch 1/300\n",
      "9700/9700 [==============================] - 0s 29us/step - loss: 2276.3164 - acc: 0.2957 - val_loss: 20040.5020 - val_acc: 0.2926\n",
      "Epoch 2/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2229.2932 - acc: 0.2955 - val_loss: 19769.4043 - val_acc: 0.3302\n",
      "Epoch 3/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2199.1218 - acc: 0.3338 - val_loss: 19525.5684 - val_acc: 0.3872\n",
      "Epoch 4/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2172.0049 - acc: 0.3900 - val_loss: 19286.3457 - val_acc: 0.4745\n",
      "Epoch 5/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2145.4033 - acc: 0.4812 - val_loss: 19046.2598 - val_acc: 0.6089\n",
      "Epoch 6/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2118.6746 - acc: 0.6102 - val_loss: 18801.5664 - val_acc: 0.7699\n",
      "Epoch 7/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2091.4084 - acc: 0.7729 - val_loss: 18551.0684 - val_acc: 0.8814\n",
      "Epoch 8/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2063.4961 - acc: 0.8834 - val_loss: 18293.7520 - val_acc: 0.8986\n",
      "Epoch 9/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2034.8186 - acc: 0.9003 - val_loss: 18028.6230 - val_acc: 0.8986\n",
      "Epoch 10/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 2005.2511 - acc: 0.9003 - val_loss: 17756.7031 - val_acc: 0.8986\n",
      "Epoch 11/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1974.9181 - acc: 0.9003 - val_loss: 17479.7129 - val_acc: 0.8986\n",
      "Epoch 12/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1944.0243 - acc: 0.9003 - val_loss: 17196.1387 - val_acc: 0.8986\n",
      "Epoch 13/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1912.3771 - acc: 0.9003 - val_loss: 16908.8301 - val_acc: 0.8986\n",
      "Epoch 14/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1880.2959 - acc: 0.9003 - val_loss: 16619.4688 - val_acc: 0.8986\n",
      "Epoch 15/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1847.9590 - acc: 0.9003 - val_loss: 16327.7051 - val_acc: 0.8986\n",
      "Epoch 16/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1815.3414 - acc: 0.9003 - val_loss: 16033.2754 - val_acc: 0.8986\n",
      "Epoch 17/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1782.4202 - acc: 0.9003 - val_loss: 15739.5605 - val_acc: 0.8986\n",
      "Epoch 18/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1749.5544 - acc: 0.9003 - val_loss: 15448.4678 - val_acc: 0.8986\n",
      "Epoch 19/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1716.9532 - acc: 0.9003 - val_loss: 15168.3574 - val_acc: 0.8986\n",
      "Epoch 20/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1685.5876 - acc: 0.9003 - val_loss: 14886.5527 - val_acc: 0.8986\n",
      "Epoch 21/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1654.0400 - acc: 0.9003 - val_loss: 14612.4355 - val_acc: 0.8986\n",
      "Epoch 22/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1623.3311 - acc: 0.9003 - val_loss: 14345.9834 - val_acc: 0.8986\n",
      "Epoch 23/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1593.4728 - acc: 0.9003 - val_loss: 14086.4775 - val_acc: 0.8986\n",
      "Epoch 24/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1564.3950 - acc: 0.9003 - val_loss: 13838.7617 - val_acc: 0.8986\n",
      "Epoch 25/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1536.6475 - acc: 0.9003 - val_loss: 13592.9082 - val_acc: 0.8986\n",
      "Epoch 26/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1509.1113 - acc: 0.9003 - val_loss: 13354.1006 - val_acc: 0.8986\n",
      "Epoch 27/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1482.3763 - acc: 0.9003 - val_loss: 13122.4160 - val_acc: 0.8986\n",
      "Epoch 28/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1456.4357 - acc: 0.9003 - val_loss: 12897.9443 - val_acc: 0.8986\n",
      "Epoch 29/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1431.3027 - acc: 0.9003 - val_loss: 12680.7148 - val_acc: 0.8986\n",
      "Epoch 30/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1406.9617 - acc: 0.9003 - val_loss: 12470.2822 - val_acc: 0.8986\n",
      "Epoch 31/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1383.3867 - acc: 0.9003 - val_loss: 12269.7256 - val_acc: 0.8986\n",
      "Epoch 32/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1360.9194 - acc: 0.9003 - val_loss: 12071.9365 - val_acc: 0.8986\n",
      "Epoch 33/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1338.7256 - acc: 0.9003 - val_loss: 11879.5244 - val_acc: 0.8986\n",
      "Epoch 34/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1317.1490 - acc: 0.9003 - val_loss: 11692.5693 - val_acc: 0.8986\n",
      "Epoch 35/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1296.1769 - acc: 0.9003 - val_loss: 11508.9609 - val_acc: 0.8986\n",
      "Epoch 36/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1275.5518 - acc: 0.9003 - val_loss: 11327.3691 - val_acc: 0.8986\n",
      "Epoch 37/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1255.1797 - acc: 0.9003 - val_loss: 11150.5771 - val_acc: 0.8986\n",
      "Epoch 38/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1235.3402 - acc: 0.9003 - val_loss: 10979.8242 - val_acc: 0.8986\n",
      "Epoch 39/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1216.1504 - acc: 0.9003 - val_loss: 10817.8398 - val_acc: 0.8986\n",
      "Epoch 40/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1197.9658 - acc: 0.9003 - val_loss: 10668.8633 - val_acc: 0.8986\n",
      "Epoch 41/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1181.2238 - acc: 0.9003 - val_loss: 10534.1943 - val_acc: 0.8986\n",
      "Epoch 42/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1166.0614 - acc: 0.9003 - val_loss: 10411.5166 - val_acc: 0.8986\n",
      "Epoch 43/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1152.2294 - acc: 0.9003 - val_loss: 10298.8584 - val_acc: 0.8986\n",
      "Epoch 44/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1139.5151 - acc: 0.9003 - val_loss: 10195.0566 - val_acc: 0.8986\n",
      "Epoch 45/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1127.7902 - acc: 0.9003 - val_loss: 10100.0684 - val_acc: 0.8986\n",
      "Epoch 46/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1117.0516 - acc: 0.9003 - val_loss: 10010.8975 - val_acc: 0.8986\n",
      "Epoch 47/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1106.9624 - acc: 0.9003 - val_loss: 9927.6875 - val_acc: 0.8986\n",
      "Epoch 48/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1097.5449 - acc: 0.9003 - val_loss: 9849.7061 - val_acc: 0.8986\n",
      "Epoch 49/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1088.7150 - acc: 0.9003 - val_loss: 9776.9609 - val_acc: 0.8986\n",
      "Epoch 50/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1080.4785 - acc: 0.9003 - val_loss: 9707.3818 - val_acc: 0.8986\n",
      "Epoch 51/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1072.6044 - acc: 0.9003 - val_loss: 9641.0850 - val_acc: 0.8986\n",
      "Epoch 52/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1065.1031 - acc: 0.9003 - val_loss: 9577.5303 - val_acc: 0.8986\n",
      "Epoch 53/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1057.9152 - acc: 0.9003 - val_loss: 9516.1943 - val_acc: 0.8986\n",
      "Epoch 54/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1050.9889 - acc: 0.9003 - val_loss: 9456.6709 - val_acc: 0.8986\n",
      "Epoch 55/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1044.2726 - acc: 0.9003 - val_loss: 9398.4932 - val_acc: 0.8986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1037.7173 - acc: 0.9003 - val_loss: 9341.2949 - val_acc: 0.8986\n",
      "Epoch 57/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1031.2831 - acc: 0.9003 - val_loss: 9284.7510 - val_acc: 0.8986\n",
      "Epoch 58/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1024.9314 - acc: 0.9003 - val_loss: 9228.6250 - val_acc: 0.8986\n",
      "Epoch 59/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1018.6367 - acc: 0.9003 - val_loss: 9172.7334 - val_acc: 0.8986\n",
      "Epoch 60/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1012.3771 - acc: 0.9003 - val_loss: 9116.8584 - val_acc: 0.8986\n",
      "Epoch 61/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1006.1268 - acc: 0.9003 - val_loss: 9060.8193 - val_acc: 0.8986\n",
      "Epoch 62/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 999.8658 - acc: 0.9003 - val_loss: 9001.7607 - val_acc: 0.8986\n",
      "Epoch 63/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 993.2930 - acc: 0.9003 - val_loss: 8934.3828 - val_acc: 0.8986\n",
      "Epoch 64/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 985.8741 - acc: 0.9003 - val_loss: 8867.0010 - val_acc: 0.8986\n",
      "Epoch 65/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 978.4545 - acc: 0.9003 - val_loss: 8799.4297 - val_acc: 0.8986\n",
      "Epoch 66/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 971.0161 - acc: 0.9003 - val_loss: 8731.1641 - val_acc: 0.8986\n",
      "Epoch 67/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 963.5025 - acc: 0.9003 - val_loss: 8662.0342 - val_acc: 0.8986\n",
      "Epoch 68/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 955.8981 - acc: 0.9003 - val_loss: 8592.0000 - val_acc: 0.8986\n",
      "Epoch 69/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 948.1938 - acc: 0.9003 - val_loss: 8521.0850 - val_acc: 0.8986\n",
      "Epoch 70/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 940.3960 - acc: 0.9003 - val_loss: 8449.3145 - val_acc: 0.8986\n",
      "Epoch 71/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 932.5055 - acc: 0.9003 - val_loss: 8376.7500 - val_acc: 0.8986\n",
      "Epoch 72/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 924.5268 - acc: 0.9003 - val_loss: 8303.9062 - val_acc: 0.8986\n",
      "Epoch 73/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 916.5204 - acc: 0.9003 - val_loss: 8229.9385 - val_acc: 0.8986\n",
      "Epoch 74/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 908.3849 - acc: 0.9003 - val_loss: 8155.3911 - val_acc: 0.8986\n",
      "Epoch 75/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 900.1915 - acc: 0.9003 - val_loss: 8080.3906 - val_acc: 0.8986\n",
      "Epoch 76/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 891.9481 - acc: 0.9003 - val_loss: 8004.8984 - val_acc: 0.8986\n",
      "Epoch 77/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 883.6414 - acc: 0.9003 - val_loss: 7928.9609 - val_acc: 0.8986\n",
      "Epoch 78/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 875.2817 - acc: 0.9003 - val_loss: 7853.0933 - val_acc: 0.8986\n",
      "Epoch 79/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 866.9307 - acc: 0.9003 - val_loss: 7776.2891 - val_acc: 0.8986\n",
      "Epoch 80/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 858.4737 - acc: 0.9003 - val_loss: 7698.7441 - val_acc: 0.8986\n",
      "Epoch 81/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 849.9243 - acc: 0.9003 - val_loss: 7619.1846 - val_acc: 0.8986\n",
      "Epoch 82/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 841.1436 - acc: 0.9003 - val_loss: 7535.0908 - val_acc: 0.8986\n",
      "Epoch 83/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 831.9122 - acc: 0.9003 - val_loss: 7450.2041 - val_acc: 0.8986\n",
      "Epoch 84/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 822.5967 - acc: 0.9003 - val_loss: 7365.3662 - val_acc: 0.8986\n",
      "Epoch 85/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 813.2683 - acc: 0.9003 - val_loss: 7280.1885 - val_acc: 0.8986\n",
      "Epoch 86/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 803.8942 - acc: 0.9003 - val_loss: 7194.5034 - val_acc: 0.8986\n",
      "Epoch 87/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 794.4619 - acc: 0.9003 - val_loss: 7107.9175 - val_acc: 0.8986\n",
      "Epoch 88/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 784.9044 - acc: 0.9003 - val_loss: 7020.2075 - val_acc: 0.8986\n",
      "Epoch 89/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 775.2144 - acc: 0.9003 - val_loss: 6932.2441 - val_acc: 0.8986\n",
      "Epoch 90/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 765.4810 - acc: 0.9003 - val_loss: 6845.5688 - val_acc: 0.8986\n",
      "Epoch 91/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 755.8928 - acc: 0.9003 - val_loss: 6761.0903 - val_acc: 0.8986\n",
      "Epoch 92/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 746.5440 - acc: 0.9003 - val_loss: 6678.1719 - val_acc: 0.8986\n",
      "Epoch 93/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 737.3511 - acc: 0.9003 - val_loss: 6596.2900 - val_acc: 0.8986\n",
      "Epoch 94/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 728.2563 - acc: 0.9003 - val_loss: 6515.0400 - val_acc: 0.8986\n",
      "Epoch 95/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 719.2265 - acc: 0.9003 - val_loss: 6434.4224 - val_acc: 0.8986\n",
      "Epoch 96/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 710.2593 - acc: 0.9003 - val_loss: 6355.1597 - val_acc: 0.8986\n",
      "Epoch 97/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 701.4457 - acc: 0.9003 - val_loss: 6277.7827 - val_acc: 0.8986\n",
      "Epoch 98/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 692.8376 - acc: 0.9003 - val_loss: 6202.4209 - val_acc: 0.8986\n",
      "Epoch 99/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 684.4459 - acc: 0.9003 - val_loss: 6128.1885 - val_acc: 0.8986\n",
      "Epoch 100/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 676.1785 - acc: 0.9003 - val_loss: 6055.3872 - val_acc: 0.8986\n",
      "Epoch 101/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 668.0684 - acc: 0.9003 - val_loss: 5983.9370 - val_acc: 0.8986\n",
      "Epoch 102/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 660.1082 - acc: 0.9003 - val_loss: 5913.8403 - val_acc: 0.8986\n",
      "Epoch 103/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 652.3027 - acc: 0.9003 - val_loss: 5845.1201 - val_acc: 0.8986\n",
      "Epoch 104/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 644.6519 - acc: 0.9003 - val_loss: 5777.7588 - val_acc: 0.8986\n",
      "Epoch 105/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 637.1570 - acc: 0.9003 - val_loss: 5711.7778 - val_acc: 0.8986\n",
      "Epoch 106/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 629.8148 - acc: 0.9003 - val_loss: 5647.2021 - val_acc: 0.8986\n",
      "Epoch 107/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 622.6269 - acc: 0.9003 - val_loss: 5584.0088 - val_acc: 0.8986\n",
      "Epoch 108/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 615.5971 - acc: 0.9003 - val_loss: 5522.2222 - val_acc: 0.8986\n",
      "Epoch 109/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 608.7258 - acc: 0.9003 - val_loss: 5461.8511 - val_acc: 0.8986\n",
      "Epoch 110/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 602.0156 - acc: 0.9003 - val_loss: 5402.9033 - val_acc: 0.8986\n",
      "Epoch 111/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 595.4665 - acc: 0.9003 - val_loss: 5345.3525 - val_acc: 0.8986\n",
      "Epoch 112/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 589.0723 - acc: 0.9003 - val_loss: 5289.1846 - val_acc: 0.8986\n",
      "Epoch 113/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 582.8321 - acc: 0.9003 - val_loss: 5234.3862 - val_acc: 0.8986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 576.7442 - acc: 0.9003 - val_loss: 5180.9365 - val_acc: 0.8986\n",
      "Epoch 115/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 570.8092 - acc: 0.9003 - val_loss: 5128.8242 - val_acc: 0.8986\n",
      "Epoch 116/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 565.0181 - acc: 0.9003 - val_loss: 5078.0122 - val_acc: 0.8986\n",
      "Epoch 117/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 559.3677 - acc: 0.9003 - val_loss: 5028.4810 - val_acc: 0.8986\n",
      "Epoch 118/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 553.8604 - acc: 0.9003 - val_loss: 4980.2104 - val_acc: 0.8986\n",
      "Epoch 119/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 548.4919 - acc: 0.9003 - val_loss: 4933.1543 - val_acc: 0.8986\n",
      "Epoch 120/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 543.2595 - acc: 0.9003 - val_loss: 4887.2930 - val_acc: 0.8986\n",
      "Epoch 121/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 538.1609 - acc: 0.9003 - val_loss: 4842.7729 - val_acc: 0.8986\n",
      "Epoch 122/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 533.2095 - acc: 0.9003 - val_loss: 4799.2046 - val_acc: 0.8986\n",
      "Epoch 123/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 528.3611 - acc: 0.9003 - val_loss: 4756.7329 - val_acc: 0.8986\n",
      "Epoch 124/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 523.6349 - acc: 0.9003 - val_loss: 4715.3110 - val_acc: 0.8986\n",
      "Epoch 125/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 519.0220 - acc: 0.9003 - val_loss: 4674.9077 - val_acc: 0.8986\n",
      "Epoch 126/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 514.5181 - acc: 0.9003 - val_loss: 4635.5083 - val_acc: 0.8986\n",
      "Epoch 127/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 510.1216 - acc: 0.9003 - val_loss: 4597.0498 - val_acc: 0.8986\n",
      "Epoch 128/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 505.8313 - acc: 0.9003 - val_loss: 4559.5317 - val_acc: 0.8986\n",
      "Epoch 129/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 501.6411 - acc: 0.9003 - val_loss: 4522.8979 - val_acc: 0.8986\n",
      "Epoch 130/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 497.5461 - acc: 0.9003 - val_loss: 4487.1479 - val_acc: 0.8986\n",
      "Epoch 131/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 493.5478 - acc: 0.9003 - val_loss: 4452.2734 - val_acc: 0.8986\n",
      "Epoch 132/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 489.6475 - acc: 0.9003 - val_loss: 4418.2578 - val_acc: 0.8986\n",
      "Epoch 133/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 485.8452 - acc: 0.9003 - val_loss: 4385.0630 - val_acc: 0.8986\n",
      "Epoch 134/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 482.1319 - acc: 0.9003 - val_loss: 4352.6553 - val_acc: 0.8986\n",
      "Epoch 135/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 478.4987 - acc: 0.9003 - val_loss: 4320.9634 - val_acc: 0.8986\n",
      "Epoch 136/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 474.9500 - acc: 0.9003 - val_loss: 4289.9985 - val_acc: 0.8986\n",
      "Epoch 137/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 471.4800 - acc: 0.9003 - val_loss: 4259.7188 - val_acc: 0.8986\n",
      "Epoch 138/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 468.0906 - acc: 0.9003 - val_loss: 4230.0908 - val_acc: 0.8986\n",
      "Epoch 139/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 464.7771 - acc: 0.9003 - val_loss: 4201.1724 - val_acc: 0.8986\n",
      "Epoch 140/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 461.5481 - acc: 0.9003 - val_loss: 4172.7583 - val_acc: 0.8986\n",
      "Epoch 141/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 458.3730 - acc: 0.9003 - val_loss: 4144.8794 - val_acc: 0.8986\n",
      "Epoch 142/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 455.2594 - acc: 0.9003 - val_loss: 4117.5269 - val_acc: 0.8986\n",
      "Epoch 143/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 452.2075 - acc: 0.9003 - val_loss: 4090.6667 - val_acc: 0.8986\n",
      "Epoch 144/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 449.2126 - acc: 0.9003 - val_loss: 4064.2581 - val_acc: 0.8986\n",
      "Epoch 145/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 446.2701 - acc: 0.9003 - val_loss: 4038.2615 - val_acc: 0.8986\n",
      "Epoch 146/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 443.3780 - acc: 0.9003 - val_loss: 4012.6702 - val_acc: 0.8986\n",
      "Epoch 147/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 440.5320 - acc: 0.9003 - val_loss: 3987.4478 - val_acc: 0.8986\n",
      "Epoch 148/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 437.7292 - acc: 0.9003 - val_loss: 3962.5625 - val_acc: 0.8986\n",
      "Epoch 149/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 434.9676 - acc: 0.9003 - val_loss: 3938.0037 - val_acc: 0.8986\n",
      "Epoch 150/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 432.2454 - acc: 0.9003 - val_loss: 3913.7341 - val_acc: 0.8986\n",
      "Epoch 151/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 429.5561 - acc: 0.9003 - val_loss: 3889.7231 - val_acc: 0.8986\n",
      "Epoch 152/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 426.8961 - acc: 0.9003 - val_loss: 3865.9570 - val_acc: 0.8986\n",
      "Epoch 153/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 424.2635 - acc: 0.9003 - val_loss: 3842.4404 - val_acc: 0.8986\n",
      "Epoch 154/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 421.6614 - acc: 0.9003 - val_loss: 3819.1409 - val_acc: 0.8986\n",
      "Epoch 155/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 419.0849 - acc: 0.9003 - val_loss: 3795.9529 - val_acc: 0.8986\n",
      "Epoch 156/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 416.5185 - acc: 0.9003 - val_loss: 3773.0039 - val_acc: 0.8986\n",
      "Epoch 157/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 413.9810 - acc: 0.9003 - val_loss: 3750.2651 - val_acc: 0.8986\n",
      "Epoch 158/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 411.4680 - acc: 0.9003 - val_loss: 3727.7002 - val_acc: 0.8986\n",
      "Epoch 159/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 408.9773 - acc: 0.9003 - val_loss: 3705.3274 - val_acc: 0.8986\n",
      "Epoch 160/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 406.5091 - acc: 0.9003 - val_loss: 3683.1311 - val_acc: 0.8986\n",
      "Epoch 161/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 404.0664 - acc: 0.9003 - val_loss: 3661.0969 - val_acc: 0.8986\n",
      "Epoch 162/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 401.6458 - acc: 0.9003 - val_loss: 3639.2673 - val_acc: 0.8986\n",
      "Epoch 163/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 399.2470 - acc: 0.9003 - val_loss: 3617.4978 - val_acc: 0.8986\n",
      "Epoch 164/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 396.8535 - acc: 0.9003 - val_loss: 3595.8718 - val_acc: 0.8986\n",
      "Epoch 165/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 394.4792 - acc: 0.9003 - val_loss: 3574.2849 - val_acc: 0.8986\n",
      "Epoch 166/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 392.1140 - acc: 0.9003 - val_loss: 3552.8892 - val_acc: 0.8986\n",
      "Epoch 167/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 389.7567 - acc: 0.9003 - val_loss: 3531.4688 - val_acc: 0.8986\n",
      "Epoch 168/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 387.4087 - acc: 0.9003 - val_loss: 3510.2219 - val_acc: 0.8986\n",
      "Epoch 169/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 385.0771 - acc: 0.9003 - val_loss: 3489.0059 - val_acc: 0.8986\n",
      "Epoch 170/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 382.7573 - acc: 0.9003 - val_loss: 3467.8689 - val_acc: 0.8986\n",
      "Epoch 171/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 380.4451 - acc: 0.9003 - val_loss: 3446.7827 - val_acc: 0.8986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 378.1401 - acc: 0.9003 - val_loss: 3425.6990 - val_acc: 0.8986\n",
      "Epoch 173/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 375.8272 - acc: 0.9003 - val_loss: 3404.3777 - val_acc: 0.8986\n",
      "Epoch 174/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 373.4753 - acc: 0.9003 - val_loss: 3382.5549 - val_acc: 0.8986\n",
      "Epoch 175/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 371.0813 - acc: 0.9003 - val_loss: 3359.7727 - val_acc: 0.8986\n",
      "Epoch 176/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 368.5999 - acc: 0.9003 - val_loss: 3332.5012 - val_acc: 0.8986\n",
      "Epoch 177/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 365.7427 - acc: 0.9003 - val_loss: 3307.0464 - val_acc: 0.8986\n",
      "Epoch 178/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 363.0203 - acc: 0.9003 - val_loss: 3283.0234 - val_acc: 0.8986\n",
      "Epoch 179/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 360.3474 - acc: 0.9003 - val_loss: 3258.8381 - val_acc: 0.8986\n",
      "Epoch 180/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 357.7116 - acc: 0.9003 - val_loss: 3235.0916 - val_acc: 0.8986\n",
      "Epoch 181/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 355.1084 - acc: 0.9003 - val_loss: 3211.5193 - val_acc: 0.8986\n",
      "Epoch 182/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 352.5359 - acc: 0.9003 - val_loss: 3188.2673 - val_acc: 0.8986\n",
      "Epoch 183/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 349.9995 - acc: 0.9003 - val_loss: 3165.2351 - val_acc: 0.8986\n",
      "Epoch 184/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 347.4988 - acc: 0.9003 - val_loss: 3142.5315 - val_acc: 0.8986\n",
      "Epoch 185/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 345.0287 - acc: 0.9003 - val_loss: 3120.1606 - val_acc: 0.8986\n",
      "Epoch 186/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 342.5878 - acc: 0.9003 - val_loss: 3098.0024 - val_acc: 0.8986\n",
      "Epoch 187/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 340.1716 - acc: 0.9003 - val_loss: 3076.1841 - val_acc: 0.8986\n",
      "Epoch 188/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 337.7825 - acc: 0.9003 - val_loss: 3054.5701 - val_acc: 0.8986\n",
      "Epoch 189/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 335.4275 - acc: 0.9003 - val_loss: 3033.3262 - val_acc: 0.8986\n",
      "Epoch 190/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 333.1084 - acc: 0.9003 - val_loss: 3012.3411 - val_acc: 0.8986\n",
      "Epoch 191/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 330.8273 - acc: 0.9003 - val_loss: 2991.6541 - val_acc: 0.8986\n",
      "Epoch 192/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 328.5782 - acc: 0.9003 - val_loss: 2971.2205 - val_acc: 0.8986\n",
      "Epoch 193/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 326.3572 - acc: 0.9003 - val_loss: 2951.0999 - val_acc: 0.8986\n",
      "Epoch 194/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 324.1654 - acc: 0.9003 - val_loss: 2931.2190 - val_acc: 0.8986\n",
      "Epoch 195/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 322.0040 - acc: 0.9003 - val_loss: 2911.7166 - val_acc: 0.8986\n",
      "Epoch 196/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 319.8783 - acc: 0.9003 - val_loss: 2892.4202 - val_acc: 0.8986\n",
      "Epoch 197/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 317.7751 - acc: 0.9003 - val_loss: 2873.3865 - val_acc: 0.8986\n",
      "Epoch 198/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 315.7022 - acc: 0.9003 - val_loss: 2854.6067 - val_acc: 0.8986\n",
      "Epoch 199/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 313.6602 - acc: 0.9003 - val_loss: 2836.1050 - val_acc: 0.8986\n",
      "Epoch 200/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 311.6444 - acc: 0.9003 - val_loss: 2817.8965 - val_acc: 0.8986\n",
      "Epoch 201/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 309.6543 - acc: 0.9003 - val_loss: 2799.8298 - val_acc: 0.8986\n",
      "Epoch 202/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 307.6877 - acc: 0.9001 - val_loss: 2782.0125 - val_acc: 0.8986\n",
      "Epoch 203/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 305.7456 - acc: 0.9003 - val_loss: 2764.3513 - val_acc: 0.8985\n",
      "Epoch 204/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 303.8292 - acc: 0.9001 - val_loss: 2747.1274 - val_acc: 0.8985\n",
      "Epoch 205/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 301.9359 - acc: 0.9001 - val_loss: 2729.8271 - val_acc: 0.8983\n",
      "Epoch 206/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 300.0645 - acc: 0.9000 - val_loss: 2713.1477 - val_acc: 0.8985\n",
      "Epoch 207/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 298.2230 - acc: 0.9001 - val_loss: 2696.3164 - val_acc: 0.8980\n",
      "Epoch 208/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 296.4155 - acc: 0.8997 - val_loss: 2680.5627 - val_acc: 0.8984\n",
      "Epoch 209/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 294.6594 - acc: 0.9001 - val_loss: 2664.6245 - val_acc: 0.8973\n",
      "Epoch 210/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 292.9722 - acc: 0.8990 - val_loss: 2650.9360 - val_acc: 0.8985\n",
      "Epoch 211/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 291.4015 - acc: 0.9001 - val_loss: 2637.1133 - val_acc: 0.8960\n",
      "Epoch 212/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 289.9969 - acc: 0.8973 - val_loss: 2628.0842 - val_acc: 0.8986\n",
      "Epoch 213/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 288.8728 - acc: 0.9003 - val_loss: 2618.4651 - val_acc: 0.8941\n",
      "Epoch 214/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 287.9602 - acc: 0.8953 - val_loss: 2614.8337 - val_acc: 0.8986\n",
      "Epoch 215/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 287.3905 - acc: 0.9003 - val_loss: 2605.0515 - val_acc: 0.8922\n",
      "Epoch 216/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 286.4669 - acc: 0.8933 - val_loss: 2596.6267 - val_acc: 0.8986\n",
      "Epoch 217/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 285.3897 - acc: 0.9003 - val_loss: 2576.2441 - val_acc: 0.8918\n",
      "Epoch 218/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 283.3047 - acc: 0.8931 - val_loss: 2558.3008 - val_acc: 0.8986\n",
      "Epoch 219/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 281.2295 - acc: 0.9003 - val_loss: 2534.3635 - val_acc: 0.8929\n",
      "Epoch 220/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 278.7351 - acc: 0.8942 - val_loss: 2515.3748 - val_acc: 0.8985\n",
      "Epoch 221/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 276.5841 - acc: 0.9001 - val_loss: 2495.4192 - val_acc: 0.8940\n",
      "Epoch 222/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 274.4873 - acc: 0.8953 - val_loss: 2479.1423 - val_acc: 0.8981\n",
      "Epoch 223/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 272.6526 - acc: 0.8997 - val_loss: 2462.6702 - val_acc: 0.8948\n",
      "Epoch 224/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 270.9045 - acc: 0.8961 - val_loss: 2448.2004 - val_acc: 0.8976\n",
      "Epoch 225/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 269.2903 - acc: 0.8994 - val_loss: 2433.7383 - val_acc: 0.8952\n",
      "Epoch 226/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 267.7339 - acc: 0.8964 - val_loss: 2420.2576 - val_acc: 0.8972\n",
      "Epoch 227/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 266.2383 - acc: 0.8990 - val_loss: 2406.7698 - val_acc: 0.8954\n",
      "Epoch 228/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 264.7778 - acc: 0.8966 - val_loss: 2393.8604 - val_acc: 0.8969\n",
      "Epoch 229/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 263.3474 - acc: 0.8986 - val_loss: 2380.9177 - val_acc: 0.8956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 230/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 261.9409 - acc: 0.8971 - val_loss: 2368.4102 - val_acc: 0.8967\n",
      "Epoch 231/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 260.5542 - acc: 0.8985 - val_loss: 2355.8530 - val_acc: 0.8957\n",
      "Epoch 232/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 259.1880 - acc: 0.8974 - val_loss: 2343.6191 - val_acc: 0.8966\n",
      "Epoch 233/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 257.8342 - acc: 0.8982 - val_loss: 2331.3835 - val_acc: 0.8958\n",
      "Epoch 234/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 256.4983 - acc: 0.8973 - val_loss: 2319.4202 - val_acc: 0.8965\n",
      "Epoch 235/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 255.1753 - acc: 0.8982 - val_loss: 2307.4353 - val_acc: 0.8958\n",
      "Epoch 236/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 253.8660 - acc: 0.8975 - val_loss: 2295.6799 - val_acc: 0.8965\n",
      "Epoch 237/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 252.5693 - acc: 0.8982 - val_loss: 2283.9026 - val_acc: 0.8958\n",
      "Epoch 238/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 251.2843 - acc: 0.8975 - val_loss: 2272.4148 - val_acc: 0.8965\n",
      "Epoch 239/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 250.0142 - acc: 0.8982 - val_loss: 2260.8750 - val_acc: 0.8959\n",
      "Epoch 240/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 248.7566 - acc: 0.8975 - val_loss: 2249.6108 - val_acc: 0.8965\n",
      "Epoch 241/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 247.5098 - acc: 0.8984 - val_loss: 2238.2698 - val_acc: 0.8959\n",
      "Epoch 242/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 246.2759 - acc: 0.8976 - val_loss: 2227.2107 - val_acc: 0.8965\n",
      "Epoch 243/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 245.0546 - acc: 0.8986 - val_loss: 2216.1101 - val_acc: 0.8959\n",
      "Epoch 244/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 243.8446 - acc: 0.8976 - val_loss: 2205.2434 - val_acc: 0.8966\n",
      "Epoch 245/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 242.6449 - acc: 0.8986 - val_loss: 2194.3188 - val_acc: 0.8960\n",
      "Epoch 246/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 241.4540 - acc: 0.8976 - val_loss: 2183.6477 - val_acc: 0.8966\n",
      "Epoch 247/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 240.2751 - acc: 0.8984 - val_loss: 2172.9805 - val_acc: 0.8960\n",
      "Epoch 248/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 239.1089 - acc: 0.8977 - val_loss: 2162.5154 - val_acc: 0.8967\n",
      "Epoch 249/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 237.9547 - acc: 0.8985 - val_loss: 2152.0437 - val_acc: 0.8960\n",
      "Epoch 250/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 236.8138 - acc: 0.8977 - val_loss: 2141.8430 - val_acc: 0.8968\n",
      "Epoch 251/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 235.6832 - acc: 0.8986 - val_loss: 2131.5916 - val_acc: 0.8959\n",
      "Epoch 252/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 234.5675 - acc: 0.8977 - val_loss: 2121.6348 - val_acc: 0.8969\n",
      "Epoch 253/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 233.4656 - acc: 0.8987 - val_loss: 2111.6221 - val_acc: 0.8958\n",
      "Epoch 254/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 232.3767 - acc: 0.8977 - val_loss: 2101.9998 - val_acc: 0.8970\n",
      "Epoch 255/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 231.3055 - acc: 0.8988 - val_loss: 2092.1875 - val_acc: 0.8956\n",
      "Epoch 256/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 230.2439 - acc: 0.8975 - val_loss: 2083.0078 - val_acc: 0.8970\n",
      "Epoch 257/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 229.2128 - acc: 0.8990 - val_loss: 2073.5186 - val_acc: 0.8954\n",
      "Epoch 258/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 228.1917 - acc: 0.8974 - val_loss: 2064.9258 - val_acc: 0.8972\n",
      "Epoch 259/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 227.2250 - acc: 0.8990 - val_loss: 2056.1858 - val_acc: 0.8952\n",
      "Epoch 260/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 226.2825 - acc: 0.8968 - val_loss: 2048.6423 - val_acc: 0.8974\n",
      "Epoch 261/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 225.4253 - acc: 0.8994 - val_loss: 2040.8828 - val_acc: 0.8947\n",
      "Epoch 262/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 224.5948 - acc: 0.8963 - val_loss: 2035.1948 - val_acc: 0.8978\n",
      "Epoch 263/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 223.9286 - acc: 0.8995 - val_loss: 2028.9492 - val_acc: 0.8944\n",
      "Epoch 264/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 223.2776 - acc: 0.8958 - val_loss: 2025.9670 - val_acc: 0.8980\n",
      "Epoch 265/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 222.8889 - acc: 0.8996 - val_loss: 2020.9741 - val_acc: 0.8935\n",
      "Epoch 266/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 222.3849 - acc: 0.8944 - val_loss: 2020.1750 - val_acc: 0.8983\n",
      "Epoch 267/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 222.2296 - acc: 0.8999 - val_loss: 2014.0730 - val_acc: 0.8926\n",
      "Epoch 268/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 221.6054 - acc: 0.8936 - val_loss: 2011.9825 - val_acc: 0.8985\n",
      "Epoch 269/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 221.3141 - acc: 0.9001 - val_loss: 2000.8467 - val_acc: 0.8922\n",
      "Epoch 270/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 220.1423 - acc: 0.8937 - val_loss: 1994.3192 - val_acc: 0.8985\n",
      "Epoch 271/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 219.3867 - acc: 0.9001 - val_loss: 1979.0475 - val_acc: 0.8927\n",
      "Epoch 272/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 217.7543 - acc: 0.8942 - val_loss: 1968.6078 - val_acc: 0.8983\n",
      "Epoch 273/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 216.5946 - acc: 0.8999 - val_loss: 1953.1121 - val_acc: 0.8936\n",
      "Epoch 274/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 214.9227 - acc: 0.8947 - val_loss: 1941.7827 - val_acc: 0.8980\n",
      "Epoch 275/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 213.6851 - acc: 0.8996 - val_loss: 1928.4718 - val_acc: 0.8943\n",
      "Epoch 276/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 212.2369 - acc: 0.8961 - val_loss: 1917.7941 - val_acc: 0.8978\n",
      "Epoch 277/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 211.0773 - acc: 0.8995 - val_loss: 1906.9766 - val_acc: 0.8950\n",
      "Epoch 278/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 209.8917 - acc: 0.8965 - val_loss: 1897.4120 - val_acc: 0.8974\n",
      "Epoch 279/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 208.8555 - acc: 0.8995 - val_loss: 1888.0560 - val_acc: 0.8953\n",
      "Epoch 280/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 207.8256 - acc: 0.8966 - val_loss: 1879.3442 - val_acc: 0.8973\n",
      "Epoch 281/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 206.8773 - acc: 0.8991 - val_loss: 1870.8103 - val_acc: 0.8956\n",
      "Epoch 282/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 205.9387 - acc: 0.8970 - val_loss: 1862.6619 - val_acc: 0.8971\n",
      "Epoch 283/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 205.0503 - acc: 0.8990 - val_loss: 1854.7203 - val_acc: 0.8959\n",
      "Epoch 284/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 204.1741 - acc: 0.8975 - val_loss: 1846.9407 - val_acc: 0.8971\n",
      "Epoch 285/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 203.3254 - acc: 0.8988 - val_loss: 1839.3164 - val_acc: 0.8960\n",
      "Epoch 286/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 202.4824 - acc: 0.8978 - val_loss: 1831.7932 - val_acc: 0.8971\n",
      "Epoch 287/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 201.6566 - acc: 0.8985 - val_loss: 1824.3483 - val_acc: 0.8962\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 288/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 200.8369 - acc: 0.8978 - val_loss: 1817.0092 - val_acc: 0.8971\n",
      "Epoch 289/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 200.0310 - acc: 0.8987 - val_loss: 1809.7479 - val_acc: 0.8963\n",
      "Epoch 290/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 199.2285 - acc: 0.8978 - val_loss: 1802.5626 - val_acc: 0.8971\n",
      "Epoch 291/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 198.4380 - acc: 0.8984 - val_loss: 1795.4595 - val_acc: 0.8963\n",
      "Epoch 292/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 197.6521 - acc: 0.8978 - val_loss: 1788.3958 - val_acc: 0.8972\n",
      "Epoch 293/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 196.8762 - acc: 0.8982 - val_loss: 1781.4198 - val_acc: 0.8964\n",
      "Epoch 294/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 196.1053 - acc: 0.8979 - val_loss: 1774.4648 - val_acc: 0.8972\n",
      "Epoch 295/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 195.3406 - acc: 0.8984 - val_loss: 1767.5867 - val_acc: 0.8964\n",
      "Epoch 296/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 194.5823 - acc: 0.8979 - val_loss: 1760.7463 - val_acc: 0.8972\n",
      "Epoch 297/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 193.8307 - acc: 0.8986 - val_loss: 1754.0028 - val_acc: 0.8964\n",
      "Epoch 298/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 193.0852 - acc: 0.8980 - val_loss: 1747.2656 - val_acc: 0.8972\n",
      "Epoch 299/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 192.3473 - acc: 0.8986 - val_loss: 1740.6445 - val_acc: 0.8964\n",
      "Epoch 300/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 191.6132 - acc: 0.8981 - val_loss: 1734.0009 - val_acc: 0.8972\n",
      "3000/3000 [==============================] - 0s 32us/step\n",
      "['loss', 'acc'] [0.6445642221768697, 0.9089999998410543]\n",
      "[[0.66108923 0.95594316]] [[0.00266594 0.9957009  0.988624  ]]\n"
     ]
    }
   ],
   "source": [
    "mask_value = -1.0\n",
    "model = multi_learning_demo(activation='sigmoid', loss=[binary_focal_loss(alpha=.25, gamma=2, mask_value=mask_value)]\n",
    "                                       , mask_value=mask_value)\n",
    "x = np.random.rand(1,2)\n",
    "print(x, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### softmax + Focal Lossなし\n",
    "- うまくいってる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not sigmoid\n",
      "(100000, 3) [[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]]\n",
      "0.0    50159\n",
      "1.0    49841\n",
      "dtype: int64\n",
      "1.0    50159\n",
      "0.0    49841\n",
      "dtype: int64\n",
      "0.0    100000\n",
      "dtype: int64\n",
      "input_dim, nb_classes: 2 3\n",
      "Train on 9700 samples, validate on 87300 samples\n",
      "Epoch 1/300\n",
      "9700/9700 [==============================] - 0s 16us/step - loss: 1.1053 - acc: 0.1644 - val_loss: 1.0882 - val_acc: 0.2577\n",
      "Epoch 2/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1.0888 - acc: 0.2552 - val_loss: 1.0771 - val_acc: 0.4151\n",
      "Epoch 3/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1.0777 - acc: 0.4045 - val_loss: 1.0690 - val_acc: 0.5027\n",
      "Epoch 4/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1.0696 - acc: 0.4952 - val_loss: 1.0603 - val_acc: 0.5027\n",
      "Epoch 5/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1.0609 - acc: 0.4952 - val_loss: 1.0517 - val_acc: 0.5027\n",
      "Epoch 6/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1.0524 - acc: 0.4952 - val_loss: 1.0432 - val_acc: 0.5027\n",
      "Epoch 7/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1.0439 - acc: 0.4952 - val_loss: 1.0346 - val_acc: 0.5027\n",
      "Epoch 8/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1.0354 - acc: 0.4952 - val_loss: 1.0265 - val_acc: 0.5027\n",
      "Epoch 9/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1.0273 - acc: 0.4952 - val_loss: 1.0178 - val_acc: 0.5027\n",
      "Epoch 10/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1.0187 - acc: 0.4952 - val_loss: 1.0091 - val_acc: 0.5027\n",
      "Epoch 11/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1.0101 - acc: 0.4952 - val_loss: 1.0003 - val_acc: 0.5027\n",
      "Epoch 12/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 1.0013 - acc: 0.4952 - val_loss: 0.9915 - val_acc: 0.5027\n",
      "Epoch 13/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.9926 - acc: 0.4952 - val_loss: 0.9826 - val_acc: 0.5027\n",
      "Epoch 14/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.9838 - acc: 0.4952 - val_loss: 0.9737 - val_acc: 0.5027\n",
      "Epoch 15/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.9749 - acc: 0.4952 - val_loss: 0.9648 - val_acc: 0.5027\n",
      "Epoch 16/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.9661 - acc: 0.4952 - val_loss: 0.9559 - val_acc: 0.5027\n",
      "Epoch 17/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.9572 - acc: 0.4952 - val_loss: 0.9469 - val_acc: 0.5027\n",
      "Epoch 18/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.9483 - acc: 0.4952 - val_loss: 0.9378 - val_acc: 0.5027\n",
      "Epoch 19/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.9393 - acc: 0.4952 - val_loss: 0.9288 - val_acc: 0.5027\n",
      "Epoch 20/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.9304 - acc: 0.4952 - val_loss: 0.9197 - val_acc: 0.5027\n",
      "Epoch 21/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.9213 - acc: 0.4952 - val_loss: 0.9105 - val_acc: 0.5027\n",
      "Epoch 22/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.9122 - acc: 0.4952 - val_loss: 0.9013 - val_acc: 0.5027\n",
      "Epoch 23/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.9031 - acc: 0.4952 - val_loss: 0.8920 - val_acc: 0.5027\n",
      "Epoch 24/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.8939 - acc: 0.4952 - val_loss: 0.8826 - val_acc: 0.5027\n",
      "Epoch 25/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.8846 - acc: 0.4952 - val_loss: 0.8731 - val_acc: 0.5027\n",
      "Epoch 26/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.8752 - acc: 0.4952 - val_loss: 0.8635 - val_acc: 0.5027\n",
      "Epoch 27/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.8657 - acc: 0.4952 - val_loss: 0.8539 - val_acc: 0.5027\n",
      "Epoch 28/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.8562 - acc: 0.4952 - val_loss: 0.8445 - val_acc: 0.5027\n",
      "Epoch 29/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.8468 - acc: 0.4952 - val_loss: 0.8351 - val_acc: 0.5027\n",
      "Epoch 30/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.8375 - acc: 0.4952 - val_loss: 0.8258 - val_acc: 0.5027\n",
      "Epoch 31/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.8284 - acc: 0.4952 - val_loss: 0.8167 - val_acc: 0.5027\n",
      "Epoch 32/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.8193 - acc: 0.4952 - val_loss: 0.8077 - val_acc: 0.5027\n",
      "Epoch 33/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.8104 - acc: 0.4952 - val_loss: 0.7988 - val_acc: 0.5027\n",
      "Epoch 34/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.8016 - acc: 0.4952 - val_loss: 0.7901 - val_acc: 0.5027\n",
      "Epoch 35/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.7929 - acc: 0.4952 - val_loss: 0.7814 - val_acc: 0.5031\n",
      "Epoch 36/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.7844 - acc: 0.4964 - val_loss: 0.7731 - val_acc: 0.5044\n",
      "Epoch 37/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.7761 - acc: 0.4978 - val_loss: 0.7647 - val_acc: 0.5071\n",
      "Epoch 38/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.7679 - acc: 0.5004 - val_loss: 0.7565 - val_acc: 0.5118\n",
      "Epoch 39/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.7598 - acc: 0.5055 - val_loss: 0.7485 - val_acc: 0.5174\n",
      "Epoch 40/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.7518 - acc: 0.5115 - val_loss: 0.7406 - val_acc: 0.5260\n",
      "Epoch 41/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.7439 - acc: 0.5185 - val_loss: 0.7328 - val_acc: 0.5370\n",
      "Epoch 42/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.7361 - acc: 0.5297 - val_loss: 0.7251 - val_acc: 0.5500\n",
      "Epoch 43/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.7285 - acc: 0.5432 - val_loss: 0.7175 - val_acc: 0.5626\n",
      "Epoch 44/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.7210 - acc: 0.5563 - val_loss: 0.7101 - val_acc: 0.5737\n",
      "Epoch 45/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.7136 - acc: 0.5666 - val_loss: 0.7028 - val_acc: 0.5851\n",
      "Epoch 46/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.7063 - acc: 0.5778 - val_loss: 0.6955 - val_acc: 0.5968\n",
      "Epoch 47/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6991 - acc: 0.5895 - val_loss: 0.6883 - val_acc: 0.6088\n",
      "Epoch 48/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6919 - acc: 0.6029 - val_loss: 0.6811 - val_acc: 0.6212\n",
      "Epoch 49/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6848 - acc: 0.6161 - val_loss: 0.6740 - val_acc: 0.6335\n",
      "Epoch 50/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6777 - acc: 0.6285 - val_loss: 0.6670 - val_acc: 0.6461\n",
      "Epoch 51/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6707 - acc: 0.6407 - val_loss: 0.6600 - val_acc: 0.6587\n",
      "Epoch 52/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6637 - acc: 0.6536 - val_loss: 0.6530 - val_acc: 0.6716\n",
      "Epoch 53/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6568 - acc: 0.6671 - val_loss: 0.6462 - val_acc: 0.6832\n",
      "Epoch 54/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6499 - acc: 0.6797 - val_loss: 0.6394 - val_acc: 0.6942\n",
      "Epoch 55/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6431 - acc: 0.6908 - val_loss: 0.6326 - val_acc: 0.7050\n",
      "Epoch 56/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6364 - acc: 0.7007 - val_loss: 0.6259 - val_acc: 0.7148\n",
      "Epoch 57/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6298 - acc: 0.7111 - val_loss: 0.6193 - val_acc: 0.7243\n",
      "Epoch 58/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6232 - acc: 0.7219 - val_loss: 0.6128 - val_acc: 0.7326\n",
      "Epoch 59/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6166 - acc: 0.7286 - val_loss: 0.6062 - val_acc: 0.7406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6101 - acc: 0.7368 - val_loss: 0.5998 - val_acc: 0.7485\n",
      "Epoch 61/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6037 - acc: 0.7434 - val_loss: 0.5933 - val_acc: 0.7562\n",
      "Epoch 62/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5972 - acc: 0.7518 - val_loss: 0.5869 - val_acc: 0.7637\n",
      "Epoch 63/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5909 - acc: 0.7594 - val_loss: 0.5805 - val_acc: 0.7707\n",
      "Epoch 64/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5845 - acc: 0.7671 - val_loss: 0.5742 - val_acc: 0.7776\n",
      "Epoch 65/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5781 - acc: 0.7746 - val_loss: 0.5678 - val_acc: 0.7845\n",
      "Epoch 66/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5718 - acc: 0.7820 - val_loss: 0.5615 - val_acc: 0.7915\n",
      "Epoch 67/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5655 - acc: 0.7867 - val_loss: 0.5551 - val_acc: 0.7980\n",
      "Epoch 68/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5592 - acc: 0.7924 - val_loss: 0.5488 - val_acc: 0.8034\n",
      "Epoch 69/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5529 - acc: 0.7989 - val_loss: 0.5425 - val_acc: 0.8092\n",
      "Epoch 70/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5466 - acc: 0.8053 - val_loss: 0.5363 - val_acc: 0.8149\n",
      "Epoch 71/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5404 - acc: 0.8112 - val_loss: 0.5300 - val_acc: 0.8205\n",
      "Epoch 72/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5341 - acc: 0.8167 - val_loss: 0.5237 - val_acc: 0.8264\n",
      "Epoch 73/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5279 - acc: 0.8221 - val_loss: 0.5175 - val_acc: 0.8320\n",
      "Epoch 74/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5216 - acc: 0.8268 - val_loss: 0.5112 - val_acc: 0.8372\n",
      "Epoch 75/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5154 - acc: 0.8312 - val_loss: 0.5050 - val_acc: 0.8424\n",
      "Epoch 76/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5092 - acc: 0.8366 - val_loss: 0.4987 - val_acc: 0.8479\n",
      "Epoch 77/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5029 - acc: 0.8412 - val_loss: 0.4925 - val_acc: 0.8529\n",
      "Epoch 78/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4967 - acc: 0.8460 - val_loss: 0.4863 - val_acc: 0.8578\n",
      "Epoch 79/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4905 - acc: 0.8496 - val_loss: 0.4800 - val_acc: 0.8621\n",
      "Epoch 80/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4843 - acc: 0.8549 - val_loss: 0.4738 - val_acc: 0.8663\n",
      "Epoch 81/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4781 - acc: 0.8594 - val_loss: 0.4676 - val_acc: 0.8708\n",
      "Epoch 82/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4719 - acc: 0.8639 - val_loss: 0.4614 - val_acc: 0.8747\n",
      "Epoch 83/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4657 - acc: 0.8689 - val_loss: 0.4552 - val_acc: 0.8787\n",
      "Epoch 84/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4595 - acc: 0.8736 - val_loss: 0.4490 - val_acc: 0.8828\n",
      "Epoch 85/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4533 - acc: 0.8777 - val_loss: 0.4428 - val_acc: 0.8866\n",
      "Epoch 86/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4471 - acc: 0.8820 - val_loss: 0.4367 - val_acc: 0.8902\n",
      "Epoch 87/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4409 - acc: 0.8864 - val_loss: 0.4305 - val_acc: 0.8936\n",
      "Epoch 88/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4348 - acc: 0.8897 - val_loss: 0.4244 - val_acc: 0.8969\n",
      "Epoch 89/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4286 - acc: 0.8936 - val_loss: 0.4183 - val_acc: 0.9001\n",
      "Epoch 90/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4225 - acc: 0.8960 - val_loss: 0.4122 - val_acc: 0.9032\n",
      "Epoch 91/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4164 - acc: 0.8989 - val_loss: 0.4061 - val_acc: 0.9057\n",
      "Epoch 92/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4103 - acc: 0.9015 - val_loss: 0.4001 - val_acc: 0.9082\n",
      "Epoch 93/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4043 - acc: 0.9041 - val_loss: 0.3941 - val_acc: 0.9106\n",
      "Epoch 94/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3982 - acc: 0.9058 - val_loss: 0.3881 - val_acc: 0.9123\n",
      "Epoch 95/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3923 - acc: 0.9085 - val_loss: 0.3822 - val_acc: 0.9143\n",
      "Epoch 96/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3863 - acc: 0.9098 - val_loss: 0.3763 - val_acc: 0.9161\n",
      "Epoch 97/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3804 - acc: 0.9121 - val_loss: 0.3704 - val_acc: 0.9179\n",
      "Epoch 98/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3745 - acc: 0.9131 - val_loss: 0.3646 - val_acc: 0.9192\n",
      "Epoch 99/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3686 - acc: 0.9146 - val_loss: 0.3588 - val_acc: 0.9208\n",
      "Epoch 100/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3629 - acc: 0.9161 - val_loss: 0.3531 - val_acc: 0.9222\n",
      "Epoch 101/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3571 - acc: 0.9177 - val_loss: 0.3474 - val_acc: 0.9238\n",
      "Epoch 102/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3514 - acc: 0.9192 - val_loss: 0.3418 - val_acc: 0.9252\n",
      "Epoch 103/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3457 - acc: 0.9207 - val_loss: 0.3362 - val_acc: 0.9262\n",
      "Epoch 104/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3401 - acc: 0.9220 - val_loss: 0.3307 - val_acc: 0.9273\n",
      "Epoch 105/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3345 - acc: 0.9226 - val_loss: 0.3253 - val_acc: 0.9285\n",
      "Epoch 106/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3290 - acc: 0.9247 - val_loss: 0.3199 - val_acc: 0.9298\n",
      "Epoch 107/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3236 - acc: 0.9261 - val_loss: 0.3145 - val_acc: 0.9306\n",
      "Epoch 108/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3182 - acc: 0.9277 - val_loss: 0.3092 - val_acc: 0.9317\n",
      "Epoch 109/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3129 - acc: 0.9295 - val_loss: 0.3040 - val_acc: 0.9328\n",
      "Epoch 110/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3076 - acc: 0.9305 - val_loss: 0.2988 - val_acc: 0.9336\n",
      "Epoch 111/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3023 - acc: 0.9319 - val_loss: 0.2936 - val_acc: 0.9347\n",
      "Epoch 112/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2971 - acc: 0.9331 - val_loss: 0.2885 - val_acc: 0.9358\n",
      "Epoch 113/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2919 - acc: 0.9345 - val_loss: 0.2835 - val_acc: 0.9372\n",
      "Epoch 114/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2869 - acc: 0.9367 - val_loss: 0.2786 - val_acc: 0.9386\n",
      "Epoch 115/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2819 - acc: 0.9378 - val_loss: 0.2738 - val_acc: 0.9400\n",
      "Epoch 116/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2770 - acc: 0.9387 - val_loss: 0.2690 - val_acc: 0.9414\n",
      "Epoch 117/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2722 - acc: 0.9395 - val_loss: 0.2643 - val_acc: 0.9424\n",
      "Epoch 118/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2674 - acc: 0.9404 - val_loss: 0.2596 - val_acc: 0.9437\n",
      "Epoch 119/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2626 - acc: 0.9415 - val_loss: 0.2549 - val_acc: 0.9447\n",
      "Epoch 120/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2579 - acc: 0.9422 - val_loss: 0.2503 - val_acc: 0.9460\n",
      "Epoch 121/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2532 - acc: 0.9439 - val_loss: 0.2456 - val_acc: 0.9471\n",
      "Epoch 122/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2485 - acc: 0.9453 - val_loss: 0.2409 - val_acc: 0.9481\n",
      "Epoch 123/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2437 - acc: 0.9464 - val_loss: 0.2363 - val_acc: 0.9490\n",
      "Epoch 124/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2390 - acc: 0.9472 - val_loss: 0.2316 - val_acc: 0.9503\n",
      "Epoch 125/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2342 - acc: 0.9479 - val_loss: 0.2270 - val_acc: 0.9516\n",
      "Epoch 126/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2296 - acc: 0.9510 - val_loss: 0.2225 - val_acc: 0.9527\n",
      "Epoch 127/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2250 - acc: 0.9526 - val_loss: 0.2181 - val_acc: 0.9539\n",
      "Epoch 128/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2206 - acc: 0.9537 - val_loss: 0.2139 - val_acc: 0.9552\n",
      "Epoch 129/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2162 - acc: 0.9554 - val_loss: 0.2097 - val_acc: 0.9564\n",
      "Epoch 130/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2120 - acc: 0.9566 - val_loss: 0.2056 - val_acc: 0.9575\n",
      "Epoch 131/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2078 - acc: 0.9577 - val_loss: 0.2016 - val_acc: 0.9586\n",
      "Epoch 132/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2038 - acc: 0.9590 - val_loss: 0.1977 - val_acc: 0.9596\n",
      "Epoch 133/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1998 - acc: 0.9607 - val_loss: 0.1939 - val_acc: 0.9608\n",
      "Epoch 134/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1959 - acc: 0.9616 - val_loss: 0.1902 - val_acc: 0.9619\n",
      "Epoch 135/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1921 - acc: 0.9634 - val_loss: 0.1865 - val_acc: 0.9629\n",
      "Epoch 136/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1884 - acc: 0.9644 - val_loss: 0.1830 - val_acc: 0.9642\n",
      "Epoch 137/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1848 - acc: 0.9655 - val_loss: 0.1795 - val_acc: 0.9652\n",
      "Epoch 138/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1813 - acc: 0.9661 - val_loss: 0.1761 - val_acc: 0.9662\n",
      "Epoch 139/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1778 - acc: 0.9668 - val_loss: 0.1728 - val_acc: 0.9674\n",
      "Epoch 140/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1745 - acc: 0.9675 - val_loss: 0.1696 - val_acc: 0.9684\n",
      "Epoch 141/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1712 - acc: 0.9684 - val_loss: 0.1664 - val_acc: 0.9694\n",
      "Epoch 142/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1680 - acc: 0.9693 - val_loss: 0.1633 - val_acc: 0.9703\n",
      "Epoch 143/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1648 - acc: 0.9708 - val_loss: 0.1603 - val_acc: 0.9712\n",
      "Epoch 144/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1618 - acc: 0.9719 - val_loss: 0.1574 - val_acc: 0.9719\n",
      "Epoch 145/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1588 - acc: 0.9726 - val_loss: 0.1545 - val_acc: 0.9728\n",
      "Epoch 146/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1559 - acc: 0.9734 - val_loss: 0.1517 - val_acc: 0.9737\n",
      "Epoch 147/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1530 - acc: 0.9741 - val_loss: 0.1490 - val_acc: 0.9745\n",
      "Epoch 148/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1503 - acc: 0.9753 - val_loss: 0.1464 - val_acc: 0.9752\n",
      "Epoch 149/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1476 - acc: 0.9762 - val_loss: 0.1438 - val_acc: 0.9761\n",
      "Epoch 150/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1449 - acc: 0.9767 - val_loss: 0.1412 - val_acc: 0.9768\n",
      "Epoch 151/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1424 - acc: 0.9775 - val_loss: 0.1388 - val_acc: 0.9775\n",
      "Epoch 152/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1399 - acc: 0.9785 - val_loss: 0.1364 - val_acc: 0.9785\n",
      "Epoch 153/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1374 - acc: 0.9790 - val_loss: 0.1340 - val_acc: 0.9791\n",
      "Epoch 154/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1351 - acc: 0.9795 - val_loss: 0.1318 - val_acc: 0.9797\n",
      "Epoch 155/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1328 - acc: 0.9803 - val_loss: 0.1296 - val_acc: 0.9804\n",
      "Epoch 156/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1305 - acc: 0.9810 - val_loss: 0.1274 - val_acc: 0.9809\n",
      "Epoch 157/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1283 - acc: 0.9816 - val_loss: 0.1253 - val_acc: 0.9815\n",
      "Epoch 158/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1262 - acc: 0.9823 - val_loss: 0.1232 - val_acc: 0.9820\n",
      "Epoch 159/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1241 - acc: 0.9832 - val_loss: 0.1212 - val_acc: 0.9826\n",
      "Epoch 160/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1221 - acc: 0.9834 - val_loss: 0.1193 - val_acc: 0.9832\n",
      "Epoch 161/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1201 - acc: 0.9839 - val_loss: 0.1174 - val_acc: 0.9838\n",
      "Epoch 162/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1182 - acc: 0.9841 - val_loss: 0.1156 - val_acc: 0.9844\n",
      "Epoch 163/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1163 - acc: 0.9843 - val_loss: 0.1138 - val_acc: 0.9849\n",
      "Epoch 164/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1145 - acc: 0.9847 - val_loss: 0.1120 - val_acc: 0.9855\n",
      "Epoch 165/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1127 - acc: 0.9856 - val_loss: 0.1103 - val_acc: 0.9861\n",
      "Epoch 166/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1110 - acc: 0.9863 - val_loss: 0.1087 - val_acc: 0.9867\n",
      "Epoch 167/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1093 - acc: 0.9866 - val_loss: 0.1070 - val_acc: 0.9870\n",
      "Epoch 168/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1077 - acc: 0.9870 - val_loss: 0.1055 - val_acc: 0.9875\n",
      "Epoch 169/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1061 - acc: 0.9875 - val_loss: 0.1039 - val_acc: 0.9879\n",
      "Epoch 170/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1046 - acc: 0.9880 - val_loss: 0.1024 - val_acc: 0.9882\n",
      "Epoch 171/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1031 - acc: 0.9886 - val_loss: 0.1010 - val_acc: 0.9886\n",
      "Epoch 172/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1016 - acc: 0.9887 - val_loss: 0.0995 - val_acc: 0.9891\n",
      "Epoch 173/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1001 - acc: 0.9890 - val_loss: 0.0981 - val_acc: 0.9894\n",
      "Epoch 174/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0988 - acc: 0.9892 - val_loss: 0.0968 - val_acc: 0.9899\n",
      "Epoch 175/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0974 - acc: 0.9893 - val_loss: 0.0955 - val_acc: 0.9902\n",
      "Epoch 176/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0961 - acc: 0.9898 - val_loss: 0.0942 - val_acc: 0.9905\n",
      "Epoch 177/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0948 - acc: 0.9900 - val_loss: 0.0929 - val_acc: 0.9908\n",
      "Epoch 178/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0935 - acc: 0.9907 - val_loss: 0.0917 - val_acc: 0.9911\n",
      "Epoch 179/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0923 - acc: 0.9910 - val_loss: 0.0905 - val_acc: 0.9915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0911 - acc: 0.9916 - val_loss: 0.0893 - val_acc: 0.9918\n",
      "Epoch 181/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0899 - acc: 0.9919 - val_loss: 0.0882 - val_acc: 0.9920\n",
      "Epoch 182/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0887 - acc: 0.9923 - val_loss: 0.0871 - val_acc: 0.9923\n",
      "Epoch 183/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0876 - acc: 0.9924 - val_loss: 0.0860 - val_acc: 0.9926\n",
      "Epoch 184/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0865 - acc: 0.9924 - val_loss: 0.0850 - val_acc: 0.9929\n",
      "Epoch 185/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0855 - acc: 0.9926 - val_loss: 0.0839 - val_acc: 0.9931\n",
      "Epoch 186/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0844 - acc: 0.9928 - val_loss: 0.0829 - val_acc: 0.9933\n",
      "Epoch 187/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0834 - acc: 0.9931 - val_loss: 0.0819 - val_acc: 0.9935\n",
      "Epoch 188/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0824 - acc: 0.9932 - val_loss: 0.0810 - val_acc: 0.9937\n",
      "Epoch 189/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0815 - acc: 0.9933 - val_loss: 0.0800 - val_acc: 0.9939\n",
      "Epoch 190/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0805 - acc: 0.9936 - val_loss: 0.0791 - val_acc: 0.9941\n",
      "Epoch 191/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0796 - acc: 0.9939 - val_loss: 0.0782 - val_acc: 0.9943\n",
      "Epoch 192/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0787 - acc: 0.9942 - val_loss: 0.0773 - val_acc: 0.9945\n",
      "Epoch 193/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0778 - acc: 0.9944 - val_loss: 0.0764 - val_acc: 0.9946\n",
      "Epoch 194/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0769 - acc: 0.9945 - val_loss: 0.0756 - val_acc: 0.9948\n",
      "Epoch 195/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0761 - acc: 0.9949 - val_loss: 0.0748 - val_acc: 0.9950\n",
      "Epoch 196/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0753 - acc: 0.9951 - val_loss: 0.0740 - val_acc: 0.9951\n",
      "Epoch 197/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0745 - acc: 0.9951 - val_loss: 0.0732 - val_acc: 0.9952\n",
      "Epoch 198/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0737 - acc: 0.9951 - val_loss: 0.0724 - val_acc: 0.9954\n",
      "Epoch 199/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0729 - acc: 0.9953 - val_loss: 0.0716 - val_acc: 0.9955\n",
      "Epoch 200/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0721 - acc: 0.9954 - val_loss: 0.0709 - val_acc: 0.9955\n",
      "Epoch 201/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0714 - acc: 0.9954 - val_loss: 0.0702 - val_acc: 0.9956\n",
      "Epoch 202/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0707 - acc: 0.9954 - val_loss: 0.0695 - val_acc: 0.9957\n",
      "Epoch 203/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0699 - acc: 0.9955 - val_loss: 0.0688 - val_acc: 0.9957\n",
      "Epoch 204/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0692 - acc: 0.9956 - val_loss: 0.0681 - val_acc: 0.9958\n",
      "Epoch 205/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0686 - acc: 0.9957 - val_loss: 0.0674 - val_acc: 0.9960\n",
      "Epoch 206/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0679 - acc: 0.9959 - val_loss: 0.0667 - val_acc: 0.9960\n",
      "Epoch 207/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0672 - acc: 0.9959 - val_loss: 0.0661 - val_acc: 0.9961\n",
      "Epoch 208/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0666 - acc: 0.9960 - val_loss: 0.0655 - val_acc: 0.9962\n",
      "Epoch 209/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0659 - acc: 0.9960 - val_loss: 0.0648 - val_acc: 0.9963\n",
      "Epoch 210/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0653 - acc: 0.9961 - val_loss: 0.0642 - val_acc: 0.9964\n",
      "Epoch 211/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0647 - acc: 0.9963 - val_loss: 0.0636 - val_acc: 0.9964\n",
      "Epoch 212/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0641 - acc: 0.9963 - val_loss: 0.0630 - val_acc: 0.9965\n",
      "Epoch 213/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0635 - acc: 0.9963 - val_loss: 0.0625 - val_acc: 0.9966\n",
      "Epoch 214/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0629 - acc: 0.9964 - val_loss: 0.0619 - val_acc: 0.9966\n",
      "Epoch 215/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0624 - acc: 0.9964 - val_loss: 0.0613 - val_acc: 0.9967\n",
      "Epoch 216/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0618 - acc: 0.9964 - val_loss: 0.0608 - val_acc: 0.9968\n",
      "Epoch 217/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0613 - acc: 0.9964 - val_loss: 0.0602 - val_acc: 0.9968\n",
      "Epoch 218/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0607 - acc: 0.9964 - val_loss: 0.0597 - val_acc: 0.9969\n",
      "Epoch 219/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0602 - acc: 0.9964 - val_loss: 0.0592 - val_acc: 0.9969\n",
      "Epoch 220/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0597 - acc: 0.9965 - val_loss: 0.0587 - val_acc: 0.9969\n",
      "Epoch 221/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0592 - acc: 0.9965 - val_loss: 0.0582 - val_acc: 0.9970\n",
      "Epoch 222/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0586 - acc: 0.9967 - val_loss: 0.0577 - val_acc: 0.9970\n",
      "Epoch 223/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0582 - acc: 0.9966 - val_loss: 0.0572 - val_acc: 0.9971\n",
      "Epoch 224/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0577 - acc: 0.9968 - val_loss: 0.0567 - val_acc: 0.9971\n",
      "Epoch 225/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0572 - acc: 0.9966 - val_loss: 0.0562 - val_acc: 0.9971\n",
      "Epoch 226/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0567 - acc: 0.9968 - val_loss: 0.0558 - val_acc: 0.9971\n",
      "Epoch 227/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0562 - acc: 0.9967 - val_loss: 0.0553 - val_acc: 0.9972\n",
      "Epoch 228/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0558 - acc: 0.9968 - val_loss: 0.0548 - val_acc: 0.9972\n",
      "Epoch 229/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0553 - acc: 0.9967 - val_loss: 0.0544 - val_acc: 0.9972\n",
      "Epoch 230/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0549 - acc: 0.9968 - val_loss: 0.0540 - val_acc: 0.9972\n",
      "Epoch 231/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0544 - acc: 0.9968 - val_loss: 0.0535 - val_acc: 0.9973\n",
      "Epoch 232/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0540 - acc: 0.9968 - val_loss: 0.0531 - val_acc: 0.9972\n",
      "Epoch 233/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0536 - acc: 0.9968 - val_loss: 0.0527 - val_acc: 0.9974\n",
      "Epoch 234/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0532 - acc: 0.9969 - val_loss: 0.0523 - val_acc: 0.9972\n",
      "Epoch 235/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0527 - acc: 0.9968 - val_loss: 0.0518 - val_acc: 0.9974\n",
      "Epoch 236/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0523 - acc: 0.9971 - val_loss: 0.0515 - val_acc: 0.9972\n",
      "Epoch 237/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0519 - acc: 0.9970 - val_loss: 0.0510 - val_acc: 0.9975\n",
      "Epoch 238/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0515 - acc: 0.9972 - val_loss: 0.0507 - val_acc: 0.9971\n",
      "Epoch 239/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0511 - acc: 0.9971 - val_loss: 0.0503 - val_acc: 0.9976\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0508 - acc: 0.9975 - val_loss: 0.0500 - val_acc: 0.9964\n",
      "Epoch 241/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0504 - acc: 0.9965 - val_loss: 0.0496 - val_acc: 0.9975\n",
      "Epoch 242/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0501 - acc: 0.9970 - val_loss: 0.0494 - val_acc: 0.9950\n",
      "Epoch 243/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0498 - acc: 0.9949 - val_loss: 0.0490 - val_acc: 0.9968\n",
      "Epoch 244/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0496 - acc: 0.9963 - val_loss: 0.0490 - val_acc: 0.9934\n",
      "Epoch 245/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0493 - acc: 0.9933 - val_loss: 0.0485 - val_acc: 0.9960\n",
      "Epoch 246/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0491 - acc: 0.9960 - val_loss: 0.0484 - val_acc: 0.9927\n",
      "Epoch 247/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0488 - acc: 0.9931 - val_loss: 0.0478 - val_acc: 0.9959\n",
      "Epoch 248/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0484 - acc: 0.9959 - val_loss: 0.0476 - val_acc: 0.9933\n",
      "Epoch 249/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0480 - acc: 0.9933 - val_loss: 0.0470 - val_acc: 0.9965\n",
      "Epoch 250/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0476 - acc: 0.9963 - val_loss: 0.0468 - val_acc: 0.9942\n",
      "Epoch 251/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0472 - acc: 0.9943 - val_loss: 0.0462 - val_acc: 0.9971\n",
      "Epoch 252/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0468 - acc: 0.9967 - val_loss: 0.0460 - val_acc: 0.9952\n",
      "Epoch 253/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0464 - acc: 0.9954 - val_loss: 0.0455 - val_acc: 0.9974\n",
      "Epoch 254/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0460 - acc: 0.9971 - val_loss: 0.0453 - val_acc: 0.9960\n",
      "Epoch 255/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0457 - acc: 0.9962 - val_loss: 0.0448 - val_acc: 0.9978\n",
      "Epoch 256/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0454 - acc: 0.9973 - val_loss: 0.0446 - val_acc: 0.9964\n",
      "Epoch 257/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0450 - acc: 0.9966 - val_loss: 0.0442 - val_acc: 0.9979\n",
      "Epoch 258/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0447 - acc: 0.9976 - val_loss: 0.0440 - val_acc: 0.9968\n",
      "Epoch 259/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0444 - acc: 0.9968 - val_loss: 0.0436 - val_acc: 0.9981\n",
      "Epoch 260/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0441 - acc: 0.9979 - val_loss: 0.0434 - val_acc: 0.9971\n",
      "Epoch 261/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0438 - acc: 0.9970 - val_loss: 0.0430 - val_acc: 0.9981\n",
      "Epoch 262/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0435 - acc: 0.9978 - val_loss: 0.0428 - val_acc: 0.9973\n",
      "Epoch 263/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0433 - acc: 0.9971 - val_loss: 0.0424 - val_acc: 0.9981\n",
      "Epoch 264/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0430 - acc: 0.9977 - val_loss: 0.0422 - val_acc: 0.9974\n",
      "Epoch 265/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0427 - acc: 0.9973 - val_loss: 0.0419 - val_acc: 0.9982\n",
      "Epoch 266/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0424 - acc: 0.9978 - val_loss: 0.0417 - val_acc: 0.9975\n",
      "Epoch 267/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0421 - acc: 0.9974 - val_loss: 0.0413 - val_acc: 0.9982\n",
      "Epoch 268/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0419 - acc: 0.9979 - val_loss: 0.0411 - val_acc: 0.9975\n",
      "Epoch 269/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0416 - acc: 0.9974 - val_loss: 0.0408 - val_acc: 0.9983\n",
      "Epoch 270/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0414 - acc: 0.9980 - val_loss: 0.0406 - val_acc: 0.9974\n",
      "Epoch 271/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0411 - acc: 0.9974 - val_loss: 0.0403 - val_acc: 0.9984\n",
      "Epoch 272/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0408 - acc: 0.9980 - val_loss: 0.0401 - val_acc: 0.9973\n",
      "Epoch 273/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0406 - acc: 0.9974 - val_loss: 0.0398 - val_acc: 0.9984\n",
      "Epoch 274/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0403 - acc: 0.9981 - val_loss: 0.0396 - val_acc: 0.9972\n",
      "Epoch 275/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0401 - acc: 0.9972 - val_loss: 0.0393 - val_acc: 0.9985\n",
      "Epoch 276/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0398 - acc: 0.9980 - val_loss: 0.0392 - val_acc: 0.9970\n",
      "Epoch 277/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0396 - acc: 0.9969 - val_loss: 0.0388 - val_acc: 0.9985\n",
      "Epoch 278/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0394 - acc: 0.9977 - val_loss: 0.0387 - val_acc: 0.9966\n",
      "Epoch 279/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0392 - acc: 0.9967 - val_loss: 0.0384 - val_acc: 0.9983\n",
      "Epoch 280/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0390 - acc: 0.9979 - val_loss: 0.0383 - val_acc: 0.9960\n",
      "Epoch 281/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0388 - acc: 0.9964 - val_loss: 0.0380 - val_acc: 0.9981\n",
      "Epoch 282/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0386 - acc: 0.9980 - val_loss: 0.0380 - val_acc: 0.9955\n",
      "Epoch 283/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0384 - acc: 0.9957 - val_loss: 0.0376 - val_acc: 0.9976\n",
      "Epoch 284/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0382 - acc: 0.9978 - val_loss: 0.0377 - val_acc: 0.9947\n",
      "Epoch 285/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0381 - acc: 0.9947 - val_loss: 0.0373 - val_acc: 0.9971\n",
      "Epoch 286/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0379 - acc: 0.9972 - val_loss: 0.0375 - val_acc: 0.9941\n",
      "Epoch 287/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0378 - acc: 0.9940 - val_loss: 0.0370 - val_acc: 0.9966\n",
      "Epoch 288/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0377 - acc: 0.9963 - val_loss: 0.0372 - val_acc: 0.9936\n",
      "Epoch 289/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0375 - acc: 0.9936 - val_loss: 0.0366 - val_acc: 0.9964\n",
      "Epoch 290/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0373 - acc: 0.9960 - val_loss: 0.0369 - val_acc: 0.9934\n",
      "Epoch 291/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0372 - acc: 0.9936 - val_loss: 0.0362 - val_acc: 0.9964\n",
      "Epoch 292/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0369 - acc: 0.9961 - val_loss: 0.0364 - val_acc: 0.9939\n",
      "Epoch 293/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0367 - acc: 0.9937 - val_loss: 0.0358 - val_acc: 0.9969\n",
      "Epoch 294/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0365 - acc: 0.9967 - val_loss: 0.0359 - val_acc: 0.9944\n",
      "Epoch 295/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0362 - acc: 0.9941 - val_loss: 0.0353 - val_acc: 0.9973\n",
      "Epoch 296/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0360 - acc: 0.9974 - val_loss: 0.0354 - val_acc: 0.9949\n",
      "Epoch 297/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0357 - acc: 0.9948 - val_loss: 0.0348 - val_acc: 0.9977\n",
      "Epoch 298/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0355 - acc: 0.9980 - val_loss: 0.0349 - val_acc: 0.9954\n",
      "Epoch 299/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0353 - acc: 0.9957 - val_loss: 0.0344 - val_acc: 0.9981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0351 - acc: 0.9984 - val_loss: 0.0345 - val_acc: 0.9959\n",
      "3000/3000 [==============================] - 0s 46us/step\n",
      "['loss', 'acc'] [0.035511267801125845, 0.995]\n",
      "[[0.66108923 0.95594316]] [[1.0644247e-09 1.0000000e+00 2.6063091e-08]]\n"
     ]
    }
   ],
   "source": [
    "model = multi_learning_demo(activation='softmax', loss='categorical_crossentropy')\n",
    "x = np.random.rand(1,2)\n",
    "print(x, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### softmax + categorical_Focal_Lossあり\n",
    "- うまくいってて、精度上がってる（乱数に依存するので精度下がるときもあり）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not sigmoid\n",
      "(100000, 3) [[0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]]\n",
      "0.0    95031\n",
      "1.0     4969\n",
      "dtype: int64\n",
      "1.0    95031\n",
      "0.0     4969\n",
      "dtype: int64\n",
      "0.0    100000\n",
      "dtype: int64\n",
      "input_dim, nb_classes: 2 3\n",
      "Train on 9700 samples, validate on 87300 samples\n",
      "Epoch 1/300\n",
      "9700/9700 [==============================] - 0s 20us/step - loss: 0.1176 - acc: 0.3379 - val_loss: 0.1127 - val_acc: 0.6127\n",
      "Epoch 2/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1128 - acc: 0.6162 - val_loss: 0.1095 - val_acc: 0.8901\n",
      "Epoch 3/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1095 - acc: 0.8864 - val_loss: 0.1067 - val_acc: 0.9504\n",
      "Epoch 4/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1067 - acc: 0.9499 - val_loss: 0.1040 - val_acc: 0.9504\n",
      "Epoch 5/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1041 - acc: 0.9499 - val_loss: 0.1013 - val_acc: 0.9504\n",
      "Epoch 6/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1014 - acc: 0.9499 - val_loss: 0.0986 - val_acc: 0.9504\n",
      "Epoch 7/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0986 - acc: 0.9499 - val_loss: 0.0958 - val_acc: 0.9504\n",
      "Epoch 8/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0958 - acc: 0.9499 - val_loss: 0.0929 - val_acc: 0.9504\n",
      "Epoch 9/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0930 - acc: 0.9499 - val_loss: 0.0902 - val_acc: 0.9504\n",
      "Epoch 10/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0903 - acc: 0.9499 - val_loss: 0.0873 - val_acc: 0.9504\n",
      "Epoch 11/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0874 - acc: 0.9499 - val_loss: 0.0844 - val_acc: 0.9504\n",
      "Epoch 12/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0845 - acc: 0.9499 - val_loss: 0.0814 - val_acc: 0.9504\n",
      "Epoch 13/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0815 - acc: 0.9499 - val_loss: 0.0785 - val_acc: 0.9504\n",
      "Epoch 14/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0786 - acc: 0.9499 - val_loss: 0.0755 - val_acc: 0.9504\n",
      "Epoch 15/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0756 - acc: 0.9499 - val_loss: 0.0725 - val_acc: 0.9504\n",
      "Epoch 16/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0727 - acc: 0.9499 - val_loss: 0.0695 - val_acc: 0.9504\n",
      "Epoch 17/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0697 - acc: 0.9499 - val_loss: 0.0666 - val_acc: 0.9504\n",
      "Epoch 18/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0667 - acc: 0.9499 - val_loss: 0.0636 - val_acc: 0.9504\n",
      "Epoch 19/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0638 - acc: 0.9499 - val_loss: 0.0607 - val_acc: 0.9504\n",
      "Epoch 20/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0609 - acc: 0.9499 - val_loss: 0.0578 - val_acc: 0.9504\n",
      "Epoch 21/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0580 - acc: 0.9499 - val_loss: 0.0550 - val_acc: 0.9504\n",
      "Epoch 22/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0551 - acc: 0.9499 - val_loss: 0.0522 - val_acc: 0.9504\n",
      "Epoch 23/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0523 - acc: 0.9499 - val_loss: 0.0494 - val_acc: 0.9504\n",
      "Epoch 24/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0496 - acc: 0.9499 - val_loss: 0.0468 - val_acc: 0.9504\n",
      "Epoch 25/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0469 - acc: 0.9499 - val_loss: 0.0442 - val_acc: 0.9504\n",
      "Epoch 26/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0444 - acc: 0.9499 - val_loss: 0.0417 - val_acc: 0.9504\n",
      "Epoch 27/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0419 - acc: 0.9499 - val_loss: 0.0394 - val_acc: 0.9504\n",
      "Epoch 28/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0396 - acc: 0.9499 - val_loss: 0.0372 - val_acc: 0.9504\n",
      "Epoch 29/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0373 - acc: 0.9499 - val_loss: 0.0351 - val_acc: 0.9504\n",
      "Epoch 30/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0353 - acc: 0.9499 - val_loss: 0.0332 - val_acc: 0.9504\n",
      "Epoch 31/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0333 - acc: 0.9499 - val_loss: 0.0313 - val_acc: 0.9504\n",
      "Epoch 32/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0315 - acc: 0.9499 - val_loss: 0.0297 - val_acc: 0.9504\n",
      "Epoch 33/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0298 - acc: 0.9499 - val_loss: 0.0281 - val_acc: 0.9504\n",
      "Epoch 34/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0283 - acc: 0.9499 - val_loss: 0.0267 - val_acc: 0.9504\n",
      "Epoch 35/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0269 - acc: 0.9499 - val_loss: 0.0254 - val_acc: 0.9504\n",
      "Epoch 36/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0256 - acc: 0.9499 - val_loss: 0.0243 - val_acc: 0.9504\n",
      "Epoch 37/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0245 - acc: 0.9499 - val_loss: 0.0233 - val_acc: 0.9504\n",
      "Epoch 38/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0234 - acc: 0.9499 - val_loss: 0.0223 - val_acc: 0.9504\n",
      "Epoch 39/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0225 - acc: 0.9499 - val_loss: 0.0215 - val_acc: 0.9504\n",
      "Epoch 40/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0217 - acc: 0.9499 - val_loss: 0.0208 - val_acc: 0.9504\n",
      "Epoch 41/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0209 - acc: 0.9499 - val_loss: 0.0201 - val_acc: 0.9504\n",
      "Epoch 42/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0203 - acc: 0.9499 - val_loss: 0.0195 - val_acc: 0.9504\n",
      "Epoch 43/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0197 - acc: 0.9499 - val_loss: 0.0190 - val_acc: 0.9504\n",
      "Epoch 44/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0192 - acc: 0.9499 - val_loss: 0.0186 - val_acc: 0.9504\n",
      "Epoch 45/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0187 - acc: 0.9499 - val_loss: 0.0182 - val_acc: 0.9504\n",
      "Epoch 46/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0183 - acc: 0.9499 - val_loss: 0.0178 - val_acc: 0.9504\n",
      "Epoch 47/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0179 - acc: 0.9499 - val_loss: 0.0175 - val_acc: 0.9504\n",
      "Epoch 48/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0176 - acc: 0.9499 - val_loss: 0.0172 - val_acc: 0.9504\n",
      "Epoch 49/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0173 - acc: 0.9499 - val_loss: 0.0169 - val_acc: 0.9504\n",
      "Epoch 50/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0171 - acc: 0.9499 - val_loss: 0.0167 - val_acc: 0.9504\n",
      "Epoch 51/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0169 - acc: 0.9499 - val_loss: 0.0165 - val_acc: 0.9504\n",
      "Epoch 52/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0166 - acc: 0.9499 - val_loss: 0.0163 - val_acc: 0.9504\n",
      "Epoch 53/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0165 - acc: 0.9499 - val_loss: 0.0162 - val_acc: 0.9504\n",
      "Epoch 54/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0163 - acc: 0.9499 - val_loss: 0.0160 - val_acc: 0.9504\n",
      "Epoch 55/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0161 - acc: 0.9499 - val_loss: 0.0159 - val_acc: 0.9504\n",
      "Epoch 56/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0160 - acc: 0.9499 - val_loss: 0.0157 - val_acc: 0.9504\n",
      "Epoch 57/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0159 - acc: 0.9499 - val_loss: 0.0156 - val_acc: 0.9504\n",
      "Epoch 58/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0158 - acc: 0.9499 - val_loss: 0.0155 - val_acc: 0.9504\n",
      "Epoch 59/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0156 - acc: 0.9499 - val_loss: 0.0154 - val_acc: 0.9504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0155 - acc: 0.9499 - val_loss: 0.0153 - val_acc: 0.9504\n",
      "Epoch 61/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0154 - acc: 0.9499 - val_loss: 0.0152 - val_acc: 0.9504\n",
      "Epoch 62/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0153 - acc: 0.9499 - val_loss: 0.0151 - val_acc: 0.9504\n",
      "Epoch 63/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0152 - acc: 0.9499 - val_loss: 0.0150 - val_acc: 0.9504\n",
      "Epoch 64/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0151 - acc: 0.9499 - val_loss: 0.0149 - val_acc: 0.9504\n",
      "Epoch 65/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0150 - acc: 0.9499 - val_loss: 0.0148 - val_acc: 0.9504\n",
      "Epoch 66/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0149 - acc: 0.9499 - val_loss: 0.0147 - val_acc: 0.9504\n",
      "Epoch 67/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0148 - acc: 0.9499 - val_loss: 0.0146 - val_acc: 0.9504\n",
      "Epoch 68/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0148 - acc: 0.9499 - val_loss: 0.0145 - val_acc: 0.9504\n",
      "Epoch 69/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0147 - acc: 0.9499 - val_loss: 0.0145 - val_acc: 0.9504\n",
      "Epoch 70/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0146 - acc: 0.9499 - val_loss: 0.0144 - val_acc: 0.9504\n",
      "Epoch 71/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0145 - acc: 0.9499 - val_loss: 0.0143 - val_acc: 0.9504\n",
      "Epoch 72/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0144 - acc: 0.9499 - val_loss: 0.0142 - val_acc: 0.9504\n",
      "Epoch 73/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0144 - acc: 0.9499 - val_loss: 0.0142 - val_acc: 0.9504\n",
      "Epoch 74/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0143 - acc: 0.9499 - val_loss: 0.0141 - val_acc: 0.9504\n",
      "Epoch 75/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0142 - acc: 0.9499 - val_loss: 0.0140 - val_acc: 0.9504\n",
      "Epoch 76/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0141 - acc: 0.9499 - val_loss: 0.0139 - val_acc: 0.9504\n",
      "Epoch 77/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0141 - acc: 0.9499 - val_loss: 0.0139 - val_acc: 0.9504\n",
      "Epoch 78/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0140 - acc: 0.9499 - val_loss: 0.0138 - val_acc: 0.9504\n",
      "Epoch 79/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0139 - acc: 0.9499 - val_loss: 0.0137 - val_acc: 0.9504\n",
      "Epoch 80/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0139 - acc: 0.9499 - val_loss: 0.0137 - val_acc: 0.9504\n",
      "Epoch 81/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0138 - acc: 0.9499 - val_loss: 0.0136 - val_acc: 0.9504\n",
      "Epoch 82/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0137 - acc: 0.9499 - val_loss: 0.0135 - val_acc: 0.9504\n",
      "Epoch 83/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0136 - acc: 0.9499 - val_loss: 0.0135 - val_acc: 0.9504\n",
      "Epoch 84/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0136 - acc: 0.9499 - val_loss: 0.0134 - val_acc: 0.9504\n",
      "Epoch 85/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0135 - acc: 0.9499 - val_loss: 0.0133 - val_acc: 0.9504\n",
      "Epoch 86/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0134 - acc: 0.9499 - val_loss: 0.0133 - val_acc: 0.9504\n",
      "Epoch 87/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0134 - acc: 0.9499 - val_loss: 0.0132 - val_acc: 0.9504\n",
      "Epoch 88/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0133 - acc: 0.9499 - val_loss: 0.0131 - val_acc: 0.9504\n",
      "Epoch 89/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0133 - acc: 0.9499 - val_loss: 0.0131 - val_acc: 0.9504\n",
      "Epoch 90/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0132 - acc: 0.9499 - val_loss: 0.0130 - val_acc: 0.9504\n",
      "Epoch 91/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0131 - acc: 0.9499 - val_loss: 0.0129 - val_acc: 0.9504\n",
      "Epoch 92/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0131 - acc: 0.9499 - val_loss: 0.0129 - val_acc: 0.9504\n",
      "Epoch 93/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0130 - acc: 0.9499 - val_loss: 0.0128 - val_acc: 0.9504\n",
      "Epoch 94/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0129 - acc: 0.9499 - val_loss: 0.0128 - val_acc: 0.9504\n",
      "Epoch 95/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0129 - acc: 0.9499 - val_loss: 0.0127 - val_acc: 0.9504\n",
      "Epoch 96/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0128 - acc: 0.9499 - val_loss: 0.0126 - val_acc: 0.9504\n",
      "Epoch 97/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0128 - acc: 0.9499 - val_loss: 0.0126 - val_acc: 0.9504\n",
      "Epoch 98/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0127 - acc: 0.9499 - val_loss: 0.0125 - val_acc: 0.9504\n",
      "Epoch 99/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0127 - acc: 0.9499 - val_loss: 0.0125 - val_acc: 0.9504\n",
      "Epoch 100/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0126 - acc: 0.9499 - val_loss: 0.0124 - val_acc: 0.9504\n",
      "Epoch 101/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0125 - acc: 0.9499 - val_loss: 0.0124 - val_acc: 0.9504\n",
      "Epoch 102/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0125 - acc: 0.9499 - val_loss: 0.0123 - val_acc: 0.9504\n",
      "Epoch 103/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0124 - acc: 0.9499 - val_loss: 0.0122 - val_acc: 0.9504\n",
      "Epoch 104/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0124 - acc: 0.9499 - val_loss: 0.0122 - val_acc: 0.9504\n",
      "Epoch 105/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0123 - acc: 0.9499 - val_loss: 0.0121 - val_acc: 0.9504\n",
      "Epoch 106/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0123 - acc: 0.9499 - val_loss: 0.0121 - val_acc: 0.9504\n",
      "Epoch 107/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0122 - acc: 0.9499 - val_loss: 0.0120 - val_acc: 0.9504\n",
      "Epoch 108/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0121 - acc: 0.9499 - val_loss: 0.0120 - val_acc: 0.9504\n",
      "Epoch 109/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0121 - acc: 0.9499 - val_loss: 0.0119 - val_acc: 0.9504\n",
      "Epoch 110/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0120 - acc: 0.9499 - val_loss: 0.0119 - val_acc: 0.9504\n",
      "Epoch 111/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0120 - acc: 0.9499 - val_loss: 0.0118 - val_acc: 0.9504\n",
      "Epoch 112/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0119 - acc: 0.9499 - val_loss: 0.0118 - val_acc: 0.9504\n",
      "Epoch 113/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0119 - acc: 0.9499 - val_loss: 0.0117 - val_acc: 0.9504\n",
      "Epoch 114/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0118 - acc: 0.9499 - val_loss: 0.0117 - val_acc: 0.9504\n",
      "Epoch 115/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0118 - acc: 0.9499 - val_loss: 0.0116 - val_acc: 0.9504\n",
      "Epoch 116/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0117 - acc: 0.9499 - val_loss: 0.0116 - val_acc: 0.9504\n",
      "Epoch 117/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0117 - acc: 0.9499 - val_loss: 0.0115 - val_acc: 0.9504\n",
      "Epoch 118/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0116 - acc: 0.9499 - val_loss: 0.0115 - val_acc: 0.9504\n",
      "Epoch 119/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0116 - acc: 0.9499 - val_loss: 0.0114 - val_acc: 0.9504\n",
      "Epoch 120/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0115 - acc: 0.9499 - val_loss: 0.0114 - val_acc: 0.9504\n",
      "Epoch 121/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0115 - acc: 0.9499 - val_loss: 0.0113 - val_acc: 0.9504\n",
      "Epoch 122/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0114 - acc: 0.9499 - val_loss: 0.0113 - val_acc: 0.9504\n",
      "Epoch 123/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0114 - acc: 0.9499 - val_loss: 0.0112 - val_acc: 0.9504\n",
      "Epoch 124/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0113 - acc: 0.9499 - val_loss: 0.0112 - val_acc: 0.9504\n",
      "Epoch 125/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0113 - acc: 0.9499 - val_loss: 0.0111 - val_acc: 0.9504\n",
      "Epoch 126/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0112 - acc: 0.9499 - val_loss: 0.0111 - val_acc: 0.9504\n",
      "Epoch 127/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0112 - acc: 0.9499 - val_loss: 0.0110 - val_acc: 0.9504\n",
      "Epoch 128/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0111 - acc: 0.9499 - val_loss: 0.0110 - val_acc: 0.9504\n",
      "Epoch 129/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0111 - acc: 0.9499 - val_loss: 0.0109 - val_acc: 0.9504\n",
      "Epoch 130/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0110 - acc: 0.9499 - val_loss: 0.0109 - val_acc: 0.9504\n",
      "Epoch 131/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0110 - acc: 0.9499 - val_loss: 0.0108 - val_acc: 0.9504\n",
      "Epoch 132/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0110 - acc: 0.9499 - val_loss: 0.0108 - val_acc: 0.9504\n",
      "Epoch 133/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0109 - acc: 0.9499 - val_loss: 0.0108 - val_acc: 0.9504\n",
      "Epoch 134/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0109 - acc: 0.9499 - val_loss: 0.0107 - val_acc: 0.9504\n",
      "Epoch 135/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0108 - acc: 0.9499 - val_loss: 0.0107 - val_acc: 0.9504\n",
      "Epoch 136/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0108 - acc: 0.9499 - val_loss: 0.0106 - val_acc: 0.9504\n",
      "Epoch 137/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0107 - acc: 0.9499 - val_loss: 0.0106 - val_acc: 0.9504\n",
      "Epoch 138/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0107 - acc: 0.9499 - val_loss: 0.0105 - val_acc: 0.9504\n",
      "Epoch 139/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0106 - acc: 0.9499 - val_loss: 0.0105 - val_acc: 0.9504\n",
      "Epoch 140/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0106 - acc: 0.9499 - val_loss: 0.0104 - val_acc: 0.9504\n",
      "Epoch 141/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0106 - acc: 0.9499 - val_loss: 0.0104 - val_acc: 0.9504\n",
      "Epoch 142/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0105 - acc: 0.9499 - val_loss: 0.0104 - val_acc: 0.9504\n",
      "Epoch 143/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0105 - acc: 0.9499 - val_loss: 0.0103 - val_acc: 0.9504\n",
      "Epoch 144/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0104 - acc: 0.9499 - val_loss: 0.0103 - val_acc: 0.9504\n",
      "Epoch 145/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0104 - acc: 0.9499 - val_loss: 0.0102 - val_acc: 0.9504\n",
      "Epoch 146/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0103 - acc: 0.9499 - val_loss: 0.0102 - val_acc: 0.9504\n",
      "Epoch 147/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0103 - acc: 0.9499 - val_loss: 0.0101 - val_acc: 0.9504\n",
      "Epoch 148/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0103 - acc: 0.9499 - val_loss: 0.0101 - val_acc: 0.9504\n",
      "Epoch 149/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0102 - acc: 0.9499 - val_loss: 0.0101 - val_acc: 0.9504\n",
      "Epoch 150/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0102 - acc: 0.9499 - val_loss: 0.0100 - val_acc: 0.9504\n",
      "Epoch 151/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0101 - acc: 0.9499 - val_loss: 0.0100 - val_acc: 0.9504\n",
      "Epoch 152/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0101 - acc: 0.9499 - val_loss: 0.0099 - val_acc: 0.9504\n",
      "Epoch 153/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0100 - acc: 0.9499 - val_loss: 0.0099 - val_acc: 0.9504\n",
      "Epoch 154/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0100 - acc: 0.9499 - val_loss: 0.0099 - val_acc: 0.9504\n",
      "Epoch 155/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0100 - acc: 0.9499 - val_loss: 0.0098 - val_acc: 0.9504\n",
      "Epoch 156/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0099 - acc: 0.9499 - val_loss: 0.0098 - val_acc: 0.9504\n",
      "Epoch 157/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0099 - acc: 0.9499 - val_loss: 0.0097 - val_acc: 0.9504\n",
      "Epoch 158/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0098 - acc: 0.9499 - val_loss: 0.0097 - val_acc: 0.9504\n",
      "Epoch 159/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0098 - acc: 0.9499 - val_loss: 0.0097 - val_acc: 0.9504\n",
      "Epoch 160/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0098 - acc: 0.9499 - val_loss: 0.0096 - val_acc: 0.9504\n",
      "Epoch 161/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0097 - acc: 0.9499 - val_loss: 0.0096 - val_acc: 0.9504\n",
      "Epoch 162/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0097 - acc: 0.9499 - val_loss: 0.0095 - val_acc: 0.9504\n",
      "Epoch 163/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0097 - acc: 0.9499 - val_loss: 0.0095 - val_acc: 0.9504\n",
      "Epoch 164/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0096 - acc: 0.9499 - val_loss: 0.0095 - val_acc: 0.9504\n",
      "Epoch 165/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0096 - acc: 0.9499 - val_loss: 0.0094 - val_acc: 0.9504\n",
      "Epoch 166/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0095 - acc: 0.9499 - val_loss: 0.0094 - val_acc: 0.9504\n",
      "Epoch 167/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0095 - acc: 0.9499 - val_loss: 0.0094 - val_acc: 0.9504\n",
      "Epoch 168/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0095 - acc: 0.9499 - val_loss: 0.0093 - val_acc: 0.9504\n",
      "Epoch 169/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0094 - acc: 0.9499 - val_loss: 0.0093 - val_acc: 0.9504\n",
      "Epoch 170/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0094 - acc: 0.9499 - val_loss: 0.0093 - val_acc: 0.9504\n",
      "Epoch 171/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0094 - acc: 0.9499 - val_loss: 0.0092 - val_acc: 0.9504\n",
      "Epoch 172/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0093 - acc: 0.9499 - val_loss: 0.0092 - val_acc: 0.9504\n",
      "Epoch 173/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0093 - acc: 0.9499 - val_loss: 0.0091 - val_acc: 0.9504\n",
      "Epoch 174/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0092 - acc: 0.9499 - val_loss: 0.0091 - val_acc: 0.9504\n",
      "Epoch 175/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0092 - acc: 0.9499 - val_loss: 0.0091 - val_acc: 0.9504\n",
      "Epoch 176/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0092 - acc: 0.9499 - val_loss: 0.0090 - val_acc: 0.9504\n",
      "Epoch 177/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0091 - acc: 0.9499 - val_loss: 0.0090 - val_acc: 0.9504\n",
      "Epoch 178/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0091 - acc: 0.9499 - val_loss: 0.0090 - val_acc: 0.9504\n",
      "Epoch 179/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0091 - acc: 0.9499 - val_loss: 0.0089 - val_acc: 0.9504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0090 - acc: 0.9499 - val_loss: 0.0089 - val_acc: 0.9504\n",
      "Epoch 181/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0090 - acc: 0.9499 - val_loss: 0.0089 - val_acc: 0.9504\n",
      "Epoch 182/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0090 - acc: 0.9499 - val_loss: 0.0088 - val_acc: 0.9504\n",
      "Epoch 183/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.9499 - val_loss: 0.0088 - val_acc: 0.9504\n",
      "Epoch 184/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.9499 - val_loss: 0.0088 - val_acc: 0.9504\n",
      "Epoch 185/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.9499 - val_loss: 0.0087 - val_acc: 0.9504\n",
      "Epoch 186/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0088 - acc: 0.9499 - val_loss: 0.0087 - val_acc: 0.9504\n",
      "Epoch 187/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0088 - acc: 0.9499 - val_loss: 0.0087 - val_acc: 0.9504\n",
      "Epoch 188/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0088 - acc: 0.9499 - val_loss: 0.0086 - val_acc: 0.9504\n",
      "Epoch 189/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0087 - acc: 0.9499 - val_loss: 0.0086 - val_acc: 0.9504\n",
      "Epoch 190/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0087 - acc: 0.9499 - val_loss: 0.0086 - val_acc: 0.9504\n",
      "Epoch 191/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0087 - acc: 0.9499 - val_loss: 0.0085 - val_acc: 0.9504\n",
      "Epoch 192/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0086 - acc: 0.9499 - val_loss: 0.0085 - val_acc: 0.9504\n",
      "Epoch 193/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0086 - acc: 0.9499 - val_loss: 0.0085 - val_acc: 0.9504\n",
      "Epoch 194/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0086 - acc: 0.9499 - val_loss: 0.0084 - val_acc: 0.9504\n",
      "Epoch 195/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0085 - acc: 0.9499 - val_loss: 0.0084 - val_acc: 0.9504\n",
      "Epoch 196/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0085 - acc: 0.9499 - val_loss: 0.0084 - val_acc: 0.9504\n",
      "Epoch 197/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0085 - acc: 0.9499 - val_loss: 0.0083 - val_acc: 0.9504\n",
      "Epoch 198/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0084 - acc: 0.9499 - val_loss: 0.0083 - val_acc: 0.9504\n",
      "Epoch 199/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0084 - acc: 0.9499 - val_loss: 0.0083 - val_acc: 0.9504\n",
      "Epoch 200/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0084 - acc: 0.9499 - val_loss: 0.0082 - val_acc: 0.9504\n",
      "Epoch 201/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0083 - acc: 0.9499 - val_loss: 0.0082 - val_acc: 0.9504\n",
      "Epoch 202/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0083 - acc: 0.9499 - val_loss: 0.0082 - val_acc: 0.9504\n",
      "Epoch 203/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0083 - acc: 0.9499 - val_loss: 0.0081 - val_acc: 0.9504\n",
      "Epoch 204/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0082 - acc: 0.9499 - val_loss: 0.0081 - val_acc: 0.9504\n",
      "Epoch 205/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0082 - acc: 0.9499 - val_loss: 0.0081 - val_acc: 0.9504\n",
      "Epoch 206/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0082 - acc: 0.9499 - val_loss: 0.0081 - val_acc: 0.9504\n",
      "Epoch 207/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.9499 - val_loss: 0.0080 - val_acc: 0.9504\n",
      "Epoch 208/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.9499 - val_loss: 0.0080 - val_acc: 0.9504\n",
      "Epoch 209/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.9499 - val_loss: 0.0080 - val_acc: 0.9504\n",
      "Epoch 210/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.9499 - val_loss: 0.0079 - val_acc: 0.9504\n",
      "Epoch 211/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0080 - acc: 0.9499 - val_loss: 0.0079 - val_acc: 0.9504\n",
      "Epoch 212/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0080 - acc: 0.9499 - val_loss: 0.0079 - val_acc: 0.9504\n",
      "Epoch 213/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0080 - acc: 0.9499 - val_loss: 0.0078 - val_acc: 0.9504\n",
      "Epoch 214/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.9499 - val_loss: 0.0078 - val_acc: 0.9504\n",
      "Epoch 215/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.9499 - val_loss: 0.0078 - val_acc: 0.9504\n",
      "Epoch 216/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.9499 - val_loss: 0.0078 - val_acc: 0.9504\n",
      "Epoch 217/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.9499 - val_loss: 0.0077 - val_acc: 0.9504\n",
      "Epoch 218/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0078 - acc: 0.9499 - val_loss: 0.0077 - val_acc: 0.9504\n",
      "Epoch 219/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0078 - acc: 0.9499 - val_loss: 0.0077 - val_acc: 0.9504\n",
      "Epoch 220/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0078 - acc: 0.9499 - val_loss: 0.0076 - val_acc: 0.9504\n",
      "Epoch 221/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.9499 - val_loss: 0.0076 - val_acc: 0.9504\n",
      "Epoch 222/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.9499 - val_loss: 0.0076 - val_acc: 0.9504\n",
      "Epoch 223/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.9499 - val_loss: 0.0076 - val_acc: 0.9504\n",
      "Epoch 224/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.9499 - val_loss: 0.0075 - val_acc: 0.9504\n",
      "Epoch 225/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0076 - acc: 0.9499 - val_loss: 0.0075 - val_acc: 0.9504\n",
      "Epoch 226/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0076 - acc: 0.9499 - val_loss: 0.0075 - val_acc: 0.9504\n",
      "Epoch 227/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0076 - acc: 0.9499 - val_loss: 0.0074 - val_acc: 0.9504\n",
      "Epoch 228/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.9499 - val_loss: 0.0074 - val_acc: 0.9504\n",
      "Epoch 229/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.9499 - val_loss: 0.0074 - val_acc: 0.9504\n",
      "Epoch 230/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.9499 - val_loss: 0.0074 - val_acc: 0.9504\n",
      "Epoch 231/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.9499 - val_loss: 0.0073 - val_acc: 0.9504\n",
      "Epoch 232/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.9499 - val_loss: 0.0073 - val_acc: 0.9504\n",
      "Epoch 233/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.9499 - val_loss: 0.0073 - val_acc: 0.9504\n",
      "Epoch 234/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.9499 - val_loss: 0.0073 - val_acc: 0.9504\n",
      "Epoch 235/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.9499 - val_loss: 0.0072 - val_acc: 0.9504\n",
      "Epoch 236/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.9499 - val_loss: 0.0072 - val_acc: 0.9504\n",
      "Epoch 237/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.9499 - val_loss: 0.0072 - val_acc: 0.9504\n",
      "Epoch 238/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.9499 - val_loss: 0.0072 - val_acc: 0.9504\n",
      "Epoch 239/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.9499 - val_loss: 0.0071 - val_acc: 0.9504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9499 - val_loss: 0.0071 - val_acc: 0.9504\n",
      "Epoch 241/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9499 - val_loss: 0.0071 - val_acc: 0.9504\n",
      "Epoch 242/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9499 - val_loss: 0.0071 - val_acc: 0.9504\n",
      "Epoch 243/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9499 - val_loss: 0.0070 - val_acc: 0.9504\n",
      "Epoch 244/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9499 - val_loss: 0.0070 - val_acc: 0.9504\n",
      "Epoch 245/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9499 - val_loss: 0.0070 - val_acc: 0.9504\n",
      "Epoch 246/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9499 - val_loss: 0.0070 - val_acc: 0.9504\n",
      "Epoch 247/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9499 - val_loss: 0.0069 - val_acc: 0.9504\n",
      "Epoch 248/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9499 - val_loss: 0.0069 - val_acc: 0.9504\n",
      "Epoch 249/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9499 - val_loss: 0.0069 - val_acc: 0.9504\n",
      "Epoch 250/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9499 - val_loss: 0.0069 - val_acc: 0.9504\n",
      "Epoch 251/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9499 - val_loss: 0.0068 - val_acc: 0.9504\n",
      "Epoch 252/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9499 - val_loss: 0.0068 - val_acc: 0.9504\n",
      "Epoch 253/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9499 - val_loss: 0.0068 - val_acc: 0.9504\n",
      "Epoch 254/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9499 - val_loss: 0.0068 - val_acc: 0.9504\n",
      "Epoch 255/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9499 - val_loss: 0.0068 - val_acc: 0.9504\n",
      "Epoch 256/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.9499 - val_loss: 0.0067 - val_acc: 0.9504\n",
      "Epoch 257/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.9499 - val_loss: 0.0067 - val_acc: 0.9504\n",
      "Epoch 258/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.9499 - val_loss: 0.0067 - val_acc: 0.9504\n",
      "Epoch 259/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.9499 - val_loss: 0.0067 - val_acc: 0.9504\n",
      "Epoch 260/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.9499 - val_loss: 0.0066 - val_acc: 0.9504\n",
      "Epoch 261/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.9499 - val_loss: 0.0066 - val_acc: 0.9504\n",
      "Epoch 262/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.9499 - val_loss: 0.0066 - val_acc: 0.9504\n",
      "Epoch 263/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.9499 - val_loss: 0.0066 - val_acc: 0.9504\n",
      "Epoch 264/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.9499 - val_loss: 0.0065 - val_acc: 0.9504\n",
      "Epoch 265/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9499 - val_loss: 0.0065 - val_acc: 0.9504\n",
      "Epoch 266/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9499 - val_loss: 0.0065 - val_acc: 0.9504\n",
      "Epoch 267/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9499 - val_loss: 0.0065 - val_acc: 0.9504\n",
      "Epoch 268/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9499 - val_loss: 0.0065 - val_acc: 0.9504\n",
      "Epoch 269/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0065 - acc: 0.9499 - val_loss: 0.0064 - val_acc: 0.9504\n",
      "Epoch 270/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0065 - acc: 0.9499 - val_loss: 0.0064 - val_acc: 0.9504\n",
      "Epoch 271/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0065 - acc: 0.9499 - val_loss: 0.0064 - val_acc: 0.9504\n",
      "Epoch 272/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0065 - acc: 0.9499 - val_loss: 0.0064 - val_acc: 0.9504\n",
      "Epoch 273/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0064 - acc: 0.9499 - val_loss: 0.0063 - val_acc: 0.9504\n",
      "Epoch 274/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0064 - acc: 0.9499 - val_loss: 0.0063 - val_acc: 0.9504\n",
      "Epoch 275/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0064 - acc: 0.9499 - val_loss: 0.0063 - val_acc: 0.9504\n",
      "Epoch 276/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0064 - acc: 0.9499 - val_loss: 0.0063 - val_acc: 0.9504\n",
      "Epoch 277/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0064 - acc: 0.9499 - val_loss: 0.0063 - val_acc: 0.9504\n",
      "Epoch 278/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9499 - val_loss: 0.0062 - val_acc: 0.9504\n",
      "Epoch 279/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9499 - val_loss: 0.0062 - val_acc: 0.9504\n",
      "Epoch 280/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9499 - val_loss: 0.0062 - val_acc: 0.9504\n",
      "Epoch 281/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9499 - val_loss: 0.0062 - val_acc: 0.9504\n",
      "Epoch 282/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0062 - acc: 0.9499 - val_loss: 0.0061 - val_acc: 0.9504\n",
      "Epoch 283/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0062 - acc: 0.9499 - val_loss: 0.0061 - val_acc: 0.9504\n",
      "Epoch 284/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0062 - acc: 0.9499 - val_loss: 0.0061 - val_acc: 0.9504\n",
      "Epoch 285/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0062 - acc: 0.9499 - val_loss: 0.0061 - val_acc: 0.9504\n",
      "Epoch 286/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0062 - acc: 0.9499 - val_loss: 0.0061 - val_acc: 0.9504\n",
      "Epoch 287/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9499 - val_loss: 0.0060 - val_acc: 0.9504\n",
      "Epoch 288/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9499 - val_loss: 0.0060 - val_acc: 0.9504\n",
      "Epoch 289/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9499 - val_loss: 0.0060 - val_acc: 0.9504\n",
      "Epoch 290/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9499 - val_loss: 0.0060 - val_acc: 0.9504\n",
      "Epoch 291/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9499 - val_loss: 0.0060 - val_acc: 0.9504\n",
      "Epoch 292/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0060 - acc: 0.9499 - val_loss: 0.0059 - val_acc: 0.9504\n",
      "Epoch 293/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0060 - acc: 0.9499 - val_loss: 0.0059 - val_acc: 0.9504\n",
      "Epoch 294/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0060 - acc: 0.9499 - val_loss: 0.0059 - val_acc: 0.9504\n",
      "Epoch 295/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0060 - acc: 0.9499 - val_loss: 0.0059 - val_acc: 0.9504\n",
      "Epoch 296/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0060 - acc: 0.9499 - val_loss: 0.0058 - val_acc: 0.9504\n",
      "Epoch 297/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9499 - val_loss: 0.0058 - val_acc: 0.9504\n",
      "Epoch 298/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9499 - val_loss: 0.0058 - val_acc: 0.9504\n",
      "Epoch 299/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9499 - val_loss: 0.0058 - val_acc: 0.9504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9499 - val_loss: 0.0058 - val_acc: 0.9504\n",
      "3000/3000 [==============================] - 0s 30us/step\n",
      "['loss', 'acc'] [0.005920659606034557, 0.9479999998410543]\n",
      "[[0.66108923 0.95594316]] [[9.2121195e-03 9.9056154e-01 2.2642130e-04]]\n"
     ]
    }
   ],
   "source": [
    "model = multi_learning_demo(activation='softmax', loss=[categorical_focal_loss(alpha=.25, gamma=2)])\n",
    "x = np.random.rand(1,2)\n",
    "print(x, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### softmax + 欠損ラベル作成して、maskありでcategorical_Focal_Loss使用\n",
    "- うまくいってる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not sigmoid\n",
      "(100000, 3) [[-1.  1.  0.]\n",
      " [-1.  1.  0.]\n",
      " [-1.  1.  0.]\n",
      " ...\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]]\n",
      " 0.0    93132\n",
      " 1.0     4868\n",
      "-1.0     2000\n",
      "dtype: int64\n",
      " 1.0    94365\n",
      " 0.0     4934\n",
      "-1.0      701\n",
      "dtype: int64\n",
      " 0.0    98900\n",
      "-1.0     1100\n",
      "dtype: int64\n",
      "input_dim, nb_classes: 2 3\n",
      "Train on 9700 samples, validate on 87300 samples\n",
      "Epoch 1/300\n",
      "9700/9700 [==============================] - 0s 17us/step - loss: 0.1144 - acc: 0.3367 - val_loss: 0.1098 - val_acc: 0.6099\n",
      "Epoch 2/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1097 - acc: 0.6125 - val_loss: 0.1066 - val_acc: 0.8847\n",
      "Epoch 3/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1065 - acc: 0.8801 - val_loss: 0.1039 - val_acc: 0.9446\n",
      "Epoch 4/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1038 - acc: 0.9432 - val_loss: 0.1012 - val_acc: 0.9446\n",
      "Epoch 5/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1012 - acc: 0.9432 - val_loss: 0.0986 - val_acc: 0.9446\n",
      "Epoch 6/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0986 - acc: 0.9432 - val_loss: 0.0959 - val_acc: 0.9446\n",
      "Epoch 7/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0959 - acc: 0.9432 - val_loss: 0.0932 - val_acc: 0.9446\n",
      "Epoch 8/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0932 - acc: 0.9432 - val_loss: 0.0904 - val_acc: 0.9446\n",
      "Epoch 9/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0904 - acc: 0.9432 - val_loss: 0.0876 - val_acc: 0.9446\n",
      "Epoch 10/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0876 - acc: 0.9432 - val_loss: 0.0848 - val_acc: 0.9446\n",
      "Epoch 11/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0848 - acc: 0.9432 - val_loss: 0.0819 - val_acc: 0.9446\n",
      "Epoch 12/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0819 - acc: 0.9432 - val_loss: 0.0791 - val_acc: 0.9446\n",
      "Epoch 13/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0791 - acc: 0.9432 - val_loss: 0.0762 - val_acc: 0.9446\n",
      "Epoch 14/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0762 - acc: 0.9432 - val_loss: 0.0733 - val_acc: 0.9446\n",
      "Epoch 15/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0733 - acc: 0.9432 - val_loss: 0.0704 - val_acc: 0.9446\n",
      "Epoch 16/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0704 - acc: 0.9432 - val_loss: 0.0675 - val_acc: 0.9446\n",
      "Epoch 17/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0675 - acc: 0.9432 - val_loss: 0.0646 - val_acc: 0.9446\n",
      "Epoch 18/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0647 - acc: 0.9432 - val_loss: 0.0617 - val_acc: 0.9446\n",
      "Epoch 19/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0618 - acc: 0.9432 - val_loss: 0.0589 - val_acc: 0.9446\n",
      "Epoch 20/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0590 - acc: 0.9432 - val_loss: 0.0561 - val_acc: 0.9446\n",
      "Epoch 21/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0562 - acc: 0.9432 - val_loss: 0.0533 - val_acc: 0.9446\n",
      "Epoch 22/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0534 - acc: 0.9432 - val_loss: 0.0506 - val_acc: 0.9446\n",
      "Epoch 23/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0507 - acc: 0.9432 - val_loss: 0.0479 - val_acc: 0.9446\n",
      "Epoch 24/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0481 - acc: 0.9432 - val_loss: 0.0454 - val_acc: 0.9446\n",
      "Epoch 25/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0455 - acc: 0.9432 - val_loss: 0.0429 - val_acc: 0.9446\n",
      "Epoch 26/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0430 - acc: 0.9432 - val_loss: 0.0405 - val_acc: 0.9446\n",
      "Epoch 27/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0406 - acc: 0.9432 - val_loss: 0.0382 - val_acc: 0.9446\n",
      "Epoch 28/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0384 - acc: 0.9432 - val_loss: 0.0361 - val_acc: 0.9446\n",
      "Epoch 29/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0362 - acc: 0.9432 - val_loss: 0.0341 - val_acc: 0.9446\n",
      "Epoch 30/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0343 - acc: 0.9432 - val_loss: 0.0322 - val_acc: 0.9446\n",
      "Epoch 31/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0324 - acc: 0.9432 - val_loss: 0.0305 - val_acc: 0.9446\n",
      "Epoch 32/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0306 - acc: 0.9432 - val_loss: 0.0288 - val_acc: 0.9446\n",
      "Epoch 33/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0290 - acc: 0.9432 - val_loss: 0.0273 - val_acc: 0.9446\n",
      "Epoch 34/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0275 - acc: 0.9432 - val_loss: 0.0260 - val_acc: 0.9446\n",
      "Epoch 35/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0262 - acc: 0.9432 - val_loss: 0.0247 - val_acc: 0.9446\n",
      "Epoch 36/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0249 - acc: 0.9432 - val_loss: 0.0236 - val_acc: 0.9446\n",
      "Epoch 37/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0238 - acc: 0.9432 - val_loss: 0.0226 - val_acc: 0.9446\n",
      "Epoch 38/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0228 - acc: 0.9432 - val_loss: 0.0217 - val_acc: 0.9446\n",
      "Epoch 39/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0219 - acc: 0.9432 - val_loss: 0.0209 - val_acc: 0.9446\n",
      "Epoch 40/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0211 - acc: 0.9432 - val_loss: 0.0202 - val_acc: 0.9446\n",
      "Epoch 41/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0204 - acc: 0.9432 - val_loss: 0.0196 - val_acc: 0.9446\n",
      "Epoch 42/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0198 - acc: 0.9432 - val_loss: 0.0190 - val_acc: 0.9446\n",
      "Epoch 43/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0192 - acc: 0.9432 - val_loss: 0.0185 - val_acc: 0.9446\n",
      "Epoch 44/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0187 - acc: 0.9432 - val_loss: 0.0181 - val_acc: 0.9446\n",
      "Epoch 45/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0183 - acc: 0.9432 - val_loss: 0.0177 - val_acc: 0.9446\n",
      "Epoch 46/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0179 - acc: 0.9432 - val_loss: 0.0173 - val_acc: 0.9446\n",
      "Epoch 47/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0175 - acc: 0.9432 - val_loss: 0.0170 - val_acc: 0.9446\n",
      "Epoch 48/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0172 - acc: 0.9432 - val_loss: 0.0167 - val_acc: 0.9446\n",
      "Epoch 49/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0169 - acc: 0.9432 - val_loss: 0.0165 - val_acc: 0.9446\n",
      "Epoch 50/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0167 - acc: 0.9432 - val_loss: 0.0163 - val_acc: 0.9446\n",
      "Epoch 51/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0165 - acc: 0.9432 - val_loss: 0.0161 - val_acc: 0.9446\n",
      "Epoch 52/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0163 - acc: 0.9432 - val_loss: 0.0159 - val_acc: 0.9446\n",
      "Epoch 53/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0161 - acc: 0.9432 - val_loss: 0.0157 - val_acc: 0.9446\n",
      "Epoch 54/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0159 - acc: 0.9432 - val_loss: 0.0156 - val_acc: 0.9446\n",
      "Epoch 55/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0158 - acc: 0.9432 - val_loss: 0.0154 - val_acc: 0.9446\n",
      "Epoch 56/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0157 - acc: 0.9432 - val_loss: 0.0153 - val_acc: 0.9446\n",
      "Epoch 57/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0155 - acc: 0.9432 - val_loss: 0.0152 - val_acc: 0.9446\n",
      "Epoch 58/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0154 - acc: 0.9432 - val_loss: 0.0151 - val_acc: 0.9446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0153 - acc: 0.9432 - val_loss: 0.0150 - val_acc: 0.9446\n",
      "Epoch 60/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0152 - acc: 0.9432 - val_loss: 0.0149 - val_acc: 0.9446\n",
      "Epoch 61/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0151 - acc: 0.9432 - val_loss: 0.0148 - val_acc: 0.9446\n",
      "Epoch 62/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0150 - acc: 0.9432 - val_loss: 0.0147 - val_acc: 0.9446\n",
      "Epoch 63/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0149 - acc: 0.9432 - val_loss: 0.0146 - val_acc: 0.9446\n",
      "Epoch 64/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0148 - acc: 0.9432 - val_loss: 0.0145 - val_acc: 0.9446\n",
      "Epoch 65/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0147 - acc: 0.9432 - val_loss: 0.0144 - val_acc: 0.9446\n",
      "Epoch 66/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0146 - acc: 0.9432 - val_loss: 0.0143 - val_acc: 0.9446\n",
      "Epoch 67/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0145 - acc: 0.9432 - val_loss: 0.0142 - val_acc: 0.9446\n",
      "Epoch 68/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0144 - acc: 0.9432 - val_loss: 0.0141 - val_acc: 0.9446\n",
      "Epoch 69/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0143 - acc: 0.9432 - val_loss: 0.0141 - val_acc: 0.9446\n",
      "Epoch 70/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0143 - acc: 0.9432 - val_loss: 0.0140 - val_acc: 0.9446\n",
      "Epoch 71/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0142 - acc: 0.9432 - val_loss: 0.0139 - val_acc: 0.9446\n",
      "Epoch 72/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0141 - acc: 0.9432 - val_loss: 0.0138 - val_acc: 0.9446\n",
      "Epoch 73/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0140 - acc: 0.9432 - val_loss: 0.0138 - val_acc: 0.9446\n",
      "Epoch 74/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0140 - acc: 0.9432 - val_loss: 0.0137 - val_acc: 0.9446\n",
      "Epoch 75/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0139 - acc: 0.9432 - val_loss: 0.0136 - val_acc: 0.9446\n",
      "Epoch 76/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0138 - acc: 0.9432 - val_loss: 0.0135 - val_acc: 0.9446\n",
      "Epoch 77/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0137 - acc: 0.9432 - val_loss: 0.0135 - val_acc: 0.9446\n",
      "Epoch 78/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0137 - acc: 0.9432 - val_loss: 0.0134 - val_acc: 0.9446\n",
      "Epoch 79/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0136 - acc: 0.9432 - val_loss: 0.0133 - val_acc: 0.9446\n",
      "Epoch 80/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0135 - acc: 0.9432 - val_loss: 0.0133 - val_acc: 0.9446\n",
      "Epoch 81/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0135 - acc: 0.9432 - val_loss: 0.0132 - val_acc: 0.9446\n",
      "Epoch 82/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0134 - acc: 0.9432 - val_loss: 0.0131 - val_acc: 0.9446\n",
      "Epoch 83/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0133 - acc: 0.9432 - val_loss: 0.0131 - val_acc: 0.9446\n",
      "Epoch 84/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0133 - acc: 0.9432 - val_loss: 0.0130 - val_acc: 0.9446\n",
      "Epoch 85/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0132 - acc: 0.9432 - val_loss: 0.0129 - val_acc: 0.9446\n",
      "Epoch 86/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0131 - acc: 0.9432 - val_loss: 0.0129 - val_acc: 0.9446\n",
      "Epoch 87/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0131 - acc: 0.9432 - val_loss: 0.0128 - val_acc: 0.9446\n",
      "Epoch 88/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0130 - acc: 0.9432 - val_loss: 0.0128 - val_acc: 0.9446\n",
      "Epoch 89/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0130 - acc: 0.9432 - val_loss: 0.0127 - val_acc: 0.9446\n",
      "Epoch 90/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0129 - acc: 0.9432 - val_loss: 0.0126 - val_acc: 0.9446\n",
      "Epoch 91/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0128 - acc: 0.9432 - val_loss: 0.0126 - val_acc: 0.9446\n",
      "Epoch 92/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0128 - acc: 0.9432 - val_loss: 0.0125 - val_acc: 0.9446\n",
      "Epoch 93/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0127 - acc: 0.9432 - val_loss: 0.0125 - val_acc: 0.9446\n",
      "Epoch 94/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0126 - acc: 0.9432 - val_loss: 0.0124 - val_acc: 0.9446\n",
      "Epoch 95/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0126 - acc: 0.9432 - val_loss: 0.0123 - val_acc: 0.9446\n",
      "Epoch 96/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0125 - acc: 0.9432 - val_loss: 0.0123 - val_acc: 0.9446\n",
      "Epoch 97/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0125 - acc: 0.9432 - val_loss: 0.0122 - val_acc: 0.9446\n",
      "Epoch 98/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0124 - acc: 0.9432 - val_loss: 0.0122 - val_acc: 0.9446\n",
      "Epoch 99/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0124 - acc: 0.9432 - val_loss: 0.0121 - val_acc: 0.9446\n",
      "Epoch 100/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0123 - acc: 0.9432 - val_loss: 0.0121 - val_acc: 0.9446\n",
      "Epoch 101/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0122 - acc: 0.9432 - val_loss: 0.0120 - val_acc: 0.9446\n",
      "Epoch 102/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0122 - acc: 0.9432 - val_loss: 0.0119 - val_acc: 0.9446\n",
      "Epoch 103/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0121 - acc: 0.9432 - val_loss: 0.0119 - val_acc: 0.9446\n",
      "Epoch 104/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0121 - acc: 0.9432 - val_loss: 0.0118 - val_acc: 0.9446\n",
      "Epoch 105/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0120 - acc: 0.9432 - val_loss: 0.0118 - val_acc: 0.9446\n",
      "Epoch 106/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0120 - acc: 0.9432 - val_loss: 0.0117 - val_acc: 0.9446\n",
      "Epoch 107/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0119 - acc: 0.9432 - val_loss: 0.0117 - val_acc: 0.9446\n",
      "Epoch 108/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0119 - acc: 0.9432 - val_loss: 0.0116 - val_acc: 0.9446\n",
      "Epoch 109/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0118 - acc: 0.9432 - val_loss: 0.0116 - val_acc: 0.9446\n",
      "Epoch 110/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0118 - acc: 0.9432 - val_loss: 0.0115 - val_acc: 0.9446\n",
      "Epoch 111/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0117 - acc: 0.9432 - val_loss: 0.0115 - val_acc: 0.9446\n",
      "Epoch 112/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0117 - acc: 0.9432 - val_loss: 0.0114 - val_acc: 0.9446\n",
      "Epoch 113/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0116 - acc: 0.9432 - val_loss: 0.0114 - val_acc: 0.9446\n",
      "Epoch 114/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0116 - acc: 0.9432 - val_loss: 0.0113 - val_acc: 0.9446\n",
      "Epoch 115/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0115 - acc: 0.9432 - val_loss: 0.0113 - val_acc: 0.9446\n",
      "Epoch 116/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0115 - acc: 0.9432 - val_loss: 0.0112 - val_acc: 0.9446\n",
      "Epoch 117/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0114 - acc: 0.9432 - val_loss: 0.0112 - val_acc: 0.9446\n",
      "Epoch 118/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0114 - acc: 0.9432 - val_loss: 0.0111 - val_acc: 0.9446\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0113 - acc: 0.9432 - val_loss: 0.0111 - val_acc: 0.9446\n",
      "Epoch 120/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0113 - acc: 0.9432 - val_loss: 0.0110 - val_acc: 0.9446\n",
      "Epoch 121/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0112 - acc: 0.9432 - val_loss: 0.0110 - val_acc: 0.9446\n",
      "Epoch 122/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0112 - acc: 0.9432 - val_loss: 0.0109 - val_acc: 0.9446\n",
      "Epoch 123/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0111 - acc: 0.9432 - val_loss: 0.0109 - val_acc: 0.9446\n",
      "Epoch 124/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0111 - acc: 0.9432 - val_loss: 0.0108 - val_acc: 0.9446\n",
      "Epoch 125/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0110 - acc: 0.9432 - val_loss: 0.0108 - val_acc: 0.9446\n",
      "Epoch 126/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0110 - acc: 0.9432 - val_loss: 0.0107 - val_acc: 0.9446\n",
      "Epoch 127/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0109 - acc: 0.9432 - val_loss: 0.0107 - val_acc: 0.9446\n",
      "Epoch 128/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0109 - acc: 0.9432 - val_loss: 0.0107 - val_acc: 0.9446\n",
      "Epoch 129/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0108 - acc: 0.9432 - val_loss: 0.0106 - val_acc: 0.9446\n",
      "Epoch 130/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0108 - acc: 0.9432 - val_loss: 0.0106 - val_acc: 0.9446\n",
      "Epoch 131/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0107 - acc: 0.9432 - val_loss: 0.0105 - val_acc: 0.9446\n",
      "Epoch 132/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0107 - acc: 0.9432 - val_loss: 0.0105 - val_acc: 0.9446\n",
      "Epoch 133/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0106 - acc: 0.9432 - val_loss: 0.0104 - val_acc: 0.9446\n",
      "Epoch 134/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0106 - acc: 0.9432 - val_loss: 0.0104 - val_acc: 0.9446\n",
      "Epoch 135/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0106 - acc: 0.9432 - val_loss: 0.0103 - val_acc: 0.9446\n",
      "Epoch 136/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0105 - acc: 0.9432 - val_loss: 0.0103 - val_acc: 0.9446\n",
      "Epoch 137/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0105 - acc: 0.9432 - val_loss: 0.0103 - val_acc: 0.9446\n",
      "Epoch 138/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0104 - acc: 0.9432 - val_loss: 0.0102 - val_acc: 0.9446\n",
      "Epoch 139/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0104 - acc: 0.9432 - val_loss: 0.0102 - val_acc: 0.9446\n",
      "Epoch 140/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0103 - acc: 0.9432 - val_loss: 0.0101 - val_acc: 0.9446\n",
      "Epoch 141/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0103 - acc: 0.9432 - val_loss: 0.0101 - val_acc: 0.9446\n",
      "Epoch 142/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0103 - acc: 0.9432 - val_loss: 0.0101 - val_acc: 0.9446\n",
      "Epoch 143/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0102 - acc: 0.9432 - val_loss: 0.0100 - val_acc: 0.9446\n",
      "Epoch 144/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0102 - acc: 0.9432 - val_loss: 0.0100 - val_acc: 0.9446\n",
      "Epoch 145/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0101 - acc: 0.9432 - val_loss: 0.0099 - val_acc: 0.9446\n",
      "Epoch 146/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0101 - acc: 0.9432 - val_loss: 0.0099 - val_acc: 0.9446\n",
      "Epoch 147/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0101 - acc: 0.9432 - val_loss: 0.0098 - val_acc: 0.9446\n",
      "Epoch 148/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0100 - acc: 0.9432 - val_loss: 0.0098 - val_acc: 0.9446\n",
      "Epoch 149/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0100 - acc: 0.9432 - val_loss: 0.0098 - val_acc: 0.9446\n",
      "Epoch 150/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0099 - acc: 0.9432 - val_loss: 0.0097 - val_acc: 0.9446\n",
      "Epoch 151/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0099 - acc: 0.9432 - val_loss: 0.0097 - val_acc: 0.9446\n",
      "Epoch 152/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0098 - acc: 0.9432 - val_loss: 0.0096 - val_acc: 0.9446\n",
      "Epoch 153/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0098 - acc: 0.9432 - val_loss: 0.0096 - val_acc: 0.9446\n",
      "Epoch 154/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0098 - acc: 0.9432 - val_loss: 0.0096 - val_acc: 0.9446\n",
      "Epoch 155/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0097 - acc: 0.9432 - val_loss: 0.0095 - val_acc: 0.9446\n",
      "Epoch 156/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0097 - acc: 0.9432 - val_loss: 0.0095 - val_acc: 0.9446\n",
      "Epoch 157/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0096 - acc: 0.9432 - val_loss: 0.0095 - val_acc: 0.9446\n",
      "Epoch 158/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0096 - acc: 0.9432 - val_loss: 0.0094 - val_acc: 0.9446\n",
      "Epoch 159/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0096 - acc: 0.9432 - val_loss: 0.0094 - val_acc: 0.9446\n",
      "Epoch 160/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0095 - acc: 0.9432 - val_loss: 0.0093 - val_acc: 0.9446\n",
      "Epoch 161/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0095 - acc: 0.9432 - val_loss: 0.0093 - val_acc: 0.9446\n",
      "Epoch 162/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0095 - acc: 0.9432 - val_loss: 0.0093 - val_acc: 0.9446\n",
      "Epoch 163/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0094 - acc: 0.9432 - val_loss: 0.0092 - val_acc: 0.9446\n",
      "Epoch 164/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0094 - acc: 0.9432 - val_loss: 0.0092 - val_acc: 0.9446\n",
      "Epoch 165/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0093 - acc: 0.9432 - val_loss: 0.0092 - val_acc: 0.9446\n",
      "Epoch 166/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0093 - acc: 0.9432 - val_loss: 0.0091 - val_acc: 0.9446\n",
      "Epoch 167/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0093 - acc: 0.9432 - val_loss: 0.0091 - val_acc: 0.9446\n",
      "Epoch 168/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0092 - acc: 0.9432 - val_loss: 0.0090 - val_acc: 0.9446\n",
      "Epoch 169/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0092 - acc: 0.9432 - val_loss: 0.0090 - val_acc: 0.9446\n",
      "Epoch 170/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0092 - acc: 0.9432 - val_loss: 0.0090 - val_acc: 0.9446\n",
      "Epoch 171/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0091 - acc: 0.9432 - val_loss: 0.0089 - val_acc: 0.9446\n",
      "Epoch 172/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0091 - acc: 0.9432 - val_loss: 0.0089 - val_acc: 0.9446\n",
      "Epoch 173/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0091 - acc: 0.9432 - val_loss: 0.0089 - val_acc: 0.9446\n",
      "Epoch 174/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0090 - acc: 0.9432 - val_loss: 0.0088 - val_acc: 0.9446\n",
      "Epoch 175/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0090 - acc: 0.9432 - val_loss: 0.0088 - val_acc: 0.9446\n",
      "Epoch 176/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0090 - acc: 0.9432 - val_loss: 0.0088 - val_acc: 0.9446\n",
      "Epoch 177/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.9432 - val_loss: 0.0087 - val_acc: 0.9446\n",
      "Epoch 178/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.9432 - val_loss: 0.0087 - val_acc: 0.9446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0088 - acc: 0.9432 - val_loss: 0.0087 - val_acc: 0.9446\n",
      "Epoch 180/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0088 - acc: 0.9432 - val_loss: 0.0086 - val_acc: 0.9446\n",
      "Epoch 181/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0088 - acc: 0.9432 - val_loss: 0.0086 - val_acc: 0.9446\n",
      "Epoch 182/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0087 - acc: 0.9432 - val_loss: 0.0086 - val_acc: 0.9446\n",
      "Epoch 183/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0087 - acc: 0.9432 - val_loss: 0.0085 - val_acc: 0.9446\n",
      "Epoch 184/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0087 - acc: 0.9432 - val_loss: 0.0085 - val_acc: 0.9446\n",
      "Epoch 185/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0086 - acc: 0.9432 - val_loss: 0.0085 - val_acc: 0.9446\n",
      "Epoch 186/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0086 - acc: 0.9432 - val_loss: 0.0084 - val_acc: 0.9446\n",
      "Epoch 187/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0086 - acc: 0.9432 - val_loss: 0.0084 - val_acc: 0.9446\n",
      "Epoch 188/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0085 - acc: 0.9432 - val_loss: 0.0084 - val_acc: 0.9446\n",
      "Epoch 189/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0085 - acc: 0.9432 - val_loss: 0.0083 - val_acc: 0.9446\n",
      "Epoch 190/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0085 - acc: 0.9432 - val_loss: 0.0083 - val_acc: 0.9446\n",
      "Epoch 191/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0084 - acc: 0.9432 - val_loss: 0.0083 - val_acc: 0.9446\n",
      "Epoch 192/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0084 - acc: 0.9432 - val_loss: 0.0082 - val_acc: 0.9446\n",
      "Epoch 193/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0084 - acc: 0.9432 - val_loss: 0.0082 - val_acc: 0.9446\n",
      "Epoch 194/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0083 - acc: 0.9432 - val_loss: 0.0082 - val_acc: 0.9446\n",
      "Epoch 195/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0083 - acc: 0.9432 - val_loss: 0.0081 - val_acc: 0.9446\n",
      "Epoch 196/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0083 - acc: 0.9432 - val_loss: 0.0081 - val_acc: 0.9446\n",
      "Epoch 197/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0083 - acc: 0.9432 - val_loss: 0.0081 - val_acc: 0.9446\n",
      "Epoch 198/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0082 - acc: 0.9432 - val_loss: 0.0081 - val_acc: 0.9446\n",
      "Epoch 199/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0082 - acc: 0.9432 - val_loss: 0.0080 - val_acc: 0.9446\n",
      "Epoch 200/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0082 - acc: 0.9432 - val_loss: 0.0080 - val_acc: 0.9446\n",
      "Epoch 201/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.9432 - val_loss: 0.0080 - val_acc: 0.9446\n",
      "Epoch 202/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.9432 - val_loss: 0.0079 - val_acc: 0.9446\n",
      "Epoch 203/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.9432 - val_loss: 0.0079 - val_acc: 0.9446\n",
      "Epoch 204/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0080 - acc: 0.9432 - val_loss: 0.0079 - val_acc: 0.9446\n",
      "Epoch 205/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0080 - acc: 0.9432 - val_loss: 0.0078 - val_acc: 0.9446\n",
      "Epoch 206/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0080 - acc: 0.9432 - val_loss: 0.0078 - val_acc: 0.9446\n",
      "Epoch 207/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.9432 - val_loss: 0.0078 - val_acc: 0.9446\n",
      "Epoch 208/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.9432 - val_loss: 0.0077 - val_acc: 0.9446\n",
      "Epoch 209/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.9432 - val_loss: 0.0077 - val_acc: 0.9446\n",
      "Epoch 210/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.9432 - val_loss: 0.0077 - val_acc: 0.9446\n",
      "Epoch 211/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0078 - acc: 0.9432 - val_loss: 0.0077 - val_acc: 0.9446\n",
      "Epoch 212/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0078 - acc: 0.9432 - val_loss: 0.0076 - val_acc: 0.9446\n",
      "Epoch 213/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0078 - acc: 0.9432 - val_loss: 0.0076 - val_acc: 0.9446\n",
      "Epoch 214/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.9432 - val_loss: 0.0076 - val_acc: 0.9446\n",
      "Epoch 215/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.9432 - val_loss: 0.0075 - val_acc: 0.9446\n",
      "Epoch 216/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.9432 - val_loss: 0.0075 - val_acc: 0.9446\n",
      "Epoch 217/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.9432 - val_loss: 0.0075 - val_acc: 0.9446\n",
      "Epoch 218/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0076 - acc: 0.9432 - val_loss: 0.0075 - val_acc: 0.9446\n",
      "Epoch 219/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0076 - acc: 0.9432 - val_loss: 0.0074 - val_acc: 0.9446\n",
      "Epoch 220/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0076 - acc: 0.9432 - val_loss: 0.0074 - val_acc: 0.9446\n",
      "Epoch 221/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.9432 - val_loss: 0.0074 - val_acc: 0.9446\n",
      "Epoch 222/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.9432 - val_loss: 0.0074 - val_acc: 0.9446\n",
      "Epoch 223/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.9432 - val_loss: 0.0073 - val_acc: 0.9446\n",
      "Epoch 224/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.9432 - val_loss: 0.0073 - val_acc: 0.9446\n",
      "Epoch 225/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.9432 - val_loss: 0.0073 - val_acc: 0.9446\n",
      "Epoch 226/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.9432 - val_loss: 0.0072 - val_acc: 0.9446\n",
      "Epoch 227/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.9432 - val_loss: 0.0072 - val_acc: 0.9446\n",
      "Epoch 228/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.9432 - val_loss: 0.0072 - val_acc: 0.9446\n",
      "Epoch 229/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.9432 - val_loss: 0.0072 - val_acc: 0.9446\n",
      "Epoch 230/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.9432 - val_loss: 0.0071 - val_acc: 0.9446\n",
      "Epoch 231/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.9432 - val_loss: 0.0071 - val_acc: 0.9446\n",
      "Epoch 232/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9432 - val_loss: 0.0071 - val_acc: 0.9446\n",
      "Epoch 233/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9432 - val_loss: 0.0071 - val_acc: 0.9446\n",
      "Epoch 234/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9432 - val_loss: 0.0070 - val_acc: 0.9446\n",
      "Epoch 235/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9432 - val_loss: 0.0070 - val_acc: 0.9446\n",
      "Epoch 236/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9432 - val_loss: 0.0070 - val_acc: 0.9446\n",
      "Epoch 237/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9432 - val_loss: 0.0070 - val_acc: 0.9446\n",
      "Epoch 238/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9432 - val_loss: 0.0069 - val_acc: 0.9446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9432 - val_loss: 0.0069 - val_acc: 0.9446\n",
      "Epoch 240/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9432 - val_loss: 0.0069 - val_acc: 0.9446\n",
      "Epoch 241/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9432 - val_loss: 0.0069 - val_acc: 0.9446\n",
      "Epoch 242/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9432 - val_loss: 0.0069 - val_acc: 0.9446\n",
      "Epoch 243/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9432 - val_loss: 0.0068 - val_acc: 0.9446\n",
      "Epoch 244/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9432 - val_loss: 0.0068 - val_acc: 0.9446\n",
      "Epoch 245/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9432 - val_loss: 0.0068 - val_acc: 0.9446\n",
      "Epoch 246/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9432 - val_loss: 0.0068 - val_acc: 0.9446\n",
      "Epoch 247/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9432 - val_loss: 0.0067 - val_acc: 0.9446\n",
      "Epoch 248/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9432 - val_loss: 0.0067 - val_acc: 0.9446\n",
      "Epoch 249/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.9432 - val_loss: 0.0067 - val_acc: 0.9446\n",
      "Epoch 250/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.9432 - val_loss: 0.0067 - val_acc: 0.9446\n",
      "Epoch 251/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.9432 - val_loss: 0.0066 - val_acc: 0.9446\n",
      "Epoch 252/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.9432 - val_loss: 0.0066 - val_acc: 0.9446\n",
      "Epoch 253/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.9432 - val_loss: 0.0066 - val_acc: 0.9446\n",
      "Epoch 254/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.9432 - val_loss: 0.0066 - val_acc: 0.9446\n",
      "Epoch 255/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.9432 - val_loss: 0.0065 - val_acc: 0.9446\n",
      "Epoch 256/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.9432 - val_loss: 0.0065 - val_acc: 0.9446\n",
      "Epoch 257/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9432 - val_loss: 0.0065 - val_acc: 0.9446\n",
      "Epoch 258/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9432 - val_loss: 0.0065 - val_acc: 0.9446\n",
      "Epoch 259/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9432 - val_loss: 0.0065 - val_acc: 0.9446\n",
      "Epoch 260/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9432 - val_loss: 0.0064 - val_acc: 0.9446\n",
      "Epoch 261/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.9432 - val_loss: 0.0064 - val_acc: 0.9446\n",
      "Epoch 262/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0065 - acc: 0.9432 - val_loss: 0.0064 - val_acc: 0.9446\n",
      "Epoch 263/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0065 - acc: 0.9432 - val_loss: 0.0064 - val_acc: 0.9446\n",
      "Epoch 264/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0065 - acc: 0.9432 - val_loss: 0.0063 - val_acc: 0.9446\n",
      "Epoch 265/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0065 - acc: 0.9432 - val_loss: 0.0063 - val_acc: 0.9446\n",
      "Epoch 266/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0064 - acc: 0.9432 - val_loss: 0.0063 - val_acc: 0.9446\n",
      "Epoch 267/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0064 - acc: 0.9432 - val_loss: 0.0063 - val_acc: 0.9446\n",
      "Epoch 268/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0064 - acc: 0.9432 - val_loss: 0.0063 - val_acc: 0.9446\n",
      "Epoch 269/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0064 - acc: 0.9432 - val_loss: 0.0062 - val_acc: 0.9446\n",
      "Epoch 270/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0064 - acc: 0.9432 - val_loss: 0.0062 - val_acc: 0.9446\n",
      "Epoch 271/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9432 - val_loss: 0.0062 - val_acc: 0.9446\n",
      "Epoch 272/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9432 - val_loss: 0.0062 - val_acc: 0.9446\n",
      "Epoch 273/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9432 - val_loss: 0.0061 - val_acc: 0.9446\n",
      "Epoch 274/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0063 - acc: 0.9432 - val_loss: 0.0061 - val_acc: 0.9446\n",
      "Epoch 275/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0062 - acc: 0.9432 - val_loss: 0.0061 - val_acc: 0.9446\n",
      "Epoch 276/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0062 - acc: 0.9432 - val_loss: 0.0061 - val_acc: 0.9446\n",
      "Epoch 277/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0062 - acc: 0.9432 - val_loss: 0.0061 - val_acc: 0.9446\n",
      "Epoch 278/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0062 - acc: 0.9432 - val_loss: 0.0060 - val_acc: 0.9446\n",
      "Epoch 279/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0062 - acc: 0.9432 - val_loss: 0.0060 - val_acc: 0.9446\n",
      "Epoch 280/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9432 - val_loss: 0.0060 - val_acc: 0.9446\n",
      "Epoch 281/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9432 - val_loss: 0.0060 - val_acc: 0.9446\n",
      "Epoch 282/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9432 - val_loss: 0.0060 - val_acc: 0.9446\n",
      "Epoch 283/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9432 - val_loss: 0.0059 - val_acc: 0.9446\n",
      "Epoch 284/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0061 - acc: 0.9432 - val_loss: 0.0059 - val_acc: 0.9446\n",
      "Epoch 285/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0060 - acc: 0.9432 - val_loss: 0.0059 - val_acc: 0.9446\n",
      "Epoch 286/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0060 - acc: 0.9432 - val_loss: 0.0059 - val_acc: 0.9446\n",
      "Epoch 287/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0060 - acc: 0.9432 - val_loss: 0.0059 - val_acc: 0.9446\n",
      "Epoch 288/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0060 - acc: 0.9432 - val_loss: 0.0058 - val_acc: 0.9446\n",
      "Epoch 289/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0060 - acc: 0.9432 - val_loss: 0.0058 - val_acc: 0.9446\n",
      "Epoch 290/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9432 - val_loss: 0.0058 - val_acc: 0.9446\n",
      "Epoch 291/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9432 - val_loss: 0.0058 - val_acc: 0.9446\n",
      "Epoch 292/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9432 - val_loss: 0.0058 - val_acc: 0.9446\n",
      "Epoch 293/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0059 - acc: 0.9432 - val_loss: 0.0057 - val_acc: 0.9446\n",
      "Epoch 294/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0058 - acc: 0.9432 - val_loss: 0.0057 - val_acc: 0.9446\n",
      "Epoch 295/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0058 - acc: 0.9432 - val_loss: 0.0057 - val_acc: 0.9446\n",
      "Epoch 296/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0058 - acc: 0.9432 - val_loss: 0.0057 - val_acc: 0.9446\n",
      "Epoch 297/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0058 - acc: 0.9432 - val_loss: 0.0057 - val_acc: 0.9446\n",
      "Epoch 298/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0058 - acc: 0.9432 - val_loss: 0.0056 - val_acc: 0.9446\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0057 - acc: 0.9432 - val_loss: 0.0056 - val_acc: 0.9446\n",
      "Epoch 300/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0057 - acc: 0.9432 - val_loss: 0.0056 - val_acc: 0.9446\n",
      "3000/3000 [==============================] - 0s 28us/step\n",
      "['loss', 'acc'] [0.0059037270365903775, 0.9479999998410543]\n",
      "[[0.66108923 0.95594316]] [[9.0722470e-03 9.9069792e-01 2.2986531e-04]]\n"
     ]
    }
   ],
   "source": [
    "mask_value = -1.0\n",
    "model = multi_learning_demo(activation='softmax', loss=[categorical_focal_loss(alpha=.25, gamma=2, mask_value=mask_value)]\n",
    "                                       , mask_value=mask_value)\n",
    "x = np.random.rand(1,2)\n",
    "print(x, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### マルチラベル+cross_entropy_lossの時のFocalLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_masked_loss(loss_function, mask_value=-1):\n",
    "    \"\"\"\n",
    "    ラベル付けされたデータを「マスクする」損失関数\n",
    "    https://www.dlology.com/blog/how-to-multi-task-learning-with-missing-labels-in-keras/\n",
    "    https://github.com/keras-team/keras/issues/3893\n",
    "    マルチラベル（多クラス多ラベル分類）は sigmoid+binary_crossentropy\n",
    "    Args:\n",
    "        loss_func: The loss function to mask（K.binary_crossentropy or K.categorical_crossentropy）\n",
    "        mask_value: The value to mask in the targets（欠損ラベルとしてマスクする値）\n",
    "    Returns:\n",
    "        function: a loss function that acts like loss_function with masked inputs\n",
    "    \"\"\"\n",
    "    def masked_loss_function(y_true, y_pred):\n",
    "        mask = K.cast(K.not_equal(y_true, mask_value), K.floatx())\n",
    "        # 欠損の要素が削除される。テンソルのshapeが[batch_size, クラス数+1(欠損クラス)]→[batch_size, クラス数]になる\n",
    "        return loss_function(y_true * mask, y_pred * mask)\n",
    "    return masked_loss_function\n",
    "\n",
    "class FocalLoss_multilabel(object):\n",
    "    \"\"\"\n",
    "    マルチラベル+cross_entropy_lossの時のFocalLoss\n",
    "    https://github.com/keras-team/keras/issues/10371\n",
    "    loss関数を引数で渡す様にした\n",
    "\n",
    "    FocalLossの論文解説記事：\n",
    "    https://towardsdatascience.com/handling-class-imbalanced-data-using-a-loss-specifically-made-for-it-6e58fd65ffab\n",
    "    論文ではCIFAR10のクラス不均衡が100倍、200倍の時focal loss有効だった\n",
    "\n",
    "    Usage:\n",
    "        f_loss = multi_loss.FocalLoss(loss_function=multi_loss.build_masked_loss(K.binary_crossentropy)).compute_loss\n",
    "        model.compile(loss=f_loss, optimizer='nadam', metrics=['accuracy', masked_accuracy])\n",
    "        model.fit_generator(…)\n",
    "    \"\"\"\n",
    "    def __init__(self, gamma=2, alpha=0.25, loss_function=K.binary_crossentropy):\n",
    "        self._gamma = gamma\n",
    "        self._alpha = alpha\n",
    "        self._loss_function = loss_function\n",
    "        \n",
    "    def compute_loss(self, y_true, y_pred):\n",
    "        cross_entropy_loss = self._loss_function(y_true, y_pred)\n",
    "        p_t = ((y_true * y_pred) + ((1 - y_true) * (1 - y_pred)))\n",
    "        modulating_factor = 1.0\n",
    "        if self._gamma:\n",
    "            modulating_factor = tf.pow(1.0 - p_t, self._gamma)\n",
    "        alpha_weight_factor = 1.0\n",
    "        if self._alpha is not None:\n",
    "            alpha_weight_factor = (y_true * self._alpha + (1 - y_true) * (1 - self._alpha))\n",
    "        focal_cross_entropy_loss = (modulating_factor * alpha_weight_factor * cross_entropy_loss)\n",
    "\n",
    "        return K.mean(focal_cross_entropy_loss, axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multi_label_learning_demo(activation='sigmoid', loss=K.binary_crossentropy , mask_value=-1.0, is_FocalLoss_multilabel=True):\n",
    "    \"\"\"\n",
    "    https://www.dlology.com/blog/how-to-multi-task-learning-with-missing-labels-in-keras/\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import OneHotEncoder\n",
    "    from sklearn.model_selection  import train_test_split\n",
    "    import tensorflow as tf\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    import numpy as np\n",
    "    seed = 42\n",
    "    np.random.seed(seed) # 乱数シード固定\n",
    "    \n",
    "    # 2D空間で100,000個のデータポイントをランダムに生成します。各軸の範囲は0〜1\n",
    "    N =100000\n",
    "    X = np.random.rand(N,2)\n",
    "    \n",
    "    # focal loss用に不均衡にする\n",
    "    threshold = 0.05#0.5\n",
    "    \n",
    "    # place holder for Y\n",
    "    Y = np.ones((N,3))\n",
    "    if activation == 'sigmoid':\n",
    "        print('sigmoid')\n",
    "        Y[:,0] = X[:, 1] <= threshold\n",
    "        Y[:,1] = X[:, 0] >= threshold\n",
    "        Y[:,2] = X[:, 0] + X[:, 1] > 1\n",
    "    else:\n",
    "        print('not sigmoid')\n",
    "        Y[:,0] = X[:, 1] <= threshold\n",
    "        Y[:,1] = X[:, 1] > threshold\n",
    "        Y[:,2] = 0\n",
    "\n",
    "    # Mask for missing label.\n",
    "    if mask_value is not None:\n",
    "        # Drop 2% y0.\n",
    "        Y[: int(N*0.020), 0] = mask_value\n",
    "        # Drop 0.7% y1.\n",
    "        Y[int(N*0.018): int(N*0.025), 1] = mask_value\n",
    "        # Drop 1.1% y2.\n",
    "        Y[int(N*0.024): int(N*0.035), 2] = mask_value\n",
    "\n",
    "    print(Y.shape, Y)\n",
    "    for i in range(3): \n",
    "        print(pd.Series(Y[:,i]).value_counts())\n",
    "        \n",
    "    X_train, X_dev, y_train, y_dev = train_test_split(X[:-3000], Y[:-3000], test_size=0.9, random_state=seed)\n",
    "\n",
    "    K.clear_session()\n",
    "    model = Sequential()\n",
    "\n",
    "    input_dim = X_train.shape[1]\n",
    "    nb_classes = y_train.shape[1]\n",
    "    print('input_dim, nb_classes:', input_dim, nb_classes)\n",
    "\n",
    "    model.add(Dense(10, input_dim=input_dim, activation='relu', name='input'))\n",
    "    model.add(Dense(20, activation='relu', name='fc1'))\n",
    "    model.add(Dense(10, activation='relu', name='fc2'))\n",
    "    model.add(Dense(nb_classes, activation=activation, name='output'))\n",
    "\n",
    "    if mask_value is not None:\n",
    "        loss = build_masked_loss(loss, mask_value=mask_value)\n",
    "        \n",
    "    if is_FocalLoss_multilabel:\n",
    "        loss = FocalLoss_multilabel(loss_function=loss).compute_loss\n",
    "\n",
    "    model.compile(loss=loss, optimizer='nadam', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(X_train, y_train, validation_data=(X_dev,y_dev), epochs=300, batch_size=500000)\n",
    "\n",
    "    print(model.metrics_names, model.evaluate(X[-3000:],Y[-3000:]))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid +  Focal_Lossなし\n",
    "- うまくいってる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid\n",
      "(100000, 3) [[0. 1. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 1. 0.]]\n",
      "0.0    95031\n",
      "1.0     4969\n",
      "dtype: int64\n",
      "1.0    95109\n",
      "0.0     4891\n",
      "dtype: int64\n",
      "1.0    50034\n",
      "0.0    49966\n",
      "dtype: int64\n",
      "input_dim, nb_classes: 2 3\n",
      "Train on 9700 samples, validate on 87300 samples\n",
      "Epoch 1/300\n",
      "9700/9700 [==============================] - 0s 16us/step - loss: 0.6779 - acc: 0.2948 - val_loss: 0.6736 - val_acc: 0.3707\n",
      "Epoch 2/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6737 - acc: 0.3741 - val_loss: 0.6708 - val_acc: 0.4028\n",
      "Epoch 3/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6708 - acc: 0.4062 - val_loss: 0.6682 - val_acc: 0.4320\n",
      "Epoch 4/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6682 - acc: 0.4373 - val_loss: 0.6656 - val_acc: 0.4566\n",
      "Epoch 5/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6656 - acc: 0.4606 - val_loss: 0.6628 - val_acc: 0.4751\n",
      "Epoch 6/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6629 - acc: 0.4789 - val_loss: 0.6600 - val_acc: 0.4899\n",
      "Epoch 7/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6600 - acc: 0.4940 - val_loss: 0.6570 - val_acc: 0.5035\n",
      "Epoch 8/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6570 - acc: 0.5054 - val_loss: 0.6538 - val_acc: 0.5160\n",
      "Epoch 9/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6539 - acc: 0.5212 - val_loss: 0.6505 - val_acc: 0.5323\n",
      "Epoch 10/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6506 - acc: 0.5365 - val_loss: 0.6470 - val_acc: 0.5499\n",
      "Epoch 11/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6471 - acc: 0.5561 - val_loss: 0.6435 - val_acc: 0.5673\n",
      "Epoch 12/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6436 - acc: 0.5753 - val_loss: 0.6396 - val_acc: 0.5856\n",
      "Epoch 13/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6397 - acc: 0.5938 - val_loss: 0.6357 - val_acc: 0.6042\n",
      "Epoch 14/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6357 - acc: 0.6104 - val_loss: 0.6314 - val_acc: 0.6235\n",
      "Epoch 15/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6314 - acc: 0.6291 - val_loss: 0.6269 - val_acc: 0.6441\n",
      "Epoch 16/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6269 - acc: 0.6485 - val_loss: 0.6222 - val_acc: 0.6682\n",
      "Epoch 17/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6223 - acc: 0.6685 - val_loss: 0.6173 - val_acc: 0.6932\n",
      "Epoch 18/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6174 - acc: 0.6919 - val_loss: 0.6123 - val_acc: 0.7236\n",
      "Epoch 19/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6124 - acc: 0.7234 - val_loss: 0.6070 - val_acc: 0.7604\n",
      "Epoch 20/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6071 - acc: 0.7599 - val_loss: 0.6016 - val_acc: 0.8038\n",
      "Epoch 21/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.6017 - acc: 0.8041 - val_loss: 0.5960 - val_acc: 0.8542\n",
      "Epoch 22/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5961 - acc: 0.8562 - val_loss: 0.5901 - val_acc: 0.9029\n",
      "Epoch 23/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5902 - acc: 0.9057 - val_loss: 0.5841 - val_acc: 0.9033\n",
      "Epoch 24/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5842 - acc: 0.9061 - val_loss: 0.5778 - val_acc: 0.9033\n",
      "Epoch 25/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5779 - acc: 0.9061 - val_loss: 0.5712 - val_acc: 0.9033\n",
      "Epoch 26/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5713 - acc: 0.9061 - val_loss: 0.5645 - val_acc: 0.9033\n",
      "Epoch 27/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5646 - acc: 0.9061 - val_loss: 0.5575 - val_acc: 0.9033\n",
      "Epoch 28/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5575 - acc: 0.9061 - val_loss: 0.5502 - val_acc: 0.9033\n",
      "Epoch 29/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5502 - acc: 0.9061 - val_loss: 0.5426 - val_acc: 0.9033\n",
      "Epoch 30/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5427 - acc: 0.9061 - val_loss: 0.5348 - val_acc: 0.9033\n",
      "Epoch 31/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5348 - acc: 0.9061 - val_loss: 0.5268 - val_acc: 0.9033\n",
      "Epoch 32/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5267 - acc: 0.9061 - val_loss: 0.5184 - val_acc: 0.9033\n",
      "Epoch 33/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5184 - acc: 0.9061 - val_loss: 0.5098 - val_acc: 0.9033\n",
      "Epoch 34/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5097 - acc: 0.9061 - val_loss: 0.5010 - val_acc: 0.9033\n",
      "Epoch 35/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.5010 - acc: 0.9061 - val_loss: 0.4919 - val_acc: 0.9033\n",
      "Epoch 36/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4918 - acc: 0.9061 - val_loss: 0.4826 - val_acc: 0.9033\n",
      "Epoch 37/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4825 - acc: 0.9061 - val_loss: 0.4731 - val_acc: 0.9033\n",
      "Epoch 38/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4730 - acc: 0.9061 - val_loss: 0.4633 - val_acc: 0.9033\n",
      "Epoch 39/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4631 - acc: 0.9061 - val_loss: 0.4531 - val_acc: 0.9033\n",
      "Epoch 40/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4529 - acc: 0.9061 - val_loss: 0.4428 - val_acc: 0.9033\n",
      "Epoch 41/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4425 - acc: 0.9061 - val_loss: 0.4327 - val_acc: 0.9033\n",
      "Epoch 42/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4325 - acc: 0.9061 - val_loss: 0.4231 - val_acc: 0.9033\n",
      "Epoch 43/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4228 - acc: 0.9061 - val_loss: 0.4140 - val_acc: 0.9033\n",
      "Epoch 44/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4137 - acc: 0.9061 - val_loss: 0.4055 - val_acc: 0.9033\n",
      "Epoch 45/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.4051 - acc: 0.9061 - val_loss: 0.3974 - val_acc: 0.9033\n",
      "Epoch 46/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3970 - acc: 0.9061 - val_loss: 0.3898 - val_acc: 0.9033\n",
      "Epoch 47/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3894 - acc: 0.9061 - val_loss: 0.3827 - val_acc: 0.9033\n",
      "Epoch 48/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3823 - acc: 0.9061 - val_loss: 0.3761 - val_acc: 0.9033\n",
      "Epoch 49/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3757 - acc: 0.9061 - val_loss: 0.3701 - val_acc: 0.9033\n",
      "Epoch 50/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3696 - acc: 0.9061 - val_loss: 0.3645 - val_acc: 0.9033\n",
      "Epoch 51/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3640 - acc: 0.9061 - val_loss: 0.3595 - val_acc: 0.9033\n",
      "Epoch 52/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3589 - acc: 0.9061 - val_loss: 0.3548 - val_acc: 0.9033\n",
      "Epoch 53/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3542 - acc: 0.9061 - val_loss: 0.3507 - val_acc: 0.9033\n",
      "Epoch 54/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3500 - acc: 0.9061 - val_loss: 0.3469 - val_acc: 0.9033\n",
      "Epoch 55/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3462 - acc: 0.9061 - val_loss: 0.3435 - val_acc: 0.9033\n",
      "Epoch 56/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3428 - acc: 0.9061 - val_loss: 0.3404 - val_acc: 0.9033\n",
      "Epoch 57/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3397 - acc: 0.9061 - val_loss: 0.3377 - val_acc: 0.9033\n",
      "Epoch 58/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3369 - acc: 0.9061 - val_loss: 0.3353 - val_acc: 0.9033\n",
      "Epoch 59/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3344 - acc: 0.9061 - val_loss: 0.3331 - val_acc: 0.9033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3321 - acc: 0.9061 - val_loss: 0.3311 - val_acc: 0.9033\n",
      "Epoch 61/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3301 - acc: 0.9061 - val_loss: 0.3294 - val_acc: 0.9033\n",
      "Epoch 62/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3283 - acc: 0.9061 - val_loss: 0.3278 - val_acc: 0.9033\n",
      "Epoch 63/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3267 - acc: 0.9061 - val_loss: 0.3264 - val_acc: 0.9033\n",
      "Epoch 64/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3252 - acc: 0.9061 - val_loss: 0.3250 - val_acc: 0.9033\n",
      "Epoch 65/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3238 - acc: 0.9061 - val_loss: 0.3238 - val_acc: 0.9033\n",
      "Epoch 66/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3226 - acc: 0.9061 - val_loss: 0.3227 - val_acc: 0.9033\n",
      "Epoch 67/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3214 - acc: 0.9061 - val_loss: 0.3217 - val_acc: 0.9033\n",
      "Epoch 68/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3204 - acc: 0.9061 - val_loss: 0.3207 - val_acc: 0.9033\n",
      "Epoch 69/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3193 - acc: 0.9061 - val_loss: 0.3197 - val_acc: 0.9033\n",
      "Epoch 70/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3183 - acc: 0.9061 - val_loss: 0.3188 - val_acc: 0.9033\n",
      "Epoch 71/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3174 - acc: 0.9061 - val_loss: 0.3180 - val_acc: 0.9033\n",
      "Epoch 72/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3165 - acc: 0.9061 - val_loss: 0.3171 - val_acc: 0.9033\n",
      "Epoch 73/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3156 - acc: 0.9061 - val_loss: 0.3162 - val_acc: 0.9033\n",
      "Epoch 74/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3147 - acc: 0.9061 - val_loss: 0.3154 - val_acc: 0.9033\n",
      "Epoch 75/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3138 - acc: 0.9061 - val_loss: 0.3145 - val_acc: 0.9033\n",
      "Epoch 76/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3130 - acc: 0.9061 - val_loss: 0.3136 - val_acc: 0.9033\n",
      "Epoch 77/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3121 - acc: 0.9061 - val_loss: 0.3128 - val_acc: 0.9033\n",
      "Epoch 78/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3112 - acc: 0.9061 - val_loss: 0.3119 - val_acc: 0.9033\n",
      "Epoch 79/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3103 - acc: 0.9061 - val_loss: 0.3110 - val_acc: 0.9033\n",
      "Epoch 80/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3094 - acc: 0.9061 - val_loss: 0.3101 - val_acc: 0.9033\n",
      "Epoch 81/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3084 - acc: 0.9061 - val_loss: 0.3091 - val_acc: 0.9033\n",
      "Epoch 82/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3075 - acc: 0.9061 - val_loss: 0.3082 - val_acc: 0.9033\n",
      "Epoch 83/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3065 - acc: 0.9061 - val_loss: 0.3072 - val_acc: 0.9033\n",
      "Epoch 84/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3055 - acc: 0.9061 - val_loss: 0.3062 - val_acc: 0.9033\n",
      "Epoch 85/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3045 - acc: 0.9061 - val_loss: 0.3052 - val_acc: 0.9033\n",
      "Epoch 86/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3035 - acc: 0.9061 - val_loss: 0.3042 - val_acc: 0.9033\n",
      "Epoch 87/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3025 - acc: 0.9061 - val_loss: 0.3031 - val_acc: 0.9033\n",
      "Epoch 88/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3014 - acc: 0.9061 - val_loss: 0.3021 - val_acc: 0.9033\n",
      "Epoch 89/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.3003 - acc: 0.9061 - val_loss: 0.3010 - val_acc: 0.9033\n",
      "Epoch 90/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2992 - acc: 0.9061 - val_loss: 0.2998 - val_acc: 0.9033\n",
      "Epoch 91/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2981 - acc: 0.9061 - val_loss: 0.2987 - val_acc: 0.9033\n",
      "Epoch 92/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2969 - acc: 0.9061 - val_loss: 0.2975 - val_acc: 0.9033\n",
      "Epoch 93/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2958 - acc: 0.9061 - val_loss: 0.2963 - val_acc: 0.9033\n",
      "Epoch 94/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2945 - acc: 0.9061 - val_loss: 0.2950 - val_acc: 0.9033\n",
      "Epoch 95/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2933 - acc: 0.9061 - val_loss: 0.2938 - val_acc: 0.9033\n",
      "Epoch 96/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2920 - acc: 0.9061 - val_loss: 0.2925 - val_acc: 0.9033\n",
      "Epoch 97/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2907 - acc: 0.9061 - val_loss: 0.2911 - val_acc: 0.9033\n",
      "Epoch 98/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2894 - acc: 0.9061 - val_loss: 0.2897 - val_acc: 0.9033\n",
      "Epoch 99/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2880 - acc: 0.9061 - val_loss: 0.2883 - val_acc: 0.9033\n",
      "Epoch 100/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2866 - acc: 0.9061 - val_loss: 0.2869 - val_acc: 0.9033\n",
      "Epoch 101/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2851 - acc: 0.9061 - val_loss: 0.2854 - val_acc: 0.9033\n",
      "Epoch 102/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2836 - acc: 0.9061 - val_loss: 0.2839 - val_acc: 0.9033\n",
      "Epoch 103/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2821 - acc: 0.9061 - val_loss: 0.2823 - val_acc: 0.9033\n",
      "Epoch 104/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2805 - acc: 0.9061 - val_loss: 0.2807 - val_acc: 0.9033\n",
      "Epoch 105/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2789 - acc: 0.9061 - val_loss: 0.2790 - val_acc: 0.9033\n",
      "Epoch 106/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2773 - acc: 0.9061 - val_loss: 0.2773 - val_acc: 0.9033\n",
      "Epoch 107/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2756 - acc: 0.9061 - val_loss: 0.2756 - val_acc: 0.9033\n",
      "Epoch 108/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2738 - acc: 0.9061 - val_loss: 0.2738 - val_acc: 0.9033\n",
      "Epoch 109/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2720 - acc: 0.9061 - val_loss: 0.2720 - val_acc: 0.9033\n",
      "Epoch 110/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2702 - acc: 0.9061 - val_loss: 0.2701 - val_acc: 0.9033\n",
      "Epoch 111/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2683 - acc: 0.9061 - val_loss: 0.2682 - val_acc: 0.9033\n",
      "Epoch 112/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2664 - acc: 0.9061 - val_loss: 0.2662 - val_acc: 0.9033\n",
      "Epoch 113/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2644 - acc: 0.9061 - val_loss: 0.2642 - val_acc: 0.9033\n",
      "Epoch 114/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2624 - acc: 0.9061 - val_loss: 0.2622 - val_acc: 0.9033\n",
      "Epoch 115/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2604 - acc: 0.9061 - val_loss: 0.2601 - val_acc: 0.9033\n",
      "Epoch 116/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2583 - acc: 0.9061 - val_loss: 0.2580 - val_acc: 0.9033\n",
      "Epoch 117/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2562 - acc: 0.9061 - val_loss: 0.2559 - val_acc: 0.9033\n",
      "Epoch 118/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2540 - acc: 0.9061 - val_loss: 0.2537 - val_acc: 0.9033\n",
      "Epoch 119/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2519 - acc: 0.9061 - val_loss: 0.2515 - val_acc: 0.9033\n",
      "Epoch 120/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2496 - acc: 0.9061 - val_loss: 0.2492 - val_acc: 0.9033\n",
      "Epoch 121/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2474 - acc: 0.9061 - val_loss: 0.2470 - val_acc: 0.9033\n",
      "Epoch 122/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2451 - acc: 0.9061 - val_loss: 0.2447 - val_acc: 0.9033\n",
      "Epoch 123/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2428 - acc: 0.9061 - val_loss: 0.2424 - val_acc: 0.9033\n",
      "Epoch 124/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2405 - acc: 0.9061 - val_loss: 0.2400 - val_acc: 0.9033\n",
      "Epoch 125/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2382 - acc: 0.9061 - val_loss: 0.2377 - val_acc: 0.9033\n",
      "Epoch 126/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2358 - acc: 0.9061 - val_loss: 0.2353 - val_acc: 0.9033\n",
      "Epoch 127/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2335 - acc: 0.9061 - val_loss: 0.2330 - val_acc: 0.9033\n",
      "Epoch 128/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2311 - acc: 0.9061 - val_loss: 0.2306 - val_acc: 0.9033\n",
      "Epoch 129/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2287 - acc: 0.9061 - val_loss: 0.2282 - val_acc: 0.9033\n",
      "Epoch 130/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2263 - acc: 0.9061 - val_loss: 0.2258 - val_acc: 0.9033\n",
      "Epoch 131/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2239 - acc: 0.9061 - val_loss: 0.2235 - val_acc: 0.9033\n",
      "Epoch 132/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2215 - acc: 0.9061 - val_loss: 0.2211 - val_acc: 0.9033\n",
      "Epoch 133/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2192 - acc: 0.9061 - val_loss: 0.2187 - val_acc: 0.9033\n",
      "Epoch 134/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2168 - acc: 0.9061 - val_loss: 0.2164 - val_acc: 0.9033\n",
      "Epoch 135/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2145 - acc: 0.9061 - val_loss: 0.2141 - val_acc: 0.9033\n",
      "Epoch 136/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2121 - acc: 0.9061 - val_loss: 0.2118 - val_acc: 0.9033\n",
      "Epoch 137/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2098 - acc: 0.9061 - val_loss: 0.2095 - val_acc: 0.9033\n",
      "Epoch 138/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2075 - acc: 0.9061 - val_loss: 0.2072 - val_acc: 0.9033\n",
      "Epoch 139/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2052 - acc: 0.9061 - val_loss: 0.2050 - val_acc: 0.9033\n",
      "Epoch 140/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2030 - acc: 0.9061 - val_loss: 0.2028 - val_acc: 0.9033\n",
      "Epoch 141/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.2008 - acc: 0.9061 - val_loss: 0.2006 - val_acc: 0.9033\n",
      "Epoch 142/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1986 - acc: 0.9061 - val_loss: 0.1984 - val_acc: 0.9033\n",
      "Epoch 143/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1964 - acc: 0.9061 - val_loss: 0.1963 - val_acc: 0.9033\n",
      "Epoch 144/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1943 - acc: 0.9061 - val_loss: 0.1942 - val_acc: 0.9033\n",
      "Epoch 145/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1922 - acc: 0.9061 - val_loss: 0.1921 - val_acc: 0.9033\n",
      "Epoch 146/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1901 - acc: 0.9061 - val_loss: 0.1901 - val_acc: 0.9033\n",
      "Epoch 147/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1881 - acc: 0.9061 - val_loss: 0.1881 - val_acc: 0.9033\n",
      "Epoch 148/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1861 - acc: 0.9061 - val_loss: 0.1861 - val_acc: 0.9033\n",
      "Epoch 149/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1841 - acc: 0.9061 - val_loss: 0.1842 - val_acc: 0.9033\n",
      "Epoch 150/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1822 - acc: 0.9061 - val_loss: 0.1823 - val_acc: 0.9033\n",
      "Epoch 151/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1803 - acc: 0.9061 - val_loss: 0.1805 - val_acc: 0.9033\n",
      "Epoch 152/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1784 - acc: 0.9061 - val_loss: 0.1786 - val_acc: 0.9033\n",
      "Epoch 153/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1766 - acc: 0.9061 - val_loss: 0.1768 - val_acc: 0.9033\n",
      "Epoch 154/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1748 - acc: 0.9061 - val_loss: 0.1751 - val_acc: 0.9033\n",
      "Epoch 155/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1730 - acc: 0.9061 - val_loss: 0.1733 - val_acc: 0.9033\n",
      "Epoch 156/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1713 - acc: 0.9061 - val_loss: 0.1716 - val_acc: 0.9033\n",
      "Epoch 157/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1696 - acc: 0.9061 - val_loss: 0.1700 - val_acc: 0.9033\n",
      "Epoch 158/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1679 - acc: 0.9061 - val_loss: 0.1683 - val_acc: 0.9033\n",
      "Epoch 159/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1663 - acc: 0.9061 - val_loss: 0.1667 - val_acc: 0.9033\n",
      "Epoch 160/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1647 - acc: 0.9061 - val_loss: 0.1652 - val_acc: 0.9033\n",
      "Epoch 161/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1631 - acc: 0.9061 - val_loss: 0.1636 - val_acc: 0.9033\n",
      "Epoch 162/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1616 - acc: 0.9061 - val_loss: 0.1621 - val_acc: 0.9033\n",
      "Epoch 163/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1601 - acc: 0.9061 - val_loss: 0.1607 - val_acc: 0.9033\n",
      "Epoch 164/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1587 - acc: 0.9061 - val_loss: 0.1592 - val_acc: 0.9033\n",
      "Epoch 165/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1572 - acc: 0.9061 - val_loss: 0.1578 - val_acc: 0.9033\n",
      "Epoch 166/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1558 - acc: 0.9061 - val_loss: 0.1564 - val_acc: 0.9033\n",
      "Epoch 167/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1544 - acc: 0.9061 - val_loss: 0.1551 - val_acc: 0.9033\n",
      "Epoch 168/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1531 - acc: 0.9061 - val_loss: 0.1538 - val_acc: 0.9033\n",
      "Epoch 169/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1518 - acc: 0.9061 - val_loss: 0.1525 - val_acc: 0.9033\n",
      "Epoch 170/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1505 - acc: 0.9061 - val_loss: 0.1511 - val_acc: 0.9033\n",
      "Epoch 171/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1491 - acc: 0.9061 - val_loss: 0.1495 - val_acc: 0.9033\n",
      "Epoch 172/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1476 - acc: 0.9061 - val_loss: 0.1481 - val_acc: 0.9033\n",
      "Epoch 173/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1462 - acc: 0.9061 - val_loss: 0.1468 - val_acc: 0.9033\n",
      "Epoch 174/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1449 - acc: 0.9061 - val_loss: 0.1456 - val_acc: 0.9033\n",
      "Epoch 175/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1437 - acc: 0.9061 - val_loss: 0.1443 - val_acc: 0.9033\n",
      "Epoch 176/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1425 - acc: 0.9061 - val_loss: 0.1431 - val_acc: 0.9033\n",
      "Epoch 177/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1413 - acc: 0.9061 - val_loss: 0.1420 - val_acc: 0.9033\n",
      "Epoch 178/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1401 - acc: 0.9061 - val_loss: 0.1408 - val_acc: 0.9033\n",
      "Epoch 179/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1390 - acc: 0.9061 - val_loss: 0.1397 - val_acc: 0.9033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1379 - acc: 0.9061 - val_loss: 0.1386 - val_acc: 0.9033\n",
      "Epoch 181/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1368 - acc: 0.9061 - val_loss: 0.1376 - val_acc: 0.9033\n",
      "Epoch 182/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1358 - acc: 0.9061 - val_loss: 0.1365 - val_acc: 0.9033\n",
      "Epoch 183/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1347 - acc: 0.9061 - val_loss: 0.1355 - val_acc: 0.9033\n",
      "Epoch 184/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1337 - acc: 0.9061 - val_loss: 0.1345 - val_acc: 0.9033\n",
      "Epoch 185/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1327 - acc: 0.9061 - val_loss: 0.1335 - val_acc: 0.9033\n",
      "Epoch 186/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1317 - acc: 0.9061 - val_loss: 0.1325 - val_acc: 0.9033\n",
      "Epoch 187/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1307 - acc: 0.9061 - val_loss: 0.1315 - val_acc: 0.9033\n",
      "Epoch 188/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1298 - acc: 0.9061 - val_loss: 0.1306 - val_acc: 0.9033\n",
      "Epoch 189/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1288 - acc: 0.9061 - val_loss: 0.1297 - val_acc: 0.9033\n",
      "Epoch 190/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1279 - acc: 0.9061 - val_loss: 0.1287 - val_acc: 0.9033\n",
      "Epoch 191/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1270 - acc: 0.9061 - val_loss: 0.1278 - val_acc: 0.9033\n",
      "Epoch 192/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1261 - acc: 0.9061 - val_loss: 0.1270 - val_acc: 0.9031\n",
      "Epoch 193/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1252 - acc: 0.9059 - val_loss: 0.1261 - val_acc: 0.9028\n",
      "Epoch 194/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1244 - acc: 0.9057 - val_loss: 0.1252 - val_acc: 0.9024\n",
      "Epoch 195/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1235 - acc: 0.9052 - val_loss: 0.1244 - val_acc: 0.9019\n",
      "Epoch 196/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1227 - acc: 0.9047 - val_loss: 0.1235 - val_acc: 0.9012\n",
      "Epoch 197/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1218 - acc: 0.9043 - val_loss: 0.1227 - val_acc: 0.9006\n",
      "Epoch 198/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1210 - acc: 0.9038 - val_loss: 0.1219 - val_acc: 0.9001\n",
      "Epoch 199/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1202 - acc: 0.9027 - val_loss: 0.1211 - val_acc: 0.8993\n",
      "Epoch 200/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1194 - acc: 0.9021 - val_loss: 0.1203 - val_acc: 0.8986\n",
      "Epoch 201/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1187 - acc: 0.9012 - val_loss: 0.1196 - val_acc: 0.8978\n",
      "Epoch 202/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1179 - acc: 0.9005 - val_loss: 0.1188 - val_acc: 0.8972\n",
      "Epoch 203/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1171 - acc: 0.8997 - val_loss: 0.1181 - val_acc: 0.8964\n",
      "Epoch 204/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1164 - acc: 0.8988 - val_loss: 0.1173 - val_acc: 0.8956\n",
      "Epoch 205/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1157 - acc: 0.8978 - val_loss: 0.1166 - val_acc: 0.8948\n",
      "Epoch 206/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1150 - acc: 0.8969 - val_loss: 0.1159 - val_acc: 0.8940\n",
      "Epoch 207/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1142 - acc: 0.8956 - val_loss: 0.1152 - val_acc: 0.8931\n",
      "Epoch 208/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1135 - acc: 0.8947 - val_loss: 0.1145 - val_acc: 0.8923\n",
      "Epoch 209/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1129 - acc: 0.8942 - val_loss: 0.1138 - val_acc: 0.8916\n",
      "Epoch 210/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1122 - acc: 0.8936 - val_loss: 0.1131 - val_acc: 0.8908\n",
      "Epoch 211/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1115 - acc: 0.8924 - val_loss: 0.1124 - val_acc: 0.8901\n",
      "Epoch 212/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1108 - acc: 0.8919 - val_loss: 0.1117 - val_acc: 0.8894\n",
      "Epoch 213/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1102 - acc: 0.8909 - val_loss: 0.1111 - val_acc: 0.8886\n",
      "Epoch 214/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1095 - acc: 0.8896 - val_loss: 0.1104 - val_acc: 0.8877\n",
      "Epoch 215/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1089 - acc: 0.8890 - val_loss: 0.1098 - val_acc: 0.8868\n",
      "Epoch 216/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1083 - acc: 0.8882 - val_loss: 0.1092 - val_acc: 0.8861\n",
      "Epoch 217/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1076 - acc: 0.8876 - val_loss: 0.1086 - val_acc: 0.8850\n",
      "Epoch 218/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1070 - acc: 0.8870 - val_loss: 0.1079 - val_acc: 0.8841\n",
      "Epoch 219/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1064 - acc: 0.8860 - val_loss: 0.1073 - val_acc: 0.8830\n",
      "Epoch 220/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1058 - acc: 0.8847 - val_loss: 0.1067 - val_acc: 0.8820\n",
      "Epoch 221/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1052 - acc: 0.8836 - val_loss: 0.1061 - val_acc: 0.8813\n",
      "Epoch 222/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1046 - acc: 0.8829 - val_loss: 0.1055 - val_acc: 0.8804\n",
      "Epoch 223/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1041 - acc: 0.8815 - val_loss: 0.1050 - val_acc: 0.8796\n",
      "Epoch 224/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1035 - acc: 0.8806 - val_loss: 0.1044 - val_acc: 0.8786\n",
      "Epoch 225/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1029 - acc: 0.8796 - val_loss: 0.1038 - val_acc: 0.8777\n",
      "Epoch 226/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1024 - acc: 0.8791 - val_loss: 0.1033 - val_acc: 0.8768\n",
      "Epoch 227/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1018 - acc: 0.8781 - val_loss: 0.1027 - val_acc: 0.8760\n",
      "Epoch 228/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1013 - acc: 0.8774 - val_loss: 0.1022 - val_acc: 0.8751\n",
      "Epoch 229/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1007 - acc: 0.8768 - val_loss: 0.1016 - val_acc: 0.8742\n",
      "Epoch 230/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.1002 - acc: 0.8762 - val_loss: 0.1011 - val_acc: 0.8734\n",
      "Epoch 231/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0997 - acc: 0.8757 - val_loss: 0.1006 - val_acc: 0.8726\n",
      "Epoch 232/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0992 - acc: 0.8749 - val_loss: 0.1000 - val_acc: 0.8718\n",
      "Epoch 233/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0986 - acc: 0.8740 - val_loss: 0.0995 - val_acc: 0.8709\n",
      "Epoch 234/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0981 - acc: 0.8734 - val_loss: 0.0990 - val_acc: 0.8703\n",
      "Epoch 235/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0976 - acc: 0.8728 - val_loss: 0.0985 - val_acc: 0.8694\n",
      "Epoch 236/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0971 - acc: 0.8724 - val_loss: 0.0980 - val_acc: 0.8687\n",
      "Epoch 237/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0966 - acc: 0.8715 - val_loss: 0.0975 - val_acc: 0.8678\n",
      "Epoch 238/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0961 - acc: 0.8710 - val_loss: 0.0970 - val_acc: 0.8673\n",
      "Epoch 239/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0956 - acc: 0.8702 - val_loss: 0.0965 - val_acc: 0.8668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0952 - acc: 0.8694 - val_loss: 0.0960 - val_acc: 0.8663\n",
      "Epoch 241/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0947 - acc: 0.8688 - val_loss: 0.0955 - val_acc: 0.8657\n",
      "Epoch 242/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0942 - acc: 0.8681 - val_loss: 0.0951 - val_acc: 0.8651\n",
      "Epoch 243/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0937 - acc: 0.8671 - val_loss: 0.0946 - val_acc: 0.8644\n",
      "Epoch 244/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0933 - acc: 0.8662 - val_loss: 0.0941 - val_acc: 0.8639\n",
      "Epoch 245/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0928 - acc: 0.8656 - val_loss: 0.0937 - val_acc: 0.8631\n",
      "Epoch 246/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0924 - acc: 0.8649 - val_loss: 0.0932 - val_acc: 0.8627\n",
      "Epoch 247/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0919 - acc: 0.8642 - val_loss: 0.0928 - val_acc: 0.8620\n",
      "Epoch 248/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0915 - acc: 0.8636 - val_loss: 0.0923 - val_acc: 0.8617\n",
      "Epoch 249/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0910 - acc: 0.8631 - val_loss: 0.0919 - val_acc: 0.8611\n",
      "Epoch 250/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0906 - acc: 0.8624 - val_loss: 0.0914 - val_acc: 0.8607\n",
      "Epoch 251/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0901 - acc: 0.8622 - val_loss: 0.0910 - val_acc: 0.8598\n",
      "Epoch 252/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0897 - acc: 0.8618 - val_loss: 0.0906 - val_acc: 0.8596\n",
      "Epoch 253/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0893 - acc: 0.8614 - val_loss: 0.0901 - val_acc: 0.8586\n",
      "Epoch 254/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0889 - acc: 0.8605 - val_loss: 0.0897 - val_acc: 0.8585\n",
      "Epoch 255/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0885 - acc: 0.8604 - val_loss: 0.0893 - val_acc: 0.8575\n",
      "Epoch 256/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0880 - acc: 0.8592 - val_loss: 0.0889 - val_acc: 0.8577\n",
      "Epoch 257/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0876 - acc: 0.8596 - val_loss: 0.0885 - val_acc: 0.8560\n",
      "Epoch 258/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0872 - acc: 0.8581 - val_loss: 0.0881 - val_acc: 0.8571\n",
      "Epoch 259/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0868 - acc: 0.8589 - val_loss: 0.0877 - val_acc: 0.8546\n",
      "Epoch 260/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0864 - acc: 0.8562 - val_loss: 0.0873 - val_acc: 0.8565\n",
      "Epoch 261/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0860 - acc: 0.8585 - val_loss: 0.0869 - val_acc: 0.8530\n",
      "Epoch 262/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0857 - acc: 0.8542 - val_loss: 0.0865 - val_acc: 0.8564\n",
      "Epoch 263/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0853 - acc: 0.8586 - val_loss: 0.0861 - val_acc: 0.8508\n",
      "Epoch 264/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0849 - acc: 0.8525 - val_loss: 0.0858 - val_acc: 0.8573\n",
      "Epoch 265/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0846 - acc: 0.8589 - val_loss: 0.0855 - val_acc: 0.8473\n",
      "Epoch 266/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0843 - acc: 0.8488 - val_loss: 0.0853 - val_acc: 0.8598\n",
      "Epoch 267/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0841 - acc: 0.8614 - val_loss: 0.0852 - val_acc: 0.8414\n",
      "Epoch 268/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0840 - acc: 0.8424 - val_loss: 0.0852 - val_acc: 0.8645\n",
      "Epoch 269/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0841 - acc: 0.8661 - val_loss: 0.0856 - val_acc: 0.8331\n",
      "Epoch 270/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0844 - acc: 0.8327 - val_loss: 0.0857 - val_acc: 0.8685\n",
      "Epoch 271/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0845 - acc: 0.8714 - val_loss: 0.0859 - val_acc: 0.8280\n",
      "Epoch 272/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0846 - acc: 0.8274 - val_loss: 0.0851 - val_acc: 0.8685\n",
      "Epoch 273/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0839 - acc: 0.8713 - val_loss: 0.0846 - val_acc: 0.8302\n",
      "Epoch 274/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0833 - acc: 0.8295 - val_loss: 0.0835 - val_acc: 0.8645\n",
      "Epoch 275/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0824 - acc: 0.8661 - val_loss: 0.0829 - val_acc: 0.8357\n",
      "Epoch 276/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0817 - acc: 0.8358 - val_loss: 0.0822 - val_acc: 0.8591\n",
      "Epoch 277/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0810 - acc: 0.8606 - val_loss: 0.0817 - val_acc: 0.8400\n",
      "Epoch 278/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0805 - acc: 0.8408 - val_loss: 0.0812 - val_acc: 0.8552\n",
      "Epoch 279/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0801 - acc: 0.8568 - val_loss: 0.0808 - val_acc: 0.8426\n",
      "Epoch 280/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0797 - acc: 0.8430 - val_loss: 0.0804 - val_acc: 0.8525\n",
      "Epoch 281/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0793 - acc: 0.8538 - val_loss: 0.0801 - val_acc: 0.8441\n",
      "Epoch 282/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0790 - acc: 0.8449 - val_loss: 0.0798 - val_acc: 0.8508\n",
      "Epoch 283/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0787 - acc: 0.8521 - val_loss: 0.0795 - val_acc: 0.8448\n",
      "Epoch 284/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0784 - acc: 0.8458 - val_loss: 0.0792 - val_acc: 0.8494\n",
      "Epoch 285/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0781 - acc: 0.8508 - val_loss: 0.0789 - val_acc: 0.8449\n",
      "Epoch 286/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0778 - acc: 0.8462 - val_loss: 0.0786 - val_acc: 0.8483\n",
      "Epoch 287/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0775 - acc: 0.8493 - val_loss: 0.0783 - val_acc: 0.8451\n",
      "Epoch 288/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0772 - acc: 0.8463 - val_loss: 0.0780 - val_acc: 0.8476\n",
      "Epoch 289/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0769 - acc: 0.8490 - val_loss: 0.0777 - val_acc: 0.8450\n",
      "Epoch 290/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0766 - acc: 0.8459 - val_loss: 0.0774 - val_acc: 0.8470\n",
      "Epoch 291/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0764 - acc: 0.8487 - val_loss: 0.0772 - val_acc: 0.8449\n",
      "Epoch 292/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0761 - acc: 0.8457 - val_loss: 0.0769 - val_acc: 0.8466\n",
      "Epoch 293/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0758 - acc: 0.8476 - val_loss: 0.0766 - val_acc: 0.8445\n",
      "Epoch 294/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0755 - acc: 0.8457 - val_loss: 0.0763 - val_acc: 0.8460\n",
      "Epoch 295/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0753 - acc: 0.8474 - val_loss: 0.0760 - val_acc: 0.8444\n",
      "Epoch 296/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0750 - acc: 0.8451 - val_loss: 0.0758 - val_acc: 0.8457\n",
      "Epoch 297/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0747 - acc: 0.8470 - val_loss: 0.0755 - val_acc: 0.8441\n",
      "Epoch 298/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0744 - acc: 0.8453 - val_loss: 0.0752 - val_acc: 0.8454\n",
      "Epoch 299/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0742 - acc: 0.8466 - val_loss: 0.0750 - val_acc: 0.8438\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0739 - acc: 0.8440 - val_loss: 0.0747 - val_acc: 0.8452\n",
      "3000/3000 [==============================] - 0s 27us/step\n",
      "['loss', 'acc'] [0.0736976805528005, 0.8559999998410542]\n",
      "[[0.66108923 0.95594316]] [[3.2678074e-07 9.9999118e-01 9.9999392e-01]]\n"
     ]
    }
   ],
   "source": [
    "model = multi_label_learning_demo(mask_value=None, is_FocalLoss_multilabel=False)\n",
    "x = np.random.rand(1,2)\n",
    "print(x, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid +  binary_Focal_Loss使用\n",
    "- うまくいってて、精度上がってる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid\n",
      "(100000, 3) [[0. 1. 1.]\n",
      " [0. 1. 1.]\n",
      " [0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 1. 0.]]\n",
      "0.0    95031\n",
      "1.0     4969\n",
      "dtype: int64\n",
      "1.0    95109\n",
      "0.0     4891\n",
      "dtype: int64\n",
      "1.0    50034\n",
      "0.0    49966\n",
      "dtype: int64\n",
      "input_dim, nb_classes: 2 3\n",
      "Train on 9700 samples, validate on 87300 samples\n",
      "Epoch 1/300\n",
      "9700/9700 [==============================] - 0s 17us/step - loss: 0.0795 - acc: 0.2948 - val_loss: 0.0776 - val_acc: 0.2901\n",
      "Epoch 2/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0778 - acc: 0.2943 - val_loss: 0.0766 - val_acc: 0.3277\n",
      "Epoch 3/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0768 - acc: 0.3330 - val_loss: 0.0756 - val_acc: 0.3853\n",
      "Epoch 4/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0758 - acc: 0.3901 - val_loss: 0.0747 - val_acc: 0.4740\n",
      "Epoch 5/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0749 - acc: 0.4822 - val_loss: 0.0738 - val_acc: 0.6113\n",
      "Epoch 6/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0739 - acc: 0.6137 - val_loss: 0.0728 - val_acc: 0.7735\n",
      "Epoch 7/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0730 - acc: 0.7784 - val_loss: 0.0718 - val_acc: 0.8868\n",
      "Epoch 8/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0720 - acc: 0.8898 - val_loss: 0.0708 - val_acc: 0.9033\n",
      "Epoch 9/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0710 - acc: 0.9061 - val_loss: 0.0698 - val_acc: 0.9033\n",
      "Epoch 10/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0699 - acc: 0.9061 - val_loss: 0.0687 - val_acc: 0.9033\n",
      "Epoch 11/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0689 - acc: 0.9061 - val_loss: 0.0677 - val_acc: 0.9033\n",
      "Epoch 12/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0678 - acc: 0.9061 - val_loss: 0.0666 - val_acc: 0.9033\n",
      "Epoch 13/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0667 - acc: 0.9061 - val_loss: 0.0654 - val_acc: 0.9033\n",
      "Epoch 14/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0656 - acc: 0.9061 - val_loss: 0.0643 - val_acc: 0.9033\n",
      "Epoch 15/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0644 - acc: 0.9061 - val_loss: 0.0632 - val_acc: 0.9033\n",
      "Epoch 16/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0633 - acc: 0.9061 - val_loss: 0.0620 - val_acc: 0.9033\n",
      "Epoch 17/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0621 - acc: 0.9061 - val_loss: 0.0609 - val_acc: 0.9033\n",
      "Epoch 18/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0610 - acc: 0.9061 - val_loss: 0.0598 - val_acc: 0.9033\n",
      "Epoch 19/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0598 - acc: 0.9061 - val_loss: 0.0587 - val_acc: 0.9033\n",
      "Epoch 20/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0587 - acc: 0.9061 - val_loss: 0.0576 - val_acc: 0.9033\n",
      "Epoch 21/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0576 - acc: 0.9061 - val_loss: 0.0565 - val_acc: 0.9033\n",
      "Epoch 22/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0565 - acc: 0.9061 - val_loss: 0.0555 - val_acc: 0.9033\n",
      "Epoch 23/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0555 - acc: 0.9061 - val_loss: 0.0545 - val_acc: 0.9033\n",
      "Epoch 24/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0545 - acc: 0.9061 - val_loss: 0.0535 - val_acc: 0.9033\n",
      "Epoch 25/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0535 - acc: 0.9061 - val_loss: 0.0525 - val_acc: 0.9033\n",
      "Epoch 26/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0525 - acc: 0.9061 - val_loss: 0.0516 - val_acc: 0.9033\n",
      "Epoch 27/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0516 - acc: 0.9061 - val_loss: 0.0507 - val_acc: 0.9033\n",
      "Epoch 28/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0507 - acc: 0.9061 - val_loss: 0.0498 - val_acc: 0.9033\n",
      "Epoch 29/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0498 - acc: 0.9061 - val_loss: 0.0490 - val_acc: 0.9033\n",
      "Epoch 30/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0489 - acc: 0.9061 - val_loss: 0.0482 - val_acc: 0.9033\n",
      "Epoch 31/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0481 - acc: 0.9061 - val_loss: 0.0474 - val_acc: 0.9033\n",
      "Epoch 32/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0473 - acc: 0.9061 - val_loss: 0.0466 - val_acc: 0.9033\n",
      "Epoch 33/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0465 - acc: 0.9061 - val_loss: 0.0458 - val_acc: 0.9033\n",
      "Epoch 34/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0458 - acc: 0.9061 - val_loss: 0.0451 - val_acc: 0.9033\n",
      "Epoch 35/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0450 - acc: 0.9061 - val_loss: 0.0444 - val_acc: 0.9033\n",
      "Epoch 36/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0443 - acc: 0.9061 - val_loss: 0.0437 - val_acc: 0.9033\n",
      "Epoch 37/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0436 - acc: 0.9061 - val_loss: 0.0430 - val_acc: 0.9033\n",
      "Epoch 38/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0429 - acc: 0.9061 - val_loss: 0.0423 - val_acc: 0.9033\n",
      "Epoch 39/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0422 - acc: 0.9061 - val_loss: 0.0417 - val_acc: 0.9033\n",
      "Epoch 40/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0416 - acc: 0.9061 - val_loss: 0.0412 - val_acc: 0.9033\n",
      "Epoch 41/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0410 - acc: 0.9061 - val_loss: 0.0407 - val_acc: 0.9033\n",
      "Epoch 42/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0405 - acc: 0.9061 - val_loss: 0.0402 - val_acc: 0.9033\n",
      "Epoch 43/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0400 - acc: 0.9061 - val_loss: 0.0398 - val_acc: 0.9033\n",
      "Epoch 44/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0396 - acc: 0.9061 - val_loss: 0.0394 - val_acc: 0.9033\n",
      "Epoch 45/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0392 - acc: 0.9061 - val_loss: 0.0390 - val_acc: 0.9033\n",
      "Epoch 46/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0388 - acc: 0.9061 - val_loss: 0.0387 - val_acc: 0.9033\n",
      "Epoch 47/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0385 - acc: 0.9061 - val_loss: 0.0384 - val_acc: 0.9033\n",
      "Epoch 48/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0381 - acc: 0.9061 - val_loss: 0.0381 - val_acc: 0.9033\n",
      "Epoch 49/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0378 - acc: 0.9061 - val_loss: 0.0378 - val_acc: 0.9033\n",
      "Epoch 50/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0376 - acc: 0.9061 - val_loss: 0.0375 - val_acc: 0.9033\n",
      "Epoch 51/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0373 - acc: 0.9061 - val_loss: 0.0373 - val_acc: 0.9033\n",
      "Epoch 52/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0370 - acc: 0.9061 - val_loss: 0.0370 - val_acc: 0.9033\n",
      "Epoch 53/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0368 - acc: 0.9061 - val_loss: 0.0368 - val_acc: 0.9033\n",
      "Epoch 54/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0365 - acc: 0.9061 - val_loss: 0.0366 - val_acc: 0.9033\n",
      "Epoch 55/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0363 - acc: 0.9061 - val_loss: 0.0363 - val_acc: 0.9033\n",
      "Epoch 56/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0361 - acc: 0.9061 - val_loss: 0.0361 - val_acc: 0.9033\n",
      "Epoch 57/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0359 - acc: 0.9061 - val_loss: 0.0359 - val_acc: 0.9033\n",
      "Epoch 58/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0356 - acc: 0.9061 - val_loss: 0.0357 - val_acc: 0.9033\n",
      "Epoch 59/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0354 - acc: 0.9061 - val_loss: 0.0355 - val_acc: 0.9033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0352 - acc: 0.9061 - val_loss: 0.0353 - val_acc: 0.9033\n",
      "Epoch 61/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0350 - acc: 0.9061 - val_loss: 0.0350 - val_acc: 0.9033\n",
      "Epoch 62/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0347 - acc: 0.9061 - val_loss: 0.0347 - val_acc: 0.9033\n",
      "Epoch 63/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0345 - acc: 0.9061 - val_loss: 0.0345 - val_acc: 0.9033\n",
      "Epoch 64/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0342 - acc: 0.9061 - val_loss: 0.0342 - val_acc: 0.9033\n",
      "Epoch 65/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0340 - acc: 0.9061 - val_loss: 0.0340 - val_acc: 0.9033\n",
      "Epoch 66/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0337 - acc: 0.9061 - val_loss: 0.0337 - val_acc: 0.9033\n",
      "Epoch 67/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0335 - acc: 0.9061 - val_loss: 0.0335 - val_acc: 0.9033\n",
      "Epoch 68/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0332 - acc: 0.9061 - val_loss: 0.0332 - val_acc: 0.9033\n",
      "Epoch 69/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0329 - acc: 0.9061 - val_loss: 0.0329 - val_acc: 0.9033\n",
      "Epoch 70/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0327 - acc: 0.9061 - val_loss: 0.0326 - val_acc: 0.9033\n",
      "Epoch 71/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0324 - acc: 0.9061 - val_loss: 0.0324 - val_acc: 0.9033\n",
      "Epoch 72/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0321 - acc: 0.9061 - val_loss: 0.0321 - val_acc: 0.9033\n",
      "Epoch 73/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0318 - acc: 0.9061 - val_loss: 0.0318 - val_acc: 0.9033\n",
      "Epoch 74/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0316 - acc: 0.9061 - val_loss: 0.0315 - val_acc: 0.9033\n",
      "Epoch 75/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0313 - acc: 0.9061 - val_loss: 0.0312 - val_acc: 0.9033\n",
      "Epoch 76/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0310 - acc: 0.9061 - val_loss: 0.0309 - val_acc: 0.9033\n",
      "Epoch 77/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0307 - acc: 0.9061 - val_loss: 0.0306 - val_acc: 0.9033\n",
      "Epoch 78/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0304 - acc: 0.9061 - val_loss: 0.0304 - val_acc: 0.9033\n",
      "Epoch 79/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0301 - acc: 0.9061 - val_loss: 0.0301 - val_acc: 0.9033\n",
      "Epoch 80/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0298 - acc: 0.9061 - val_loss: 0.0298 - val_acc: 0.9033\n",
      "Epoch 81/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0296 - acc: 0.9061 - val_loss: 0.0295 - val_acc: 0.9033\n",
      "Epoch 82/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0293 - acc: 0.9061 - val_loss: 0.0292 - val_acc: 0.9033\n",
      "Epoch 83/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0290 - acc: 0.9061 - val_loss: 0.0289 - val_acc: 0.9033\n",
      "Epoch 84/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0287 - acc: 0.9061 - val_loss: 0.0286 - val_acc: 0.9033\n",
      "Epoch 85/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0284 - acc: 0.9061 - val_loss: 0.0283 - val_acc: 0.9033\n",
      "Epoch 86/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0281 - acc: 0.9061 - val_loss: 0.0280 - val_acc: 0.9033\n",
      "Epoch 87/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0278 - acc: 0.9061 - val_loss: 0.0277 - val_acc: 0.9033\n",
      "Epoch 88/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0275 - acc: 0.9061 - val_loss: 0.0274 - val_acc: 0.9033\n",
      "Epoch 89/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0272 - acc: 0.9061 - val_loss: 0.0271 - val_acc: 0.9033\n",
      "Epoch 90/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0269 - acc: 0.9061 - val_loss: 0.0268 - val_acc: 0.9033\n",
      "Epoch 91/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0266 - acc: 0.9061 - val_loss: 0.0265 - val_acc: 0.9033\n",
      "Epoch 92/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0263 - acc: 0.9061 - val_loss: 0.0262 - val_acc: 0.9033\n",
      "Epoch 93/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0260 - acc: 0.9061 - val_loss: 0.0259 - val_acc: 0.9033\n",
      "Epoch 94/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0257 - acc: 0.9061 - val_loss: 0.0257 - val_acc: 0.9033\n",
      "Epoch 95/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0255 - acc: 0.9061 - val_loss: 0.0254 - val_acc: 0.9033\n",
      "Epoch 96/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0252 - acc: 0.9061 - val_loss: 0.0251 - val_acc: 0.9033\n",
      "Epoch 97/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0249 - acc: 0.9061 - val_loss: 0.0248 - val_acc: 0.9033\n",
      "Epoch 98/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0246 - acc: 0.9061 - val_loss: 0.0245 - val_acc: 0.9033\n",
      "Epoch 99/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0243 - acc: 0.9061 - val_loss: 0.0243 - val_acc: 0.9033\n",
      "Epoch 100/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0241 - acc: 0.9061 - val_loss: 0.0240 - val_acc: 0.9033\n",
      "Epoch 101/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0238 - acc: 0.9061 - val_loss: 0.0237 - val_acc: 0.9033\n",
      "Epoch 102/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0235 - acc: 0.9061 - val_loss: 0.0235 - val_acc: 0.9033\n",
      "Epoch 103/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0233 - acc: 0.9061 - val_loss: 0.0232 - val_acc: 0.9033\n",
      "Epoch 104/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0230 - acc: 0.9061 - val_loss: 0.0230 - val_acc: 0.9033\n",
      "Epoch 105/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0228 - acc: 0.9061 - val_loss: 0.0227 - val_acc: 0.9033\n",
      "Epoch 106/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0225 - acc: 0.9061 - val_loss: 0.0225 - val_acc: 0.9033\n",
      "Epoch 107/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0223 - acc: 0.9061 - val_loss: 0.0223 - val_acc: 0.9033\n",
      "Epoch 108/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0221 - acc: 0.9061 - val_loss: 0.0220 - val_acc: 0.9033\n",
      "Epoch 109/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0218 - acc: 0.9061 - val_loss: 0.0218 - val_acc: 0.9033\n",
      "Epoch 110/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0216 - acc: 0.9061 - val_loss: 0.0216 - val_acc: 0.9033\n",
      "Epoch 111/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0214 - acc: 0.9061 - val_loss: 0.0214 - val_acc: 0.9033\n",
      "Epoch 112/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0212 - acc: 0.9061 - val_loss: 0.0211 - val_acc: 0.9033\n",
      "Epoch 113/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0209 - acc: 0.9061 - val_loss: 0.0209 - val_acc: 0.9033\n",
      "Epoch 114/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0207 - acc: 0.9061 - val_loss: 0.0207 - val_acc: 0.9033\n",
      "Epoch 115/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0205 - acc: 0.9061 - val_loss: 0.0205 - val_acc: 0.9033\n",
      "Epoch 116/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0203 - acc: 0.9061 - val_loss: 0.0203 - val_acc: 0.9033\n",
      "Epoch 117/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0201 - acc: 0.9061 - val_loss: 0.0201 - val_acc: 0.9033\n",
      "Epoch 118/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0199 - acc: 0.9061 - val_loss: 0.0199 - val_acc: 0.9033\n",
      "Epoch 119/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0197 - acc: 0.9061 - val_loss: 0.0197 - val_acc: 0.9033\n",
      "Epoch 120/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0195 - acc: 0.9061 - val_loss: 0.0195 - val_acc: 0.9033\n",
      "Epoch 121/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0193 - acc: 0.9061 - val_loss: 0.0193 - val_acc: 0.9033\n",
      "Epoch 122/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0191 - acc: 0.9061 - val_loss: 0.0191 - val_acc: 0.9033\n",
      "Epoch 123/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0189 - acc: 0.9061 - val_loss: 0.0189 - val_acc: 0.9033\n",
      "Epoch 124/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0187 - acc: 0.9061 - val_loss: 0.0187 - val_acc: 0.9033\n",
      "Epoch 125/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0185 - acc: 0.9061 - val_loss: 0.0185 - val_acc: 0.9033\n",
      "Epoch 126/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0183 - acc: 0.9061 - val_loss: 0.0184 - val_acc: 0.9033\n",
      "Epoch 127/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0182 - acc: 0.9061 - val_loss: 0.0182 - val_acc: 0.9033\n",
      "Epoch 128/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0180 - acc: 0.9061 - val_loss: 0.0180 - val_acc: 0.9033\n",
      "Epoch 129/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0179 - acc: 0.9061 - val_loss: 0.0179 - val_acc: 0.9033\n",
      "Epoch 130/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0177 - acc: 0.9061 - val_loss: 0.0177 - val_acc: 0.9033\n",
      "Epoch 131/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0175 - acc: 0.9061 - val_loss: 0.0176 - val_acc: 0.9033\n",
      "Epoch 132/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0174 - acc: 0.9061 - val_loss: 0.0174 - val_acc: 0.9033\n",
      "Epoch 133/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0173 - acc: 0.9061 - val_loss: 0.0173 - val_acc: 0.9033\n",
      "Epoch 134/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0171 - acc: 0.9061 - val_loss: 0.0172 - val_acc: 0.9033\n",
      "Epoch 135/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0170 - acc: 0.9061 - val_loss: 0.0170 - val_acc: 0.9033\n",
      "Epoch 136/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0168 - acc: 0.9061 - val_loss: 0.0169 - val_acc: 0.9033\n",
      "Epoch 137/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0167 - acc: 0.9061 - val_loss: 0.0168 - val_acc: 0.9033\n",
      "Epoch 138/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0166 - acc: 0.9061 - val_loss: 0.0166 - val_acc: 0.9033\n",
      "Epoch 139/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0165 - acc: 0.9061 - val_loss: 0.0165 - val_acc: 0.9033\n",
      "Epoch 140/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0163 - acc: 0.9061 - val_loss: 0.0164 - val_acc: 0.9033\n",
      "Epoch 141/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0162 - acc: 0.9061 - val_loss: 0.0163 - val_acc: 0.9033\n",
      "Epoch 142/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0161 - acc: 0.9061 - val_loss: 0.0162 - val_acc: 0.9033\n",
      "Epoch 143/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0160 - acc: 0.9061 - val_loss: 0.0161 - val_acc: 0.9033\n",
      "Epoch 144/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0159 - acc: 0.9061 - val_loss: 0.0159 - val_acc: 0.9033\n",
      "Epoch 145/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0158 - acc: 0.9061 - val_loss: 0.0158 - val_acc: 0.9033\n",
      "Epoch 146/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0156 - acc: 0.9061 - val_loss: 0.0157 - val_acc: 0.9033\n",
      "Epoch 147/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0155 - acc: 0.9061 - val_loss: 0.0156 - val_acc: 0.9033\n",
      "Epoch 148/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0154 - acc: 0.9061 - val_loss: 0.0155 - val_acc: 0.9033\n",
      "Epoch 149/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0153 - acc: 0.9061 - val_loss: 0.0154 - val_acc: 0.9033\n",
      "Epoch 150/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0152 - acc: 0.9061 - val_loss: 0.0153 - val_acc: 0.9033\n",
      "Epoch 151/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0151 - acc: 0.9061 - val_loss: 0.0152 - val_acc: 0.9033\n",
      "Epoch 152/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0150 - acc: 0.9061 - val_loss: 0.0151 - val_acc: 0.9033\n",
      "Epoch 153/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0149 - acc: 0.9061 - val_loss: 0.0150 - val_acc: 0.9033\n",
      "Epoch 154/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0148 - acc: 0.9061 - val_loss: 0.0149 - val_acc: 0.9033\n",
      "Epoch 155/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0148 - acc: 0.9061 - val_loss: 0.0149 - val_acc: 0.9033\n",
      "Epoch 156/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0147 - acc: 0.9061 - val_loss: 0.0148 - val_acc: 0.9033\n",
      "Epoch 157/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0146 - acc: 0.9061 - val_loss: 0.0147 - val_acc: 0.9033\n",
      "Epoch 158/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0145 - acc: 0.9061 - val_loss: 0.0146 - val_acc: 0.9033\n",
      "Epoch 159/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0144 - acc: 0.9061 - val_loss: 0.0145 - val_acc: 0.9033\n",
      "Epoch 160/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0143 - acc: 0.9061 - val_loss: 0.0144 - val_acc: 0.9033\n",
      "Epoch 161/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0142 - acc: 0.9061 - val_loss: 0.0143 - val_acc: 0.9033\n",
      "Epoch 162/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0141 - acc: 0.9061 - val_loss: 0.0142 - val_acc: 0.9033\n",
      "Epoch 163/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0141 - acc: 0.9061 - val_loss: 0.0142 - val_acc: 0.9033\n",
      "Epoch 164/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0140 - acc: 0.9061 - val_loss: 0.0141 - val_acc: 0.9033\n",
      "Epoch 165/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0139 - acc: 0.9061 - val_loss: 0.0140 - val_acc: 0.9033\n",
      "Epoch 166/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0138 - acc: 0.9061 - val_loss: 0.0139 - val_acc: 0.9033\n",
      "Epoch 167/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0137 - acc: 0.9061 - val_loss: 0.0138 - val_acc: 0.9033\n",
      "Epoch 168/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0136 - acc: 0.9061 - val_loss: 0.0137 - val_acc: 0.9033\n",
      "Epoch 169/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0136 - acc: 0.9061 - val_loss: 0.0137 - val_acc: 0.9033\n",
      "Epoch 170/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0135 - acc: 0.9061 - val_loss: 0.0136 - val_acc: 0.9033\n",
      "Epoch 171/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0134 - acc: 0.9061 - val_loss: 0.0135 - val_acc: 0.9033\n",
      "Epoch 172/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0133 - acc: 0.9061 - val_loss: 0.0134 - val_acc: 0.9033\n",
      "Epoch 173/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0132 - acc: 0.9061 - val_loss: 0.0133 - val_acc: 0.9033\n",
      "Epoch 174/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0132 - acc: 0.9061 - val_loss: 0.0133 - val_acc: 0.9033\n",
      "Epoch 175/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0131 - acc: 0.9061 - val_loss: 0.0132 - val_acc: 0.9033\n",
      "Epoch 176/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0130 - acc: 0.9061 - val_loss: 0.0131 - val_acc: 0.9033\n",
      "Epoch 177/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0129 - acc: 0.9061 - val_loss: 0.0130 - val_acc: 0.9033\n",
      "Epoch 178/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0128 - acc: 0.9061 - val_loss: 0.0129 - val_acc: 0.9033\n",
      "Epoch 179/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0127 - acc: 0.9061 - val_loss: 0.0128 - val_acc: 0.9033\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 180/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0126 - acc: 0.9061 - val_loss: 0.0127 - val_acc: 0.9033\n",
      "Epoch 181/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0125 - acc: 0.9061 - val_loss: 0.0126 - val_acc: 0.9033\n",
      "Epoch 182/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0124 - acc: 0.9061 - val_loss: 0.0125 - val_acc: 0.9033\n",
      "Epoch 183/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0124 - acc: 0.9061 - val_loss: 0.0124 - val_acc: 0.9033\n",
      "Epoch 184/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0123 - acc: 0.9061 - val_loss: 0.0123 - val_acc: 0.9033\n",
      "Epoch 185/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0122 - acc: 0.9061 - val_loss: 0.0123 - val_acc: 0.9033\n",
      "Epoch 186/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0121 - acc: 0.9061 - val_loss: 0.0122 - val_acc: 0.9033\n",
      "Epoch 187/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0120 - acc: 0.9061 - val_loss: 0.0121 - val_acc: 0.9033\n",
      "Epoch 188/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0119 - acc: 0.9061 - val_loss: 0.0120 - val_acc: 0.9033\n",
      "Epoch 189/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0118 - acc: 0.9061 - val_loss: 0.0119 - val_acc: 0.9033\n",
      "Epoch 190/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0118 - acc: 0.9061 - val_loss: 0.0118 - val_acc: 0.9033\n",
      "Epoch 191/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0117 - acc: 0.9061 - val_loss: 0.0117 - val_acc: 0.9033\n",
      "Epoch 192/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0116 - acc: 0.9061 - val_loss: 0.0117 - val_acc: 0.9033\n",
      "Epoch 193/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0115 - acc: 0.9061 - val_loss: 0.0116 - val_acc: 0.9033\n",
      "Epoch 194/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0114 - acc: 0.9061 - val_loss: 0.0115 - val_acc: 0.9033\n",
      "Epoch 195/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0114 - acc: 0.9061 - val_loss: 0.0114 - val_acc: 0.9033\n",
      "Epoch 196/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0113 - acc: 0.9061 - val_loss: 0.0113 - val_acc: 0.9033\n",
      "Epoch 197/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0112 - acc: 0.9061 - val_loss: 0.0113 - val_acc: 0.9033\n",
      "Epoch 198/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0111 - acc: 0.9061 - val_loss: 0.0112 - val_acc: 0.9033\n",
      "Epoch 199/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0111 - acc: 0.9061 - val_loss: 0.0112 - val_acc: 0.9033\n",
      "Epoch 200/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0110 - acc: 0.9061 - val_loss: 0.0111 - val_acc: 0.9033\n",
      "Epoch 201/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0110 - acc: 0.9061 - val_loss: 0.0111 - val_acc: 0.9032\n",
      "Epoch 202/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0109 - acc: 0.9059 - val_loss: 0.0110 - val_acc: 0.9033\n",
      "Epoch 203/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0109 - acc: 0.9061 - val_loss: 0.0109 - val_acc: 0.9030\n",
      "Epoch 204/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0108 - acc: 0.9058 - val_loss: 0.0109 - val_acc: 0.9033\n",
      "Epoch 205/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0107 - acc: 0.9061 - val_loss: 0.0108 - val_acc: 0.9030\n",
      "Epoch 206/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0106 - acc: 0.9058 - val_loss: 0.0107 - val_acc: 0.9033\n",
      "Epoch 207/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0106 - acc: 0.9061 - val_loss: 0.0106 - val_acc: 0.9030\n",
      "Epoch 208/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0105 - acc: 0.9059 - val_loss: 0.0105 - val_acc: 0.9033\n",
      "Epoch 209/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0104 - acc: 0.9061 - val_loss: 0.0105 - val_acc: 0.9030\n",
      "Epoch 210/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0103 - acc: 0.9059 - val_loss: 0.0104 - val_acc: 0.9033\n",
      "Epoch 211/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0103 - acc: 0.9061 - val_loss: 0.0103 - val_acc: 0.9030\n",
      "Epoch 212/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0102 - acc: 0.9059 - val_loss: 0.0103 - val_acc: 0.9033\n",
      "Epoch 213/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0102 - acc: 0.9061 - val_loss: 0.0102 - val_acc: 0.9029\n",
      "Epoch 214/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0101 - acc: 0.9059 - val_loss: 0.0102 - val_acc: 0.9033\n",
      "Epoch 215/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0100 - acc: 0.9061 - val_loss: 0.0101 - val_acc: 0.9028\n",
      "Epoch 216/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0100 - acc: 0.9057 - val_loss: 0.0100 - val_acc: 0.9032\n",
      "Epoch 217/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0099 - acc: 0.9061 - val_loss: 0.0100 - val_acc: 0.9026\n",
      "Epoch 218/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0099 - acc: 0.9054 - val_loss: 0.0099 - val_acc: 0.9031\n",
      "Epoch 219/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0098 - acc: 0.9059 - val_loss: 0.0099 - val_acc: 0.9025\n",
      "Epoch 220/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0097 - acc: 0.9052 - val_loss: 0.0098 - val_acc: 0.9029\n",
      "Epoch 221/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0097 - acc: 0.9059 - val_loss: 0.0098 - val_acc: 0.9022\n",
      "Epoch 222/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0096 - acc: 0.9052 - val_loss: 0.0097 - val_acc: 0.9028\n",
      "Epoch 223/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0096 - acc: 0.9057 - val_loss: 0.0096 - val_acc: 0.9021\n",
      "Epoch 224/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0095 - acc: 0.9048 - val_loss: 0.0096 - val_acc: 0.9027\n",
      "Epoch 225/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0095 - acc: 0.9055 - val_loss: 0.0095 - val_acc: 0.9019\n",
      "Epoch 226/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0094 - acc: 0.9047 - val_loss: 0.0095 - val_acc: 0.9027\n",
      "Epoch 227/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0094 - acc: 0.9055 - val_loss: 0.0094 - val_acc: 0.9018\n",
      "Epoch 228/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0093 - acc: 0.9046 - val_loss: 0.0094 - val_acc: 0.9026\n",
      "Epoch 229/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0093 - acc: 0.9055 - val_loss: 0.0093 - val_acc: 0.9017\n",
      "Epoch 230/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0092 - acc: 0.9045 - val_loss: 0.0093 - val_acc: 0.9026\n",
      "Epoch 231/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0092 - acc: 0.9055 - val_loss: 0.0092 - val_acc: 0.9016\n",
      "Epoch 232/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0091 - acc: 0.9044 - val_loss: 0.0092 - val_acc: 0.9026\n",
      "Epoch 233/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0091 - acc: 0.9055 - val_loss: 0.0091 - val_acc: 0.9015\n",
      "Epoch 234/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0090 - acc: 0.9044 - val_loss: 0.0091 - val_acc: 0.9027\n",
      "Epoch 235/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0090 - acc: 0.9055 - val_loss: 0.0090 - val_acc: 0.9013\n",
      "Epoch 236/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.9043 - val_loss: 0.0090 - val_acc: 0.9027\n",
      "Epoch 237/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.9055 - val_loss: 0.0089 - val_acc: 0.9010\n",
      "Epoch 238/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0088 - acc: 0.9040 - val_loss: 0.0089 - val_acc: 0.9028\n",
      "Epoch 239/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0088 - acc: 0.9055 - val_loss: 0.0089 - val_acc: 0.9007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 240/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0088 - acc: 0.9038 - val_loss: 0.0088 - val_acc: 0.9030\n",
      "Epoch 241/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0087 - acc: 0.9057 - val_loss: 0.0088 - val_acc: 0.9000\n",
      "Epoch 242/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0087 - acc: 0.9027 - val_loss: 0.0088 - val_acc: 0.9031\n",
      "Epoch 243/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0087 - acc: 0.9059 - val_loss: 0.0087 - val_acc: 0.8995\n",
      "Epoch 244/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0086 - acc: 0.9020 - val_loss: 0.0087 - val_acc: 0.9032\n",
      "Epoch 245/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0086 - acc: 0.9059 - val_loss: 0.0087 - val_acc: 0.8991\n",
      "Epoch 246/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0086 - acc: 0.9014 - val_loss: 0.0086 - val_acc: 0.9033\n",
      "Epoch 247/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0085 - acc: 0.9061 - val_loss: 0.0086 - val_acc: 0.8989\n",
      "Epoch 248/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0085 - acc: 0.9012 - val_loss: 0.0086 - val_acc: 0.9033\n",
      "Epoch 249/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0085 - acc: 0.9061 - val_loss: 0.0085 - val_acc: 0.8992\n",
      "Epoch 250/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0084 - acc: 0.9016 - val_loss: 0.0085 - val_acc: 0.9033\n",
      "Epoch 251/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0084 - acc: 0.9061 - val_loss: 0.0084 - val_acc: 0.8997\n",
      "Epoch 252/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0083 - acc: 0.9027 - val_loss: 0.0084 - val_acc: 0.9032\n",
      "Epoch 253/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0083 - acc: 0.9059 - val_loss: 0.0083 - val_acc: 0.9002\n",
      "Epoch 254/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0082 - acc: 0.9032 - val_loss: 0.0083 - val_acc: 0.9031\n",
      "Epoch 255/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0082 - acc: 0.9059 - val_loss: 0.0082 - val_acc: 0.9007\n",
      "Epoch 256/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.9036 - val_loss: 0.0082 - val_acc: 0.9030\n",
      "Epoch 257/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.9057 - val_loss: 0.0081 - val_acc: 0.9012\n",
      "Epoch 258/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0080 - acc: 0.9038 - val_loss: 0.0081 - val_acc: 0.9028\n",
      "Epoch 259/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0080 - acc: 0.9055 - val_loss: 0.0080 - val_acc: 0.9014\n",
      "Epoch 260/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0080 - acc: 0.9040 - val_loss: 0.0080 - val_acc: 0.9027\n",
      "Epoch 261/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.9055 - val_loss: 0.0080 - val_acc: 0.9016\n",
      "Epoch 262/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.9045 - val_loss: 0.0079 - val_acc: 0.9026\n",
      "Epoch 263/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0078 - acc: 0.9054 - val_loss: 0.0079 - val_acc: 0.9017\n",
      "Epoch 264/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0078 - acc: 0.9047 - val_loss: 0.0079 - val_acc: 0.9026\n",
      "Epoch 265/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0078 - acc: 0.9054 - val_loss: 0.0078 - val_acc: 0.9017\n",
      "Epoch 266/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.9047 - val_loss: 0.0078 - val_acc: 0.9026\n",
      "Epoch 267/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.9054 - val_loss: 0.0077 - val_acc: 0.9017\n",
      "Epoch 268/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.9047 - val_loss: 0.0077 - val_acc: 0.9026\n",
      "Epoch 269/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0076 - acc: 0.9053 - val_loss: 0.0077 - val_acc: 0.9018\n",
      "Epoch 270/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0076 - acc: 0.9047 - val_loss: 0.0076 - val_acc: 0.9026\n",
      "Epoch 271/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0076 - acc: 0.9053 - val_loss: 0.0076 - val_acc: 0.9018\n",
      "Epoch 272/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.9047 - val_loss: 0.0076 - val_acc: 0.9026\n",
      "Epoch 273/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.9053 - val_loss: 0.0075 - val_acc: 0.9018\n",
      "Epoch 274/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.9047 - val_loss: 0.0075 - val_acc: 0.9026\n",
      "Epoch 275/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.9054 - val_loss: 0.0075 - val_acc: 0.9017\n",
      "Epoch 276/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.9046 - val_loss: 0.0075 - val_acc: 0.9026\n",
      "Epoch 277/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.9054 - val_loss: 0.0074 - val_acc: 0.9018\n",
      "Epoch 278/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.9046 - val_loss: 0.0074 - val_acc: 0.9026\n",
      "Epoch 279/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.9054 - val_loss: 0.0074 - val_acc: 0.9019\n",
      "Epoch 280/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.9046 - val_loss: 0.0073 - val_acc: 0.9027\n",
      "Epoch 281/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.9054 - val_loss: 0.0073 - val_acc: 0.9019\n",
      "Epoch 282/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9046 - val_loss: 0.0073 - val_acc: 0.9028\n",
      "Epoch 283/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9055 - val_loss: 0.0072 - val_acc: 0.9019\n",
      "Epoch 284/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.9047 - val_loss: 0.0072 - val_acc: 0.9028\n",
      "Epoch 285/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9056 - val_loss: 0.0072 - val_acc: 0.9019\n",
      "Epoch 286/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9041 - val_loss: 0.0072 - val_acc: 0.9030\n",
      "Epoch 287/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9057 - val_loss: 0.0071 - val_acc: 0.9017\n",
      "Epoch 288/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.9042 - val_loss: 0.0071 - val_acc: 0.9031\n",
      "Epoch 289/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9058 - val_loss: 0.0071 - val_acc: 0.9012\n",
      "Epoch 290/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9038 - val_loss: 0.0071 - val_acc: 0.9032\n",
      "Epoch 291/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9059 - val_loss: 0.0071 - val_acc: 0.9007\n",
      "Epoch 292/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9034 - val_loss: 0.0070 - val_acc: 0.9032\n",
      "Epoch 293/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9060 - val_loss: 0.0070 - val_acc: 0.9002\n",
      "Epoch 294/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.9034 - val_loss: 0.0070 - val_acc: 0.9033\n",
      "Epoch 295/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9061 - val_loss: 0.0070 - val_acc: 0.8999\n",
      "Epoch 296/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9028 - val_loss: 0.0070 - val_acc: 0.9033\n",
      "Epoch 297/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9061 - val_loss: 0.0069 - val_acc: 0.8997\n",
      "Epoch 298/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9023 - val_loss: 0.0069 - val_acc: 0.9033\n",
      "Epoch 299/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.9061 - val_loss: 0.0069 - val_acc: 0.8998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.9026 - val_loss: 0.0069 - val_acc: 0.9033\n",
      "3000/3000 [==============================] - 0s 30us/step\n",
      "['loss', 'acc'] [0.00693636466562748, 0.9099999998410543]\n",
      "[[0.66108923 0.95594316]] [[0.00282203 0.99587554 0.98719585]]\n"
     ]
    }
   ],
   "source": [
    "model = multi_label_learning_demo(mask_value=None)\n",
    "x = np.random.rand(1,2)\n",
    "print(x, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### sigmoid +  欠損ラベル作成して、maskありでbinary_Focal_Loss使用\n",
    "- うまくいってる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sigmoid\n",
      "(100000, 3) [[-1.  1.  1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1.  0.]\n",
      " ...\n",
      " [ 0.  0.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  1.  0.]]\n",
      " 0.0    93132\n",
      " 1.0     4868\n",
      "-1.0     2000\n",
      "dtype: int64\n",
      " 1.0    94440\n",
      " 0.0     4859\n",
      "-1.0      701\n",
      "dtype: int64\n",
      " 1.0    49495\n",
      " 0.0    49405\n",
      "-1.0     1100\n",
      "dtype: int64\n",
      "input_dim, nb_classes: 2 3\n",
      "Train on 9700 samples, validate on 87300 samples\n",
      "Epoch 1/300\n",
      "9700/9700 [==============================] - 0s 18us/step - loss: 0.0782 - acc: 0.2957 - val_loss: 0.0765 - val_acc: 0.2926\n",
      "Epoch 2/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0766 - acc: 0.2955 - val_loss: 0.0755 - val_acc: 0.3302\n",
      "Epoch 3/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0756 - acc: 0.3338 - val_loss: 0.0746 - val_acc: 0.3872\n",
      "Epoch 4/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0746 - acc: 0.3900 - val_loss: 0.0736 - val_acc: 0.4745\n",
      "Epoch 5/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0737 - acc: 0.4812 - val_loss: 0.0727 - val_acc: 0.6090\n",
      "Epoch 6/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0728 - acc: 0.6102 - val_loss: 0.0718 - val_acc: 0.7699\n",
      "Epoch 7/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0719 - acc: 0.7729 - val_loss: 0.0708 - val_acc: 0.8814\n",
      "Epoch 8/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0709 - acc: 0.8833 - val_loss: 0.0699 - val_acc: 0.8986\n",
      "Epoch 9/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0699 - acc: 0.9003 - val_loss: 0.0688 - val_acc: 0.8986\n",
      "Epoch 10/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0689 - acc: 0.9003 - val_loss: 0.0678 - val_acc: 0.8986\n",
      "Epoch 11/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0679 - acc: 0.9003 - val_loss: 0.0667 - val_acc: 0.8986\n",
      "Epoch 12/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0668 - acc: 0.9003 - val_loss: 0.0657 - val_acc: 0.8986\n",
      "Epoch 13/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0657 - acc: 0.9003 - val_loss: 0.0646 - val_acc: 0.8986\n",
      "Epoch 14/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0646 - acc: 0.9003 - val_loss: 0.0635 - val_acc: 0.8986\n",
      "Epoch 15/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0635 - acc: 0.9003 - val_loss: 0.0623 - val_acc: 0.8986\n",
      "Epoch 16/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0624 - acc: 0.9003 - val_loss: 0.0612 - val_acc: 0.8986\n",
      "Epoch 17/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0613 - acc: 0.9003 - val_loss: 0.0601 - val_acc: 0.8986\n",
      "Epoch 18/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0601 - acc: 0.9003 - val_loss: 0.0590 - val_acc: 0.8986\n",
      "Epoch 19/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0590 - acc: 0.9003 - val_loss: 0.0579 - val_acc: 0.8986\n",
      "Epoch 20/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0579 - acc: 0.9003 - val_loss: 0.0568 - val_acc: 0.8986\n",
      "Epoch 21/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0568 - acc: 0.9003 - val_loss: 0.0558 - val_acc: 0.8986\n",
      "Epoch 22/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0558 - acc: 0.9003 - val_loss: 0.0548 - val_acc: 0.8986\n",
      "Epoch 23/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0547 - acc: 0.9003 - val_loss: 0.0538 - val_acc: 0.8986\n",
      "Epoch 24/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0537 - acc: 0.9003 - val_loss: 0.0528 - val_acc: 0.8986\n",
      "Epoch 25/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0528 - acc: 0.9003 - val_loss: 0.0519 - val_acc: 0.8986\n",
      "Epoch 26/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0518 - acc: 0.9003 - val_loss: 0.0509 - val_acc: 0.8986\n",
      "Epoch 27/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0509 - acc: 0.9003 - val_loss: 0.0501 - val_acc: 0.8986\n",
      "Epoch 28/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0500 - acc: 0.9003 - val_loss: 0.0492 - val_acc: 0.8986\n",
      "Epoch 29/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0491 - acc: 0.9003 - val_loss: 0.0484 - val_acc: 0.8986\n",
      "Epoch 30/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0483 - acc: 0.9003 - val_loss: 0.0476 - val_acc: 0.8986\n",
      "Epoch 31/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0475 - acc: 0.9003 - val_loss: 0.0468 - val_acc: 0.8986\n",
      "Epoch 32/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0467 - acc: 0.9003 - val_loss: 0.0460 - val_acc: 0.8986\n",
      "Epoch 33/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0459 - acc: 0.9003 - val_loss: 0.0453 - val_acc: 0.8986\n",
      "Epoch 34/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0452 - acc: 0.9003 - val_loss: 0.0446 - val_acc: 0.8986\n",
      "Epoch 35/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0445 - acc: 0.9003 - val_loss: 0.0439 - val_acc: 0.8986\n",
      "Epoch 36/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0438 - acc: 0.9003 - val_loss: 0.0432 - val_acc: 0.8986\n",
      "Epoch 37/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0431 - acc: 0.9003 - val_loss: 0.0425 - val_acc: 0.8986\n",
      "Epoch 38/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0424 - acc: 0.9003 - val_loss: 0.0419 - val_acc: 0.8986\n",
      "Epoch 39/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0417 - acc: 0.9003 - val_loss: 0.0412 - val_acc: 0.8986\n",
      "Epoch 40/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0411 - acc: 0.9003 - val_loss: 0.0407 - val_acc: 0.8986\n",
      "Epoch 41/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0405 - acc: 0.9003 - val_loss: 0.0402 - val_acc: 0.8986\n",
      "Epoch 42/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0400 - acc: 0.9003 - val_loss: 0.0397 - val_acc: 0.8986\n",
      "Epoch 43/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0396 - acc: 0.9003 - val_loss: 0.0393 - val_acc: 0.8986\n",
      "Epoch 44/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0391 - acc: 0.9003 - val_loss: 0.0389 - val_acc: 0.8986\n",
      "Epoch 45/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0387 - acc: 0.9003 - val_loss: 0.0385 - val_acc: 0.8986\n",
      "Epoch 46/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0384 - acc: 0.9003 - val_loss: 0.0382 - val_acc: 0.8986\n",
      "Epoch 47/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0380 - acc: 0.9003 - val_loss: 0.0379 - val_acc: 0.8986\n",
      "Epoch 48/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0377 - acc: 0.9003 - val_loss: 0.0376 - val_acc: 0.8986\n",
      "Epoch 49/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0374 - acc: 0.9003 - val_loss: 0.0373 - val_acc: 0.8986\n",
      "Epoch 50/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0371 - acc: 0.9003 - val_loss: 0.0370 - val_acc: 0.8986\n",
      "Epoch 51/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0368 - acc: 0.9003 - val_loss: 0.0368 - val_acc: 0.8986\n",
      "Epoch 52/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0366 - acc: 0.9003 - val_loss: 0.0366 - val_acc: 0.8986\n",
      "Epoch 53/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0363 - acc: 0.9003 - val_loss: 0.0363 - val_acc: 0.8986\n",
      "Epoch 54/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0361 - acc: 0.9003 - val_loss: 0.0361 - val_acc: 0.8986\n",
      "Epoch 55/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0359 - acc: 0.9003 - val_loss: 0.0359 - val_acc: 0.8986\n",
      "Epoch 56/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0357 - acc: 0.9003 - val_loss: 0.0357 - val_acc: 0.8986\n",
      "Epoch 57/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0354 - acc: 0.9003 - val_loss: 0.0354 - val_acc: 0.8986\n",
      "Epoch 58/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0352 - acc: 0.9003 - val_loss: 0.0352 - val_acc: 0.8986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0350 - acc: 0.9003 - val_loss: 0.0350 - val_acc: 0.8986\n",
      "Epoch 60/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0348 - acc: 0.9003 - val_loss: 0.0348 - val_acc: 0.8986\n",
      "Epoch 61/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0346 - acc: 0.9003 - val_loss: 0.0346 - val_acc: 0.8986\n",
      "Epoch 62/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0344 - acc: 0.9003 - val_loss: 0.0343 - val_acc: 0.8986\n",
      "Epoch 63/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0341 - acc: 0.9003 - val_loss: 0.0341 - val_acc: 0.8986\n",
      "Epoch 64/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0339 - acc: 0.9003 - val_loss: 0.0338 - val_acc: 0.8986\n",
      "Epoch 65/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0336 - acc: 0.9003 - val_loss: 0.0336 - val_acc: 0.8986\n",
      "Epoch 66/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0333 - acc: 0.9003 - val_loss: 0.0333 - val_acc: 0.8986\n",
      "Epoch 67/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0331 - acc: 0.9003 - val_loss: 0.0330 - val_acc: 0.8986\n",
      "Epoch 68/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0328 - acc: 0.9003 - val_loss: 0.0328 - val_acc: 0.8986\n",
      "Epoch 69/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0326 - acc: 0.9003 - val_loss: 0.0325 - val_acc: 0.8986\n",
      "Epoch 70/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0323 - acc: 0.9003 - val_loss: 0.0322 - val_acc: 0.8986\n",
      "Epoch 71/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0320 - acc: 0.9003 - val_loss: 0.0320 - val_acc: 0.8986\n",
      "Epoch 72/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0318 - acc: 0.9003 - val_loss: 0.0317 - val_acc: 0.8986\n",
      "Epoch 73/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0315 - acc: 0.9003 - val_loss: 0.0314 - val_acc: 0.8986\n",
      "Epoch 74/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0312 - acc: 0.9003 - val_loss: 0.0311 - val_acc: 0.8986\n",
      "Epoch 75/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0309 - acc: 0.9003 - val_loss: 0.0308 - val_acc: 0.8986\n",
      "Epoch 76/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0306 - acc: 0.9003 - val_loss: 0.0305 - val_acc: 0.8986\n",
      "Epoch 77/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0303 - acc: 0.9003 - val_loss: 0.0303 - val_acc: 0.8986\n",
      "Epoch 78/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0301 - acc: 0.9003 - val_loss: 0.0300 - val_acc: 0.8986\n",
      "Epoch 79/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0298 - acc: 0.9003 - val_loss: 0.0297 - val_acc: 0.8986\n",
      "Epoch 80/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0295 - acc: 0.9003 - val_loss: 0.0294 - val_acc: 0.8986\n",
      "Epoch 81/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0292 - acc: 0.9003 - val_loss: 0.0291 - val_acc: 0.8986\n",
      "Epoch 82/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0289 - acc: 0.9003 - val_loss: 0.0288 - val_acc: 0.8986\n",
      "Epoch 83/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0286 - acc: 0.9003 - val_loss: 0.0285 - val_acc: 0.8986\n",
      "Epoch 84/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0283 - acc: 0.9003 - val_loss: 0.0282 - val_acc: 0.8986\n",
      "Epoch 85/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0280 - acc: 0.9003 - val_loss: 0.0279 - val_acc: 0.8986\n",
      "Epoch 86/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0277 - acc: 0.9003 - val_loss: 0.0276 - val_acc: 0.8986\n",
      "Epoch 87/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0275 - acc: 0.9003 - val_loss: 0.0273 - val_acc: 0.8986\n",
      "Epoch 88/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0272 - acc: 0.9003 - val_loss: 0.0271 - val_acc: 0.8986\n",
      "Epoch 89/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0269 - acc: 0.9003 - val_loss: 0.0268 - val_acc: 0.8986\n",
      "Epoch 90/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0266 - acc: 0.9003 - val_loss: 0.0265 - val_acc: 0.8986\n",
      "Epoch 91/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0263 - acc: 0.9003 - val_loss: 0.0262 - val_acc: 0.8986\n",
      "Epoch 92/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0260 - acc: 0.9003 - val_loss: 0.0259 - val_acc: 0.8986\n",
      "Epoch 93/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0257 - acc: 0.9003 - val_loss: 0.0256 - val_acc: 0.8986\n",
      "Epoch 94/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0254 - acc: 0.9003 - val_loss: 0.0253 - val_acc: 0.8986\n",
      "Epoch 95/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0251 - acc: 0.9003 - val_loss: 0.0250 - val_acc: 0.8986\n",
      "Epoch 96/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0249 - acc: 0.9003 - val_loss: 0.0247 - val_acc: 0.8986\n",
      "Epoch 97/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0246 - acc: 0.9003 - val_loss: 0.0245 - val_acc: 0.8986\n",
      "Epoch 98/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0243 - acc: 0.9003 - val_loss: 0.0242 - val_acc: 0.8986\n",
      "Epoch 99/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0240 - acc: 0.9003 - val_loss: 0.0239 - val_acc: 0.8986\n",
      "Epoch 100/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0238 - acc: 0.9003 - val_loss: 0.0237 - val_acc: 0.8986\n",
      "Epoch 101/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0235 - acc: 0.9003 - val_loss: 0.0234 - val_acc: 0.8986\n",
      "Epoch 102/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0232 - acc: 0.9003 - val_loss: 0.0232 - val_acc: 0.8986\n",
      "Epoch 103/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0230 - acc: 0.9003 - val_loss: 0.0229 - val_acc: 0.8986\n",
      "Epoch 104/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0227 - acc: 0.9003 - val_loss: 0.0227 - val_acc: 0.8986\n",
      "Epoch 105/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0225 - acc: 0.9003 - val_loss: 0.0224 - val_acc: 0.8986\n",
      "Epoch 106/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0222 - acc: 0.9003 - val_loss: 0.0222 - val_acc: 0.8986\n",
      "Epoch 107/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0220 - acc: 0.9003 - val_loss: 0.0219 - val_acc: 0.8986\n",
      "Epoch 108/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0218 - acc: 0.9003 - val_loss: 0.0217 - val_acc: 0.8986\n",
      "Epoch 109/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0215 - acc: 0.9003 - val_loss: 0.0215 - val_acc: 0.8986\n",
      "Epoch 110/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0213 - acc: 0.9003 - val_loss: 0.0212 - val_acc: 0.8986\n",
      "Epoch 111/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0211 - acc: 0.9003 - val_loss: 0.0210 - val_acc: 0.8986\n",
      "Epoch 112/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0208 - acc: 0.9003 - val_loss: 0.0208 - val_acc: 0.8986\n",
      "Epoch 113/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0206 - acc: 0.9003 - val_loss: 0.0205 - val_acc: 0.8986\n",
      "Epoch 114/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0204 - acc: 0.9003 - val_loss: 0.0203 - val_acc: 0.8986\n",
      "Epoch 115/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0201 - acc: 0.9003 - val_loss: 0.0201 - val_acc: 0.8986\n",
      "Epoch 116/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0199 - acc: 0.9003 - val_loss: 0.0199 - val_acc: 0.8986\n",
      "Epoch 117/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0197 - acc: 0.9003 - val_loss: 0.0197 - val_acc: 0.8986\n",
      "Epoch 118/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0195 - acc: 0.9003 - val_loss: 0.0195 - val_acc: 0.8986\n",
      "Epoch 119/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0193 - acc: 0.9003 - val_loss: 0.0192 - val_acc: 0.8986\n",
      "Epoch 120/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0191 - acc: 0.9003 - val_loss: 0.0191 - val_acc: 0.8986\n",
      "Epoch 121/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0189 - acc: 0.9003 - val_loss: 0.0189 - val_acc: 0.8986\n",
      "Epoch 122/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0187 - acc: 0.9003 - val_loss: 0.0187 - val_acc: 0.8986\n",
      "Epoch 123/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0185 - acc: 0.9003 - val_loss: 0.0185 - val_acc: 0.8986\n",
      "Epoch 124/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0184 - acc: 0.9003 - val_loss: 0.0183 - val_acc: 0.8986\n",
      "Epoch 125/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0182 - acc: 0.9003 - val_loss: 0.0182 - val_acc: 0.8986\n",
      "Epoch 126/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0180 - acc: 0.9003 - val_loss: 0.0180 - val_acc: 0.8986\n",
      "Epoch 127/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0179 - acc: 0.9003 - val_loss: 0.0179 - val_acc: 0.8986\n",
      "Epoch 128/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0177 - acc: 0.9003 - val_loss: 0.0177 - val_acc: 0.8986\n",
      "Epoch 129/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0175 - acc: 0.9003 - val_loss: 0.0176 - val_acc: 0.8986\n",
      "Epoch 130/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0174 - acc: 0.9003 - val_loss: 0.0174 - val_acc: 0.8986\n",
      "Epoch 131/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0172 - acc: 0.9003 - val_loss: 0.0173 - val_acc: 0.8986\n",
      "Epoch 132/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0171 - acc: 0.9003 - val_loss: 0.0171 - val_acc: 0.8986\n",
      "Epoch 133/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0170 - acc: 0.9003 - val_loss: 0.0170 - val_acc: 0.8986\n",
      "Epoch 134/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0168 - acc: 0.9003 - val_loss: 0.0168 - val_acc: 0.8986\n",
      "Epoch 135/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0167 - acc: 0.9003 - val_loss: 0.0167 - val_acc: 0.8986\n",
      "Epoch 136/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0165 - acc: 0.9003 - val_loss: 0.0166 - val_acc: 0.8986\n",
      "Epoch 137/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0164 - acc: 0.9003 - val_loss: 0.0165 - val_acc: 0.8986\n",
      "Epoch 138/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0163 - acc: 0.9003 - val_loss: 0.0163 - val_acc: 0.8986\n",
      "Epoch 139/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0162 - acc: 0.9003 - val_loss: 0.0162 - val_acc: 0.8986\n",
      "Epoch 140/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0161 - acc: 0.9003 - val_loss: 0.0161 - val_acc: 0.8986\n",
      "Epoch 141/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0159 - acc: 0.9003 - val_loss: 0.0160 - val_acc: 0.8986\n",
      "Epoch 142/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0158 - acc: 0.9003 - val_loss: 0.0159 - val_acc: 0.8986\n",
      "Epoch 143/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0157 - acc: 0.9003 - val_loss: 0.0158 - val_acc: 0.8986\n",
      "Epoch 144/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0156 - acc: 0.9003 - val_loss: 0.0157 - val_acc: 0.8986\n",
      "Epoch 145/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0155 - acc: 0.9003 - val_loss: 0.0156 - val_acc: 0.8986\n",
      "Epoch 146/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0154 - acc: 0.9003 - val_loss: 0.0155 - val_acc: 0.8986\n",
      "Epoch 147/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0153 - acc: 0.9003 - val_loss: 0.0154 - val_acc: 0.8986\n",
      "Epoch 148/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0152 - acc: 0.9003 - val_loss: 0.0153 - val_acc: 0.8986\n",
      "Epoch 149/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0151 - acc: 0.9003 - val_loss: 0.0152 - val_acc: 0.8986\n",
      "Epoch 150/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0150 - acc: 0.9003 - val_loss: 0.0151 - val_acc: 0.8986\n",
      "Epoch 151/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0149 - acc: 0.9003 - val_loss: 0.0150 - val_acc: 0.8986\n",
      "Epoch 152/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0148 - acc: 0.9003 - val_loss: 0.0149 - val_acc: 0.8986\n",
      "Epoch 153/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0147 - acc: 0.9003 - val_loss: 0.0148 - val_acc: 0.8986\n",
      "Epoch 154/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0146 - acc: 0.9003 - val_loss: 0.0147 - val_acc: 0.8986\n",
      "Epoch 155/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0145 - acc: 0.9003 - val_loss: 0.0146 - val_acc: 0.8986\n",
      "Epoch 156/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0144 - acc: 0.9003 - val_loss: 0.0145 - val_acc: 0.8986\n",
      "Epoch 157/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0143 - acc: 0.9003 - val_loss: 0.0144 - val_acc: 0.8986\n",
      "Epoch 158/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0142 - acc: 0.9003 - val_loss: 0.0143 - val_acc: 0.8986\n",
      "Epoch 159/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0142 - acc: 0.9003 - val_loss: 0.0142 - val_acc: 0.8986\n",
      "Epoch 160/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0141 - acc: 0.9003 - val_loss: 0.0142 - val_acc: 0.8986\n",
      "Epoch 161/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0140 - acc: 0.9003 - val_loss: 0.0141 - val_acc: 0.8986\n",
      "Epoch 162/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0139 - acc: 0.9003 - val_loss: 0.0140 - val_acc: 0.8986\n",
      "Epoch 163/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0138 - acc: 0.9003 - val_loss: 0.0139 - val_acc: 0.8986\n",
      "Epoch 164/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0137 - acc: 0.9003 - val_loss: 0.0138 - val_acc: 0.8986\n",
      "Epoch 165/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0136 - acc: 0.9003 - val_loss: 0.0137 - val_acc: 0.8986\n",
      "Epoch 166/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0136 - acc: 0.9003 - val_loss: 0.0137 - val_acc: 0.8986\n",
      "Epoch 167/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0135 - acc: 0.9003 - val_loss: 0.0136 - val_acc: 0.8986\n",
      "Epoch 168/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0134 - acc: 0.9003 - val_loss: 0.0135 - val_acc: 0.8986\n",
      "Epoch 169/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0133 - acc: 0.9003 - val_loss: 0.0134 - val_acc: 0.8986\n",
      "Epoch 170/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0132 - acc: 0.9003 - val_loss: 0.0133 - val_acc: 0.8986\n",
      "Epoch 171/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0132 - acc: 0.9003 - val_loss: 0.0133 - val_acc: 0.8986\n",
      "Epoch 172/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0131 - acc: 0.9003 - val_loss: 0.0132 - val_acc: 0.8986\n",
      "Epoch 173/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0130 - acc: 0.9003 - val_loss: 0.0131 - val_acc: 0.8986\n",
      "Epoch 174/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0129 - acc: 0.9003 - val_loss: 0.0130 - val_acc: 0.8986\n",
      "Epoch 175/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0128 - acc: 0.9003 - val_loss: 0.0129 - val_acc: 0.8986\n",
      "Epoch 176/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0128 - acc: 0.9003 - val_loss: 0.0128 - val_acc: 0.8986\n",
      "Epoch 177/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0127 - acc: 0.9003 - val_loss: 0.0128 - val_acc: 0.8986\n",
      "Epoch 178/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0126 - acc: 0.9003 - val_loss: 0.0127 - val_acc: 0.8986\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0125 - acc: 0.9003 - val_loss: 0.0126 - val_acc: 0.8986\n",
      "Epoch 180/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0124 - acc: 0.9003 - val_loss: 0.0125 - val_acc: 0.8986\n",
      "Epoch 181/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0123 - acc: 0.9003 - val_loss: 0.0124 - val_acc: 0.8986\n",
      "Epoch 182/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0122 - acc: 0.9003 - val_loss: 0.0123 - val_acc: 0.8986\n",
      "Epoch 183/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0121 - acc: 0.9003 - val_loss: 0.0122 - val_acc: 0.8986\n",
      "Epoch 184/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0121 - acc: 0.9003 - val_loss: 0.0121 - val_acc: 0.8986\n",
      "Epoch 185/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0120 - acc: 0.9003 - val_loss: 0.0120 - val_acc: 0.8986\n",
      "Epoch 186/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0119 - acc: 0.9003 - val_loss: 0.0120 - val_acc: 0.8986\n",
      "Epoch 187/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0118 - acc: 0.9003 - val_loss: 0.0119 - val_acc: 0.8986\n",
      "Epoch 188/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0117 - acc: 0.9003 - val_loss: 0.0118 - val_acc: 0.8986\n",
      "Epoch 189/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0116 - acc: 0.9003 - val_loss: 0.0117 - val_acc: 0.8986\n",
      "Epoch 190/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0116 - acc: 0.9003 - val_loss: 0.0116 - val_acc: 0.8986\n",
      "Epoch 191/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0115 - acc: 0.9003 - val_loss: 0.0115 - val_acc: 0.8986\n",
      "Epoch 192/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0114 - acc: 0.9003 - val_loss: 0.0115 - val_acc: 0.8986\n",
      "Epoch 193/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0113 - acc: 0.9003 - val_loss: 0.0114 - val_acc: 0.8986\n",
      "Epoch 194/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0113 - acc: 0.9003 - val_loss: 0.0113 - val_acc: 0.8986\n",
      "Epoch 195/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0112 - acc: 0.9003 - val_loss: 0.0112 - val_acc: 0.8986\n",
      "Epoch 196/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0111 - acc: 0.9003 - val_loss: 0.0112 - val_acc: 0.8986\n",
      "Epoch 197/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0110 - acc: 0.9003 - val_loss: 0.0111 - val_acc: 0.8985\n",
      "Epoch 198/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0110 - acc: 0.9001 - val_loss: 0.0110 - val_acc: 0.8986\n",
      "Epoch 199/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0109 - acc: 0.9003 - val_loss: 0.0110 - val_acc: 0.8982\n",
      "Epoch 200/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0109 - acc: 0.8997 - val_loss: 0.0109 - val_acc: 0.8986\n",
      "Epoch 201/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0108 - acc: 0.9003 - val_loss: 0.0108 - val_acc: 0.8978\n",
      "Epoch 202/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0107 - acc: 0.8996 - val_loss: 0.0108 - val_acc: 0.8986\n",
      "Epoch 203/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0107 - acc: 0.9003 - val_loss: 0.0107 - val_acc: 0.8977\n",
      "Epoch 204/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0106 - acc: 0.8995 - val_loss: 0.0106 - val_acc: 0.8986\n",
      "Epoch 205/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0105 - acc: 0.9003 - val_loss: 0.0105 - val_acc: 0.8976\n",
      "Epoch 206/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0104 - acc: 0.8994 - val_loss: 0.0105 - val_acc: 0.8986\n",
      "Epoch 207/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0104 - acc: 0.9003 - val_loss: 0.0104 - val_acc: 0.8975\n",
      "Epoch 208/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0103 - acc: 0.8993 - val_loss: 0.0103 - val_acc: 0.8986\n",
      "Epoch 209/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0102 - acc: 0.9001 - val_loss: 0.0103 - val_acc: 0.8975\n",
      "Epoch 210/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0102 - acc: 0.8993 - val_loss: 0.0102 - val_acc: 0.8984\n",
      "Epoch 211/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0101 - acc: 0.9001 - val_loss: 0.0102 - val_acc: 0.8974\n",
      "Epoch 212/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0100 - acc: 0.8992 - val_loss: 0.0101 - val_acc: 0.8982\n",
      "Epoch 213/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0100 - acc: 0.8997 - val_loss: 0.0100 - val_acc: 0.8973\n",
      "Epoch 214/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0099 - acc: 0.8991 - val_loss: 0.0100 - val_acc: 0.8980\n",
      "Epoch 215/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0099 - acc: 0.8996 - val_loss: 0.0099 - val_acc: 0.8970\n",
      "Epoch 216/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0098 - acc: 0.8989 - val_loss: 0.0099 - val_acc: 0.8978\n",
      "Epoch 217/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0097 - acc: 0.8996 - val_loss: 0.0098 - val_acc: 0.8968\n",
      "Epoch 218/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0097 - acc: 0.8985 - val_loss: 0.0097 - val_acc: 0.8977\n",
      "Epoch 219/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0096 - acc: 0.8996 - val_loss: 0.0097 - val_acc: 0.8965\n",
      "Epoch 220/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0096 - acc: 0.8982 - val_loss: 0.0096 - val_acc: 0.8975\n",
      "Epoch 221/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0095 - acc: 0.8994 - val_loss: 0.0096 - val_acc: 0.8962\n",
      "Epoch 222/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0095 - acc: 0.8982 - val_loss: 0.0095 - val_acc: 0.8974\n",
      "Epoch 223/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0094 - acc: 0.8993 - val_loss: 0.0095 - val_acc: 0.8959\n",
      "Epoch 224/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0094 - acc: 0.8980 - val_loss: 0.0094 - val_acc: 0.8973\n",
      "Epoch 225/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0093 - acc: 0.8992 - val_loss: 0.0094 - val_acc: 0.8957\n",
      "Epoch 226/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0093 - acc: 0.8975 - val_loss: 0.0093 - val_acc: 0.8973\n",
      "Epoch 227/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0092 - acc: 0.8992 - val_loss: 0.0093 - val_acc: 0.8953\n",
      "Epoch 228/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0092 - acc: 0.8970 - val_loss: 0.0092 - val_acc: 0.8973\n",
      "Epoch 229/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0091 - acc: 0.8992 - val_loss: 0.0092 - val_acc: 0.8950\n",
      "Epoch 230/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0091 - acc: 0.8964 - val_loss: 0.0091 - val_acc: 0.8973\n",
      "Epoch 231/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0090 - acc: 0.8992 - val_loss: 0.0091 - val_acc: 0.8947\n",
      "Epoch 232/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0090 - acc: 0.8959 - val_loss: 0.0090 - val_acc: 0.8974\n",
      "Epoch 233/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.8992 - val_loss: 0.0090 - val_acc: 0.8944\n",
      "Epoch 234/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0089 - acc: 0.8955 - val_loss: 0.0089 - val_acc: 0.8975\n",
      "Epoch 235/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0088 - acc: 0.8994 - val_loss: 0.0089 - val_acc: 0.8939\n",
      "Epoch 236/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0088 - acc: 0.8954 - val_loss: 0.0089 - val_acc: 0.8977\n",
      "Epoch 237/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0088 - acc: 0.8995 - val_loss: 0.0088 - val_acc: 0.8935\n",
      "Epoch 238/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0087 - acc: 0.8946 - val_loss: 0.0088 - val_acc: 0.8978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 239/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0087 - acc: 0.8995 - val_loss: 0.0087 - val_acc: 0.8932\n",
      "Epoch 240/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0087 - acc: 0.8943 - val_loss: 0.0087 - val_acc: 0.8979\n",
      "Epoch 241/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0086 - acc: 0.8996 - val_loss: 0.0087 - val_acc: 0.8930\n",
      "Epoch 242/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0086 - acc: 0.8940 - val_loss: 0.0086 - val_acc: 0.8979\n",
      "Epoch 243/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0085 - acc: 0.8996 - val_loss: 0.0086 - val_acc: 0.8931\n",
      "Epoch 244/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0085 - acc: 0.8941 - val_loss: 0.0085 - val_acc: 0.8979\n",
      "Epoch 245/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0084 - acc: 0.8996 - val_loss: 0.0085 - val_acc: 0.8935\n",
      "Epoch 246/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0084 - acc: 0.8944 - val_loss: 0.0084 - val_acc: 0.8978\n",
      "Epoch 247/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0084 - acc: 0.8995 - val_loss: 0.0084 - val_acc: 0.8938\n",
      "Epoch 248/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0083 - acc: 0.8949 - val_loss: 0.0083 - val_acc: 0.8977\n",
      "Epoch 249/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0083 - acc: 0.8995 - val_loss: 0.0083 - val_acc: 0.8941\n",
      "Epoch 250/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0082 - acc: 0.8957 - val_loss: 0.0083 - val_acc: 0.8975\n",
      "Epoch 251/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0082 - acc: 0.8994 - val_loss: 0.0082 - val_acc: 0.8945\n",
      "Epoch 252/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.8963 - val_loss: 0.0082 - val_acc: 0.8974\n",
      "Epoch 253/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0081 - acc: 0.8993 - val_loss: 0.0081 - val_acc: 0.8948\n",
      "Epoch 254/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0080 - acc: 0.8966 - val_loss: 0.0081 - val_acc: 0.8973\n",
      "Epoch 255/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0080 - acc: 0.8991 - val_loss: 0.0080 - val_acc: 0.8949\n",
      "Epoch 256/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0080 - acc: 0.8967 - val_loss: 0.0080 - val_acc: 0.8971\n",
      "Epoch 257/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.8990 - val_loss: 0.0080 - val_acc: 0.8951\n",
      "Epoch 258/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.8968 - val_loss: 0.0079 - val_acc: 0.8971\n",
      "Epoch 259/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0079 - acc: 0.8990 - val_loss: 0.0079 - val_acc: 0.8952\n",
      "Epoch 260/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0078 - acc: 0.8968 - val_loss: 0.0079 - val_acc: 0.8970\n",
      "Epoch 261/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0078 - acc: 0.8990 - val_loss: 0.0078 - val_acc: 0.8953\n",
      "Epoch 262/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.8970 - val_loss: 0.0078 - val_acc: 0.8970\n",
      "Epoch 263/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.8990 - val_loss: 0.0077 - val_acc: 0.8953\n",
      "Epoch 264/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0077 - acc: 0.8970 - val_loss: 0.0077 - val_acc: 0.8970\n",
      "Epoch 265/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0076 - acc: 0.8990 - val_loss: 0.0077 - val_acc: 0.8953\n",
      "Epoch 266/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0076 - acc: 0.8970 - val_loss: 0.0076 - val_acc: 0.8971\n",
      "Epoch 267/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0076 - acc: 0.8990 - val_loss: 0.0076 - val_acc: 0.8953\n",
      "Epoch 268/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.8970 - val_loss: 0.0076 - val_acc: 0.8971\n",
      "Epoch 269/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.8990 - val_loss: 0.0075 - val_acc: 0.8952\n",
      "Epoch 270/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0075 - acc: 0.8969 - val_loss: 0.0075 - val_acc: 0.8971\n",
      "Epoch 271/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.8990 - val_loss: 0.0075 - val_acc: 0.8952\n",
      "Epoch 272/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.8968 - val_loss: 0.0075 - val_acc: 0.8973\n",
      "Epoch 273/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.8991 - val_loss: 0.0074 - val_acc: 0.8952\n",
      "Epoch 274/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0074 - acc: 0.8966 - val_loss: 0.0074 - val_acc: 0.8974\n",
      "Epoch 275/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.8992 - val_loss: 0.0074 - val_acc: 0.8951\n",
      "Epoch 276/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.8965 - val_loss: 0.0073 - val_acc: 0.8975\n",
      "Epoch 277/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0073 - acc: 0.8995 - val_loss: 0.0073 - val_acc: 0.8951\n",
      "Epoch 278/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.8964 - val_loss: 0.0073 - val_acc: 0.8976\n",
      "Epoch 279/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.8995 - val_loss: 0.0073 - val_acc: 0.8951\n",
      "Epoch 280/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.8965 - val_loss: 0.0072 - val_acc: 0.8978\n",
      "Epoch 281/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0072 - acc: 0.8995 - val_loss: 0.0072 - val_acc: 0.8948\n",
      "Epoch 282/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.8964 - val_loss: 0.0072 - val_acc: 0.8979\n",
      "Epoch 283/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.8995 - val_loss: 0.0072 - val_acc: 0.8946\n",
      "Epoch 284/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.8961 - val_loss: 0.0071 - val_acc: 0.8979\n",
      "Epoch 285/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0071 - acc: 0.8995 - val_loss: 0.0071 - val_acc: 0.8944\n",
      "Epoch 286/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.8960 - val_loss: 0.0071 - val_acc: 0.8980\n",
      "Epoch 287/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.8996 - val_loss: 0.0071 - val_acc: 0.8942\n",
      "Epoch 288/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.8958 - val_loss: 0.0070 - val_acc: 0.8981\n",
      "Epoch 289/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0070 - acc: 0.8996 - val_loss: 0.0070 - val_acc: 0.8941\n",
      "Epoch 290/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.8958 - val_loss: 0.0070 - val_acc: 0.8981\n",
      "Epoch 291/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.8996 - val_loss: 0.0069 - val_acc: 0.8942\n",
      "Epoch 292/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0069 - acc: 0.8960 - val_loss: 0.0069 - val_acc: 0.8980\n",
      "Epoch 293/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.8996 - val_loss: 0.0069 - val_acc: 0.8944\n",
      "Epoch 294/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.8960 - val_loss: 0.0069 - val_acc: 0.8980\n",
      "Epoch 295/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.8995 - val_loss: 0.0068 - val_acc: 0.8947\n",
      "Epoch 296/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0068 - acc: 0.8962 - val_loss: 0.0068 - val_acc: 0.8979\n",
      "Epoch 297/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.8995 - val_loss: 0.0068 - val_acc: 0.8949\n",
      "Epoch 298/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.8963 - val_loss: 0.0067 - val_acc: 0.8979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 299/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0067 - acc: 0.8995 - val_loss: 0.0067 - val_acc: 0.8952\n",
      "Epoch 300/300\n",
      "9700/9700 [==============================] - 0s 4us/step - loss: 0.0066 - acc: 0.8964 - val_loss: 0.0067 - val_acc: 0.8979\n",
      "3000/3000 [==============================] - 0s 31us/step\n",
      "['loss', 'acc'] [0.00681511053442955, 0.9089999998410543]\n",
      "[[0.66108923 0.95594316]] [[0.00273981 0.99583673 0.9878747 ]]\n"
     ]
    }
   ],
   "source": [
    "model = multi_label_learning_demo(mask_value=-1.0)\n",
    "x = np.random.rand(1,2)\n",
    "print(x, model.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### softmax +  欠損ラベル作成して、maskありでcategorical_Focal_Loss使用\n",
    "- エラー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not sigmoid\n",
      "(100000, 3) [[-1.  1.  0.]\n",
      " [-1.  1.  0.]\n",
      " [-1.  1.  0.]\n",
      " ...\n",
      " [ 0.  1.  0.]\n",
      " [ 0.  1.  0.]\n",
      " [ 1.  0.  0.]]\n",
      " 0.0    93132\n",
      " 1.0     4868\n",
      "-1.0     2000\n",
      "dtype: int64\n",
      " 1.0    94365\n",
      " 0.0     4934\n",
      "-1.0      701\n",
      "dtype: int64\n",
      " 0.0    98900\n",
      "-1.0     1100\n",
      "dtype: int64\n",
      "input_dim, nb_classes: 2 3\n",
      "Train on 9700 samples, validate on 87300 samples\n",
      "Epoch 1/300\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Incompatible shapes: [9700,3] vs. [9700]\n\t [[Node: loss/output_loss/mul_8 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss/output_loss/mul_7, loss/output_loss/Neg)]]\n\t [[Node: loss/mul/_115 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_927_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'loss/output_loss/mul_8', defined at:\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-23-be2ab928269a>\", line 1, in <module>\n    model = multi_label_learning_demo(activation='softmax', loss=K.categorical_crossentropy, mask_value=-1.0)\n  File \"<ipython-input-19-ba2e882ff52a>\", line 67, in multi_label_learning_demo\n    model.compile(loss=loss, optimizer='nadam', metrics=['accuracy'])\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/keras/models.py\", line 806, in compile\n    **kwargs)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/keras/engine/training.py\", line 860, in compile\n    sample_weight, mask)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/keras/engine/training.py\", line 460, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"<ipython-input-18-ecdda528a21e>\", line 48, in compute_loss\n    focal_cross_entropy_loss = (modulating_factor * alpha_weight_factor * cross_entropy_loss)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 894, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1117, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2726, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [9700,3] vs. [9700]\n\t [[Node: loss/output_loss/mul_8 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss/output_loss/mul_7, loss/output_loss/Neg)]]\n\t [[Node: loss/mul/_115 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_927_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1322\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1323\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1324\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1301\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1303\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    474\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [9700,3] vs. [9700]\n\t [[Node: loss/output_loss/mul_8 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss/output_loss/mul_7, loss/output_loss/Neg)]]\n\t [[Node: loss/mul/_115 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_927_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-be2ab928269a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_label_learning_demo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcategorical_crossentropy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-19-ba2e882ff52a>\u001b[0m in \u001b[0;36mmulti_label_learning_demo\u001b[0;34m(activation, loss, mask_value, is_FocalLoss_multilabel)\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'nadam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_dev\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_dev\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    891\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    892\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 893\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    895\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1629\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1630\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1631\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1632\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1633\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1211\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2330\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2331\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2332\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2333\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2334\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    887\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 889\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    890\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1120\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1121\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1315\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1317\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1318\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Incompatible shapes: [9700,3] vs. [9700]\n\t [[Node: loss/output_loss/mul_8 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss/output_loss/mul_7, loss/output_loss/Neg)]]\n\t [[Node: loss/mul/_115 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_927_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'loss/output_loss/mul_8', defined at:\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 505, in start\n    self.io_loop.start()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/platform/asyncio.py\", line 148, in start\n    self.asyncio_loop.run_forever()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/asyncio/base_events.py\", line 427, in run_forever\n    self._run_once()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/asyncio/base_events.py\", line 1440, in _run_once\n    handle._run()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/asyncio/events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 690, in <lambda>\n    lambda f: self._run_callback(functools.partial(callback, future))\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/ioloop.py\", line 743, in _run_callback\n    ret = callback()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/gen.py\", line 781, in inner\n    self.run()\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/gen.py\", line 742, in run\n    yielded = self.gen.send(value)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 357, in process_one\n    yield gen.maybe_future(dispatch(*args))\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 267, in dispatch_shell\n    yield gen.maybe_future(handler(stream, idents, msg))\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 534, in execute_request\n    user_expressions, allow_stdin,\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tornado/gen.py\", line 209, in wrapper\n    yielded = next(result)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 294, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 536, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2843, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2869, in _run_cell\n    return runner(coro)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/IPython/core/async_helpers.py\", line 67, in _pseudo_sync_runner\n    coro.send(None)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3044, in run_cell_async\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3209, in run_ast_nodes\n    if (yield from self.run_code(code, result)):\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-23-be2ab928269a>\", line 1, in <module>\n    model = multi_label_learning_demo(activation='softmax', loss=K.categorical_crossentropy, mask_value=-1.0)\n  File \"<ipython-input-19-ba2e882ff52a>\", line 67, in multi_label_learning_demo\n    model.compile(loss=loss, optimizer='nadam', metrics=['accuracy'])\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/keras/models.py\", line 806, in compile\n    **kwargs)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/keras/engine/training.py\", line 860, in compile\n    sample_weight, mask)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/keras/engine/training.py\", line 460, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"<ipython-input-18-ecdda528a21e>\", line 48, in compute_loss\n    focal_cross_entropy_loss = (modulating_factor * alpha_weight_factor * cross_entropy_loss)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 894, in binary_op_wrapper\n    return func(x, y, name=name)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py\", line 1117, in _mul_dispatch\n    return gen_math_ops._mul(x, y, name=name)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/ops/gen_math_ops.py\", line 2726, in _mul\n    \"Mul\", x=x, y=y, name=name)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2956, in create_op\n    op_def=op_def)\n  File \"/home/bioinfo/.conda/envs/tfgpu_py36/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1470, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Incompatible shapes: [9700,3] vs. [9700]\n\t [[Node: loss/output_loss/mul_8 = Mul[T=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](loss/output_loss/mul_7, loss/output_loss/Neg)]]\n\t [[Node: loss/mul/_115 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_927_loss/mul\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "model = multi_label_learning_demo(activation='softmax', loss=K.categorical_crossentropy, mask_value=-1.0)\n",
    "x = np.random.rand(1,2)\n",
    "print(x, model.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bioinfo_tfgpu_py36",
   "language": "python",
   "name": "bioinfo_tfgpu_py36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
